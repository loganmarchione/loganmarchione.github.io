[{"content":"Introduction My only PC is a desktop, where I dual boot Windows (for gaming only) and Linux (for everything else). My work provided me with Macbook (read more about that here), but I don\u0026rsquo;t use it to manage my personal servers, write personal code, browse the internet, etc\u0026hellip; But, it would be really nice to SSH to a server from my couch on a device that\u0026rsquo;s not my phone. I figured it was time to get a laptop. I was looking for:\na CPU from within the last 2-3 years 16GB RAM SSD (not going to store anything critical on this device) full-size RJ-45 ethernet, HDMI, USB, etc\u0026hellip; WiFi 6 USB-C charging 1080p display (4k is too small on a laptop) $700 or under Naturally, the internet suggested a ThinkPad T-series laptop. Seeing as this wouldn\u0026rsquo;t be my main machine, I decided to purchase something refurbished from the Lenovo Outlet (their stuff is about 10% off new prices).\nSpecs I ended up purchasing a Lenovo ThinkPad T14 Gen2 (AMD) from the Lenovo Outlet. I\u0026rsquo;ve never purchased from the Lenovo Outlet before, but the model number I purchased online is not exactly the same as what showed up at my house. I\u0026rsquo;m not sure of the differences, but they\u0026rsquo;re both part of the 20XK family, so it might not matter. ü§∑‚Äç‚ôÇÔ∏è\nModel number on Lenovo Outlet and sticker on outside of laptop = 20XKX026US Model number in software and sticker on inside of laptop = 20XK005PUS For all intents and purposes, it looked like a brand new machine, minus all the paperwork and foam.\nStock Regardless of model number, here is the link to what I purchased. I paid $569.99, which I thought was a good deal. Below are the specs of the model that showed up to my house.\nPart Spec Comments CPU AMD Ryzen 5 PRO 5650U Zen3, 7nm, 6c/12t, up to 4.2GHz, 15W TDP Graphics AMD Radeon Vega 7 7 GPU cores, up to 1.8GHz RAM 8GB DDR4 3200MHz (soldered to motherboard) one open SODIMM slot Storage 256GB PCIe Gen3 x4 SSD SKHynix_HFS256GDE9X081N Display 14.0\u0026quot; FHD (1920x1080) IPS Anti-glare, 300 nits, non-touch Camera 720P HD With microphone and ThinkShutter WLAN Qualcomm WCN685x WiFi 6E LAN RealTek RTL8168/8111 2x of these (I think one is USB-C) Battery Integrated Li-Polymer 50Wh Power Supply 65W Upgraded Below are the parts I upgraded right out of the box.\nPart Spec Comments RAM Crucial 8GB Laptop DDR4 3200 MHz SODIMM (CT8G4SFRA32A) 8GB soldered to motherboard plus 8GB DDR4 SODIMM WLAN Intel AX200 WiFi 6 (AX200.NGWG.DTK) Replaced stock Qualcomm WCN685x Initial setup I booted into the default Windows install just to make sure everything worked, then updated the BIOS.\nOnce that was done, I added a stick of DDR4 SODIMM RAM and swapped out the WiFi card. For a large OEM, Lenovo has some really great documentation on their site for how to open the laptop up and access almost every part. Not as detailed as the Framework laptop documentation, but impressive nonetheless.\nThe screws on the case back were captive, which was a nice touch. There were about a dozen small clips that were almost impossible to open without a guitar pick or opening set from iFixit (I destroyed my credit card trying to use it as an opening tool). I would recommend opening the back only once, so make sure you have all the parts you need ahead of time.\nI tried to block out as many serial numbers as possible, but you can see the single SODIMM slot in the middle (under the black plastic), the SSD and WiFi modules in the top-right in an \u0026ldquo;L\u0026rdquo; shape, with the space for the WWAN module under the black plastic between them (there is a full-size image here).\nI started it up one more time to make sure everything still worked, then tested the new memory stick. I always test my memory before I use it, and I always recommend Memtest86 (not to be confused with Memtest86+).\nArch Linux install I had done my research before selecting this model and found an ArchWiki page on it, so I knew Arch should work.\nI always install Arch manually from a wiki I keep in my homelab (on DokuWiki), but maybe one day I\u0026rsquo;ll try archinstall. I\u0026rsquo;ve done it manually enough times that the whole thing takes about 15 minutes now.\nI\u0026rsquo;m a caveman, so I don\u0026rsquo;t use swap, suspend, or sleep. I shutdown my PC every time I\u0026rsquo;m done with it, then re-enter my encryption passphrase at every boot. I generally do ESP+GPT+LUKS2+SystemD boot (example partition layout below).\n+----------------------------+ +---------------------------------------------------------------------------+ | | | | | EFI System Partition (ESP) | | LUKS2 encrypted partition | | | | | | | | | | | | | | FAT32 | | XFS | | /boot | | / | |----------------------------| |---------------------------------------------------------------------------| | /dev/nvme0n1p1 | | /dev/nvme0n1p2 | +----------------------------+ +---------------------------------------------------------------------------+ +----------------------------------------------------------------------------------------------------------+ | | | /dev/nvme0n1 | | | +----------------------------------------------------------------------------------------------------------+ Once I get to the post-installation section of the installation, I use an Ansible playbook to setup my packages, desktop, settings, etc\u0026hellip; This allows me to keep my desktop and laptop setups consistent.\nConclusion I\u0026rsquo;ve been using this T14 on and off for about a week. I run KDE Plasma, so it\u0026rsquo;s very customizable, and I was able to tweak power settings, Bluetooth, trackpad speed, etc\u0026hellip; All the hardware works, and it does everything I ask it. I haven\u0026rsquo;t run the battery down to zero, but the projected 13 hour battery life sounds correct (assuming the screen brightness isn\u0026rsquo;t maxed out).\nNo complaints so far! I need to pickup a sleeve and maybe a few adapters (DisplayPort and VGA come to mind).\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/11/linux-on-the-lenovo-thinkpad-t14-gen2-amd/","summary":"Introduction My only PC is a desktop, where I dual boot Windows (for gaming only) and Linux (for everything else). My work provided me with Macbook (read more about that here), but I don\u0026rsquo;t use it to manage my personal servers, write personal code, browse the internet, etc\u0026hellip; But, it would be really nice to SSH to a server from my couch on a device that\u0026rsquo;s not my phone. I figured it was time to get a laptop.","title":"Linux on the Lenovo ThinkPad T14 Gen2 (AMD)"},{"content":"Introduction I recently started using Mend\u0026rsquo;s Renovate bot to keep my dependencies up-to-date on my GitHub projects. GitHub already has tool for this called Dependabot, but it only works with GitHub. Renovate is much more flexible, and it\u0026rsquo;s also open-source, so it can run on other Git platforms, like my self-hosted Gitea and Drone instance at home.\nHowever, self-hosting Renovate is more difficult because the hosted version takes care of a lot of the \u0026ldquo;magic\u0026rdquo; for you, so it \u0026ldquo;just works\u0026rdquo;. These are my notes on getting Renovate working with a self-hosted instance of Gitea and Drone.\nSelf-hosting Renovate As a user, there are two ways of running Renovate:\nsomeone else hosts Renovate and you install it for the repositories you choose (e.g., as a GitHub app) you extend off the global configuration provided my Renovate by adding a per-repository configuration file (called renovate.json) Renovate runs continuously in the background you host Renovate you provide some infrastructure for Renovate to run on (e.g., by running a Docker image, using a GitHub Action, running a npm package, etc\u0026hellip;) you need to provide a global configuration file (called config.js) you add a per-repository configuration file (called renovate.json) Renovate needs to run on a schedule (e.g., on a cronjob) In my case, I\u0026rsquo;m running Gitea and Drone at home, so I\u0026rsquo;m going to self-host Renovate and run the Renovate Docker image as a Drone step.\nIt\u0026rsquo;s important to note that there are two configuration files, but it\u0026rsquo;s recommended to keep as much configuration as possible in the per-repository files so that end users have the most flexibility and transparency.\nglobal configuration (called config.js) per-repository configuration (called renovate.json) Setup GitHub steps Create a GitHub personal access token (PAT) You need a GitHub PAT for getting release notes from GitHub.com to increase the hourly API limit It can be for any account (e.g., your personal account) It needs the public_repo permission, nothing else Save this token somewhere Gitea steps Renovate user Create renovate user\nLogin as the Gitea admin user and create a user for Renovate, called renovate Create a personal access token (PAT) for the renovate user\nLogout of the admin user Login as the renovate user, go to Settings--\u0026gt;Applications--\u0026gt;Manage Access Tokens and click on Generate Token Save this token somewhere Create repository for renovate\nCreate a new repository under the renovate user called renovate-config Create a file called config.js (this contains global settings for your instance of Renovate) Below is my config.js file (you\u0026rsquo;ll have to update the endpoint, gitAuthor, and the repositories section with the list of all Gitea repositories you want Renovate to run against) module.exports = { platform: \u0026#39;gitea\u0026#39;, endpoint: \u0026#39;https://git.internal.yourdomain.com/api/v1/\u0026#39;, gitAuthor: \u0026#39;Renovate Bot \u0026lt;renovate@yourdomain.com\u0026gt;\u0026#39;, username: \u0026#39;renovate\u0026#39;, autodiscover: true, onboardingConfig: { $schema: \u0026#39;https://docs.renovatebot.com/renovate-schema.json\u0026#39;, extends: [\u0026#39;config:base\u0026#39;] }, optimizeForDisabled: true, persistRepoData: true, repositories: [ \u0026#34;logan/docker\u0026#34; ] } Create a file called .drone.yml (this is the file that will run on a schedule to actually run Renovate) Below is my .drone.yml file --- kind: pipeline type: docker name: renovate trigger: event: - cron - push - custom environment: LOG_LEVEL: debug steps: - name: renovate - validate config image: renovate/renovate:33.2.0 # https://github.com/renovatebot/renovate/discussions/15049 commands: - unset GIT_COMMITTER_NAME GIT_COMMITTER_EMAIL GIT_AUTHOR_NAME GIT_AUTHOR_EMAIL - renovate-config-validator - name: renovate image: renovate/renovate:33.2.0 # https://github.com/renovatebot/renovate/discussions/15049 commands: - unset GIT_COMMITTER_NAME GIT_COMMITTER_EMAIL GIT_AUTHOR_NAME GIT_AUTHOR_EMAIL - renovate environment: RENOVATE_TOKEN: from_secret: RENOVATE_TOKEN GITHUB_COM_TOKEN: from_secret: GITHUB_COM_TOKEN Drone steps Login to Drone as the renovate user (you\u0026rsquo;ll have to authorize the application)\nGo to renovate-config--\u0026gt;Settings--\u0026gt;Secrets and click on New Secret\nAdd a secret called GITHUB_COM_TOKEN with the value of the GitHub PAT Add a secret called RENOVATE_TOKEN with the value of the renovate user\u0026rsquo;s Gitea PAT Go to renovate-config--\u0026gt;Settings--\u0026gt;Cron Jobs and click on New Cron Job\nAdd an hourly cron job using @hourly This is how to specify how often to run Renovate More Gitea steps Renovate comes with a built-in Docker Compose manager, so it can automatically find any compose files using the regex below.\n(^|/)(?:docker-)?compose[^/]*\\.ya?ml$ Now we need a target repository we want to run Renovate against. This is the example repository I\u0026rsquo;m using, called logan/docker. It contains the following:\na directory for docker apps that I don\u0026rsquo;t use anymore (apps_old) a directory for docker apps that I currently use (docker_app_host) a .drone.yml file (used for linting my docker-compose.yml files) a renovate.json file . ‚îú‚îÄ‚îÄ apps_old ‚îÇ¬†‚îú‚îÄ‚îÄ app1 ‚îÇ¬†‚îÇ¬†‚îî‚îÄ‚îÄ docker-compose.yml ‚îÇ¬†‚îú‚îÄ‚îÄ app2 ‚îÇ¬†‚îÇ¬†‚îî‚îÄ‚îÄ docker-compose.yml ‚îÇ¬†‚îî‚îÄ‚îÄ app3 ‚îÇ¬†‚îî‚îÄ‚îÄ docker-compose.yml ‚îú‚îÄ‚îÄ docker_app_host ‚îÇ¬†‚îú‚îÄ‚îÄ app1 ‚îÇ¬†‚îÇ¬†‚îî‚îÄ‚îÄ docker-compose.yml ‚îÇ¬†‚îú‚îÄ‚îÄ app2 ‚îÇ¬†‚îÇ¬†‚îî‚îÄ‚îÄ docker-compose.yml ‚îÇ¬†‚îî‚îÄ‚îÄ app3 ‚îÇ¬†‚îî‚îÄ‚îÄ docker-compose.yml ‚îú‚îÄ‚îÄ .drone.yml ‚îî‚îÄ‚îÄ renovate.json Just need to change a few settings:\nAdd renovate collaborator to repository\nIn the target repository, go to Settings--\u0026gt;Collaborators and add the renovate user (this will allow renovate to open pull requests) Add renovate.json\nUpon first run, Renovate will open a pull request with a basic renovate.json file, but I\u0026rsquo;ve provided an example below of mine (notice how I\u0026rsquo;m ignoring the path apps_old, you can leave that off if you don\u0026rsquo;t need it) { \u0026#34;$schema\u0026#34;: \u0026#34;https://docs.renovatebot.com/renovate-schema.json\u0026#34;, \u0026#34;extends\u0026#34;: [ \u0026#34;config:base\u0026#34; ], \u0026#34;dependencyDashboard\u0026#34;: true, \u0026#34;dependencyDashboardTitle\u0026#34;: \u0026#34;Renovate Dashboard\u0026#34;, \u0026#34;labels\u0026#34;: [\u0026#34;renovatebot\u0026#34;], \u0026#34;docker-compose\u0026#34;: { \u0026#34;ignorePaths\u0026#34;: [\u0026#34;apps_old\u0026#34;] }, \u0026#34;hostRules\u0026#34;: [ { \u0026#34;matchHost\u0026#34;: \u0026#34;docker.io\u0026#34;, \u0026#34;concurrentRequestLimit\u0026#34;: 2 } ] } First run Up until now, Renovate has probably been running as you\u0026rsquo;ve been making changes, but it has probably failed a few times due to missing keys or permissions.\nLogin to Drone as the renovate user and click on New Build in the top-right, and you should see Renovate run and (hopefully) succeed.\nIf not, the .drone.yml file I\u0026rsquo;ve provided above has LOG_LEVEL: debug set, which means you should be able to search in Drone\u0026rsquo;s run logs to find errors.\nWith the cronjob setup, Renovate will run on your schedule and open pull requests as it finds outdated dependencies.\nCaveats of self-hosting Continuous runs As I mentioned at the beginning, when running Renovate as a GitHub app, it runs continuously in the background. Any time you make a change, Renovate sees it and runs automatically. However, when you self-host Renovate, you need to run Renovate on a schedule (which is why we setup a Drone cronjob).\nSome features of Renovate, like the check boxes on the Dependency Dashboard, only apply when Renovate runs. For example, if you\u0026rsquo;re using the hosted Renovate GitHub app and click a checkbox on the Dependency Dashboard, Renovate will pickup that change almost immediately. However, if you\u0026rsquo;re self-hosting Renovate, the checkbox won\u0026rsquo;t do anything until Renovate runs (whether you run it manually in Drone or it runs via cron).\nRate-limiting When self-hosting, you don\u0026rsquo;t want to run Renovate too often, as you\u0026rsquo;ll probably hit a rate limit from some service (GitHub, Docker Hub, etc\u0026hellip;). In my case, I hit the Docker Hub rate limit pretty quickly by running builds every hour.\nIn November 2020, Docker introduced rate limiting to Docker Hub. It limits (by IP address) anonymous pulls to 100 per six hours, and authenticated pulls to 200 per six hours. I had 20+ docker-compose.yml files (each with multiple container images) in my initial Renovate pull request, and I kept hitting the error below.\n\u0026#34;response\u0026#34;: { \u0026#34;statusCode\u0026#34;: 429, \u0026#34;statusMessage\u0026#34;: \u0026#34;Too Many Requests\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;{\\n \\\u0026#34;errors\\\u0026#34;: [\\n {\\n \\\u0026#34;code\\\u0026#34;: \\\u0026#34;TOOMANYREQUESTS\\\u0026#34;,\\n \\\u0026#34;message\\\u0026#34;: \\\u0026#34;You have reached your pull rate limit. You may increase the limit by authenticating and upgrading: https://www.docker.com/increase-rate-limit\\\u0026#34;\\n }\\n ]\\n}\\n\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;cache-control\u0026#34;: \u0026#34;no-cache\u0026#34;, \u0026#34;content-type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;connection\u0026#34;: \u0026#34;close\u0026#34; }, \u0026#34;httpVersion\u0026#34;: \u0026#34;1.1\u0026#34;, \u0026#34;retryCount\u0026#34;: 2 } If you hit the Docker Hub rate limit, these are your options:\nTry to use some images from an alternative container registry (e.g., GHCR or Quay.io) Create a Docker account and login (example config.js below) A free Docker account will get you 200 pulls per six hours A paid Docker account at $5/month will get you 5000 pulls per day module.exports = { hostRules: [ { hostType: \u0026#39;docker\u0026#39;, username: \u0026#39;\u0026lt;your-username\u0026gt;\u0026#39;, password: process.env.DOCKER_HUB_PASSWORD, }, ], }; Run your Drone cronjob less-often or create a custom cronjob Setup a proxy registry and pull your images from there Add a concurrent request limit to docker.io (example renovate.json snippet below) \u0026#34;hostRules\u0026#34;: [ { \u0026#34;matchHost\u0026#34;: \u0026#34;docker.io\u0026#34;, \u0026#34;concurrentRequestLimit\u0026#34;: 2 } ] Docker image size The renovate/renovate Docker image is about 1.5GB in size (compressed). If you don\u0026rsquo;t pin to a specific tag (like 33.2.0), you\u0026rsquo;ll waste a lot of space downloading the latest tag over and over again.\nThere is a slim tag, but it only contains Node.js, so if you need anything else (Docker, Python, Java, etc\u0026hellip;), it won\u0026rsquo;t work.\nUse Renovate to update Renovate Obviously, since we pinned the Renovate image to 33.2.0, we\u0026rsquo;ll need to also put a renovate.json file in our renovate/renovate-config Gitea repository to use Renovate to keep Renovate updated.\nConclusion I\u0026rsquo;ve been using Renovate for about a week now and really like it. It\u0026rsquo;s obviously a much smoother experience running on GitHub than self-hosted, but it\u0026rsquo;s enough to really make a difference in my workflow already.\nAlso, I highly recommend checking out these article for more tips on getting Renovate setup:\nJerry Ng: 12 Tips to Self-host Renovate Bot Marius Shekow: Renovate bot cheat sheet ‚Äì the 11 most useful customizations -Logan\n","permalink":"https://loganmarchione.github.io/2022/10/how-to-run-renovate-on-a-self-hosted-gitea-and-drone-instance/","summary":"Introduction I recently started using Mend\u0026rsquo;s Renovate bot to keep my dependencies up-to-date on my GitHub projects. GitHub already has tool for this called Dependabot, but it only works with GitHub. Renovate is much more flexible, and it\u0026rsquo;s also open-source, so it can run on other Git platforms, like my self-hosted Gitea and Drone instance at home.\nHowever, self-hosting Renovate is more difficult because the hosted version takes care of a lot of the \u0026ldquo;magic\u0026rdquo; for you, so it \u0026ldquo;just works\u0026rdquo;.","title":"How to run Renovate on a self-hosted Gitea and Drone instance"},{"content":"Introduction I spend a lot of time on Reddit in r/devops, r/homelab, and r/selfhosted, where I always see different versions of the same question:\nIt\u0026rsquo;s difficult to get hands-on experience in DevOps. What is a good beginner project?\nI\u0026rsquo;ve posted this answer to Reddit multiple times before, but this post will have more detail.\nStatic site Build a static site. That\u0026rsquo;s the answer.\nWhy A static site is a great beginner project because:\nThis is a great chance to finally purchase yourname.com You can put whatever you want on a website (blog/resume/portfolio/business/etc\u0026hellip;) You learn how websites works (e.g., domain names, DNS, web hosting, certificates) You learn how \u0026ldquo;the cloud\u0026rdquo; works (on a basic level) You learn infrastructure-as-code (IaC) with Terraform You learn configuration management with Ansible You learn how a static site generator works (you might even learn some HTML/CSS/JS) You learn how Git works You learn continuous integration and continuous delivery (CI/CD) with GitHub Actions How Below is my outline on the general steps to setup a static site. You don\u0026rsquo;t need to follow it exactly, but it should be more than enough to get you started.\nPurchase a domain This can\u0026rsquo;t be done via IaC I like Hover, but you can also use Cloudflare, Namecheap, AWS, etc\u0026hellip; If this is a personal site, try to get a .com TLD, not .net, .io, .ai, etc\u0026hellip; Create a GitHub account and two repositories One for your IaC code (Terraform and Ansible) One for your static site\u0026rsquo;s code Provision a virtual private server (VPS) in the cloud using Terraform Use any VPS provider that has Terraform support (DigitalOcean or AWS would be my recommendations, but you can also use Linode, OVH, Oracle Cloud, Scaleway, etc\u0026hellip;) This code should be checked into Git on GitHub Bonus: Don\u0026rsquo;t hard-code your API keys anywhere in your Terraform code Bonus: You can store your state locally (don\u0026rsquo;t check it into Git), but consider storing it remotely (HashiCorp offers free state storage in Terraform Cloud) Bonus: Use Atlantis with your GitHub account to run Terraform via pull requests to GitHub Setup DNS using Terraform After you get the IP of your VPS, you need DNS to link yourname.com to 1.2.3.4 You can use a separate DNS provider (like Cloudflare, NS1, or DNSimple ), but your VPS provider might also offer DNS (e.g., DigitalOcean, AWS Route53, Linode, Scaleway, etc\u0026hellip;) This code should be checked into Git on GitHub Configure the VPS using Ansible After the VPS is online, you need to login, install updates, setup users, install packages, mess with configuration files, etc\u0026hellip; At the very least, you\u0026rsquo;ll need a webserver installed (e.g., Nginx or Apache) and a few configuration files for your webserver put in the correct places This code should be checked into Git on GitHub Bonus: Get a TLS certificate for free from Let\u0026rsquo;s Encrypt and configure your webserver to redirect from port 80 to 443 Bonus: Learn what idempotency means Bonus: Instead of making one big playbook, try to use roles Create the static site locally on your PC You\u0026rsquo;ll have to choose a static site generator (here is a good list of options) I like Hugo, but the choice is yours (consider things like speed, available themes, the language the templates are written in, plugins, if you\u0026rsquo;re migrating from another data source, etc\u0026hellip;) Make sure the site builds locally on your PC and you can visit it on localhost This code should be checked into Git on GitHub Deploy the site to your VPS using Setup GitHub Actions You need to automate deploying your static site\u0026rsquo;s rendered code from GitHub to your VPS This automation needs to happen on some sort of trigger (e.g., on each commit to Git, on a schedule, on a tag, etc\u0026hellip;) Bonus: Use GitHub Actions to lint your Terraform code with tflint and Ansible code with ansible-lint Bonus: Setup a free GitHub Pages domain at yourname.github.io and push a dev/test version of your site to there Cost In my setup, I\u0026rsquo;m spending $66/year on my site and the surrounding infrastructure.\nProduct Cost (per year) Domain name (Hover) $12 DNS (Route53) $6 VPS (DigitalOcean) $48 However, there are some cost-cutting measures that are possible:\nDNS: Use a free provider like Cloudflare or NS1 Hosting: Use a static-site host like GitHub Pages or Netlify Keep in mind that moving to a dedicated static-site host would remove the VPS from the setup above, and thus remove all reason to use Ansible in your setup (less to manage, but also less to learn).\nConclusion The setup above is more than enough to put on a resume, but it definitely lacks a few things:\nDatabase API Load balancing Containers/K8s However, in my mind, those things are not great for a beginner project, but for something more intermediate-level (for that kind of project, check out the The Cloud Resume Challenge or roadmap.sh).\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/10/the-best-devops-project-for-a-beginner/","summary":"Introduction I spend a lot of time on Reddit in r/devops, r/homelab, and r/selfhosted, where I always see different versions of the same question:\nIt\u0026rsquo;s difficult to get hands-on experience in DevOps. What is a good beginner project?\nI\u0026rsquo;ve posted this answer to Reddit multiple times before, but this post will have more detail.\nStatic site Build a static site. That\u0026rsquo;s the answer.\nWhy A static site is a great beginner project because:","title":"The best DevOps project for a beginner"},{"content":"Introduction This post serves no real purpose other than to match SEO keywords for people searching for PCIe WiFi cards for Linux.\nMy desktop is on the third floor of my house, unfortunately without wired internet. I\u0026rsquo;ve been using a PCIe 802.11n (WiFi 4) card since 2016 and realized it\u0026rsquo;s time to upgrade.\nTP-Link TL-WDN4800\nQualcomm Atheros AR9380 chipset 802.11a - 54Mbps 802.11b - 11Mbps 802.11g - 54Mbps 802.11n - 450Mbps (WiFi 4) WPA/WPA2 Comparison My access point is a UniFi UAP-AC-PRO, so at the very least, I wanted 802.11ac (WiFi 5) on the PCIe card. I also knew I wanted to stick with Intel wireless cards, since their drivers are generally available in every Linux distribution (even if they\u0026rsquo;re blobs).\nI considered purchasing this Silverstone PCIe\u0026ndash;\u0026gt;M.2 adapter and the Intel AX200 M.2 card, but was too lazy and wanted a complete product.\nI considered the cards below, but they all had external antennas, which I didn\u0026rsquo;t want.\nGigabyte GC-WBAX210 (WiFi 6E using Intel AX210) Gigabyte GC-WBAX200 (WiFi 6 using Intel AX200) Asus PCE-AXE58BT (WiFi 6E using Intel AX210) Asus PCE-AX58BT (WiFi 6 using Intel AX200) Ultimately, I went with the Asus PCE-AX3000, which has built-in antennas. It has WiFi 6, so I could upgrade my AP later and take advantage of better speeds. It also has Bluetooth, which I didn\u0026rsquo;t connect.\nIntel AX200 chipset 802.11a - 54Mbps 802.11b - 11Mbps 802.11g - 54Mbps 802.11n - 300Mbps (WiFi 4) 802.11ac - 1733Mbps (WiFi 5) 802.11ax - 2402Mbps (WiFi 6) WPA/WPA2/WPA3 Bluetooth 5.0 Speed test Keep in mind my connection to the internet is 400/400Mbps Verizon FiOS. I\u0026rsquo;m also on the third floor of my house, with the AP on the first floor.\nBelow is the TP-Link TL-WDN4800.\nBelow is the Asus PCE-AX3000.\nConclusion Needless to say, I\u0026rsquo;m very happy with the Asus card!\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/09/asus-pce-ax3000-on-linux/","summary":"Introduction This post serves no real purpose other than to match SEO keywords for people searching for PCIe WiFi cards for Linux.\nMy desktop is on the third floor of my house, unfortunately without wired internet. I\u0026rsquo;ve been using a PCIe 802.11n (WiFi 4) card since 2016 and realized it\u0026rsquo;s time to upgrade.\nTP-Link TL-WDN4800\nQualcomm Atheros AR9380 chipset 802.11a - 54Mbps 802.11b - 11Mbps 802.11g - 54Mbps 802.11n - 450Mbps (WiFi 4) WPA/WPA2 Comparison My access point is a UniFi UAP-AC-PRO, so at the very least, I wanted 802.","title":"Asus PCE-AX3000 on Linux"},{"content":"Hey! Listen! This post is part of a series on 10\u0026quot; mini-racks. Check them all out!\nDate URL Part 2022-09-16 Homelab 10\u0026quot; mini-rack shelves Comparison of 10\u0026quot; shelves 2021-01-05 Homelab 10\u0026quot; mini-rack Initial post about mini-rack Introduction ‚ö†Ô∏è WARNING ‚ö†Ô∏è\nThis is an image-heavy post (I have lazy-loading enabled, so images should only load as you scroll) I know that the imperial system of units is inferior to the metric system, but these are 10-inch racks, not 254mm racks ü§∑‚Äç‚ôÇÔ∏è For my measurements, I\u0026rsquo;ve converted fractions (8-11/16) to decimals (8.6875) For the past year-and-a-half, my network stack has lived in my 10-inch mini-rack (not on my countertop, obviously).\nI only had one complaint about my setup. Can you spot it below?\nEach shelf has a lip on the front and back that bends downward (for structural stability), but this takes away from usable height of the shelf. While the ears of the shelf are 1U in height (1.75-inches), there is less than 1.50-inches of usable shelf height to work with. I could load taller items into the shelf, but they would need to be loaded in from the back (to get around the lip).\nMy Netgear switch fit in this space, but I was looking to replace it with a UniFi Switch Lite 16 PoE, which is 1.72-inches tall.\nRack standards 19-inch racks 19-inch racks are the most common. They measure:\n19-inches wide (including the ears) 18-5/16 (18.3125) inches center-to-center on post holes 17-3/4 (17.75) inches opening width between posts Image (with misspelling) from PureStorage\n10-inch racks The 10-inch rack (aka \u0026ldquo;half-rack\u0026rdquo;) isn\u0026rsquo;t a standard (that I could find). Instead, it\u0026rsquo;s more like a general consensus (kind of like we\u0026rsquo;ve unofficially settled on two sizes of toilet seat lid). As such, all equipment advertised as 10-inches or half-rack might not be compatible.\nImage from Wikipedia\n10-inch racks are much more common outside the US (I\u0026rsquo;m not sure why). There are tons of companies selling 10-inch racks and accessories outside the US.\nCablematic (Spain) NetwerkKabel (Netherlands) ServerRack24 (Netherlands) RackMagic (Germany) Intellinet (Germany) Conrad (Germany - reseller) CommsOnline (UK) DataCabinetsDirect (UK) Network-Cabs (UK) All Metal Parts (UK) Rack Store Online (UK) DigitX (Italy) Techly (Italy) Telrex (Australia) CableHUB (Australia) Inside the US, however, the only 10-inch racks and accessories I could find were specifically for audio/video applications, so I\u0026rsquo;m assuming that form-factor is more popular in the audio/video space (again, I\u0026rsquo;m not sure why). But, because it\u0026rsquo;s a niche product segment, the prices were higher than I expected.\nFull Compass Legrand AV (Middle Atlantic) Vintage King Sweetwater Lowell Odyssey Shelves I spent way too much time looking at industrial catalogs, obscure websites, and non-English marketplaces (e.g., Alibaba, AliExpress, etc\u0026hellip;).\nI was able to find a few shelves on Amazon and eBay. I tried to only purchase shelves with reasonable shipping costs (e.g., not paying $100 to ship a $30 metal shelf across an ocean). I purchased three shelves (plus the original shelf with the metal lip).\nBrand Part Number Purchase location Price (USD) Price (USD) shipping Shipping time Usable height (in.) Usable width (in.) Usable depth (in.) Center-to-center width (in.) Digitus DN-10-TRAY-1-B eBay $24.20 $8.19 18 days (from IT) 1.625 8.25 5.8125 9.3125 Digitus DN-10-TRAY-2-B Amazon $28.62 Free 10 days (from UK) 1.6875 8.375 7.6875 9.3125 Middle Atlantic HR-UMS1-5.5 eBay $39.99 Free 3 days (from US) 1.6875 8.6875 5.5 9.6875 Intellinet 714839 Amazon $15.95 (at time of purchase in 2021) Free 9 days (from UK) 1.375 8.5 5.8125 9.375 Comparison Below are pictures, in the same order as above.\nDigitus DN-10-TRAY-1-B Digitus DN-10-TRAY-2-B Note that the lip bends upwards (it is .3125-inches tall). This is the deepest shelf. The ears are not bent metal, but are instead welded on, which makes this the most narrow shelf.\nMiddle Atlantic HR-UMS1-5.5 This was \u0026ldquo;new\u0026rdquo; on eBay and arrived bent in half (hence, why it appears not perfectly flat). Also, the center-to-center width of the post holes was slightly wider than the others (by .375-inches total), so I had to loosen all the cage nuts to allow the rack to expand slightly.\nIntellinet 714839 One of the original shelves I purchased in 2021. The lip that I hate.\nConclusion If you want one of these and you\u0026rsquo;re in Europe, lucky you. If you\u0026rsquo;re in the US, your best bet is to scour eBay and Amazon for the phrase \u0026ldquo;half-rack\u0026rdquo; and find options with low/free shipping. Other than that, you can overpay for new audio/video equipment. I\u0026rsquo;ve installed the Middle Atlantic HR-UMS1-5.5, which gives me exactly 1.75-inches to use. I will probably keep my hodgepodge of different shelves as-is for now.\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/09/homelab-10-mini-rack-shelves/","summary":"Hey! Listen! This post is part of a series on 10\u0026quot; mini-racks. Check them all out!\nDate URL Part 2022-09-16 Homelab 10\u0026quot; mini-rack shelves Comparison of 10\u0026quot; shelves 2021-01-05 Homelab 10\u0026quot; mini-rack Initial post about mini-rack Introduction ‚ö†Ô∏è WARNING ‚ö†Ô∏è\nThis is an image-heavy post (I have lazy-loading enabled, so images should only load as you scroll) I know that the imperial system of units is inferior to the metric system, but these are 10-inch racks, not 254mm racks ü§∑‚Äç‚ôÇÔ∏è For my measurements, I\u0026rsquo;ve converted fractions (8-11/16) to decimals (8.","title":"Homelab 10\" mini-rack shelves"},{"content":"Hey! Listen! This post is part of a series on the DeskMini H470 as a hypervisor. Check them all out!\nDate URL Part 2022-09-07 Adding a ZFS mirror to Proxmox Add a ZFS mirror to Proxmox 2022-09-02 Adding data center SSDs to the DeskMini H470 Add 2x Intel D3-S4510 to the DeskMini H470 2021-06-23 ASRock DeskMini H470 as a compact hypervisor Initial post about DeskMini H470 Introduction In my last post, I added two Intel D3-S4510 960 SSDs to my ASRock DeskMini H470 running Proxmox. I also upgraded the firmware, as well as ran some basic tests on the drives. In this post, I\u0026rsquo;ll be creating a ZFS mirror and adding it to Proxmox.\nZFS ‚ö†Ô∏è WARNING ‚ö†Ô∏è\nThis was my first time using ZFS I am not a ZFS expert Don\u0026rsquo;t blindly follow my instructions Almost all of my ZFS knowledge came from this ArsTechnica article, Jim Salter\u0026rsquo;s blog, and this article. Create mirror Using the GUI, you can create the mirror and add it to Proxmox in one step. However, I\u0026rsquo;m specifically looking to add one extra thing that is not in the GUI, so I\u0026rsquo;m using the CLI.\nStart by creating the mirror.\nzpool create -f -o ashift=12 intel_mirror mirror /dev/disk/by-id/xxxxxx /dev/disk/by-id/yyyyyy In the command above, it\u0026rsquo;s important that ashift be the correct size (that\u0026rsquo;s why I had to find the sector size in the last post). It generally won\u0026rsquo;t hurt if ashift is too big, but if it\u0026rsquo;s too small (the default is 9), there will definitely be some performance impact as the drive will do write amplification to fill a 4096B sector with 512B writes. For most modern SSDs, ashift=12 is what you probably want. Oh, and you can\u0026rsquo;t change this setting without destroying the mirror, so no pressure.\nashift=9 (2^9) = 512B sectors ashift=10 (2^10) = 1024B sectors ashift=11 (2^11) = 2048B sectors ashift=12 (2^12) = 4096B sectors ashift=13 (2^13) = 8192B sectors Here, I\u0026rsquo;m turning on compression and relatime (the option that is not in the GUI).\nzfs set compression=lz4 intel_mirror zfs set atime=on intel_mirror zfs set relatime=on intel_mirror Check the status of the mirror and the settings.\nzpool status zfs get all intel_mirror | grep \u0026#39;compression\\|atime\u0026#39; Extras I didn\u0026rsquo;t cover them here (because everyone\u0026rsquo;s setup might be different), but below were some extra ZFS-related things I had to take care of.\nSetup email notifications for ZED (ZFS Event Daemon) Set an email for the root user (Datacenter--\u0026gt;Permissions--\u0026gt;Users--\u0026gt;root--\u0026gt;Edit) Ensure the correct email/user is set in /etc/zfs/zed.d/zed.rc (you can probably leave root) Setup Postfix to send to a SMTP server (e.g., I\u0026rsquo;m using an external SMTP server) Test email (echo -e \u0026quot;Subject: Test\\n\\nThis is a test\u0026quot; | /usr/bin/pvemailforward) Make sure there is a ZFS scrub cronjob (cat /etc/cron.d/zfsutils-linux) Make sure there is enough RAM for ZFS, as it will use up to 50% of the host\u0026rsquo;s RAM for ARC. You can change how much is used for ARC, but keep in mind that you\u0026rsquo;ll see increased RAM usage when you activate ZFS. Proxmox Add storage to Proxmox Add the storage to Proxmox and set the content type to VM images and container root directories.\npvesm add zfspool intel_mirror -pool intel_mirror pvesh set /storage/intel_mirror -content images,rootdir In the GUI, under Datacenter--\u0026gt;node_name--\u0026gt;Disks--\u0026gt;ZFS, you should see the mirror.\nUnder Datacenter--\u0026gt;Storage, you should see the mirror with the correct content types set.\nMigrate VMs/CTs Shutdown all VMs/CTs that you intend to move to the new storage pool. In the VM Hardware menu (or CT Resources menu), select the disk, then click on Disk Action, then Move Storage (you can\u0026rsquo;t move a VM/CT disk to another storage if you have snapshots).\nThen, select the new ZFS mirror.\nBy default, the source disk is added as an \u0026ldquo;unused disk\u0026rdquo; for safety. If you don\u0026rsquo;t want this, you can select the Delete source box.\nFor me, an 8GB VM disk took 1 minute to move, and a 55GB VM disk took 8 minutes to move.\nConclusion I moved three VMs and am going to give them a few days before moving the rest of my VMs/CTs. So far, so good. ü§∑‚Äç‚ôÇÔ∏è\nI will also experiment with alerting scripts for ZFS and possibly a cronjob to send me the output of zpool status and smartctl -a /dev/sdX once a month.\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/09/adding-a-zfs-mirror-to-proxmox/","summary":"Hey! Listen! This post is part of a series on the DeskMini H470 as a hypervisor. Check them all out!\nDate URL Part 2022-09-07 Adding a ZFS mirror to Proxmox Add a ZFS mirror to Proxmox 2022-09-02 Adding data center SSDs to the DeskMini H470 Add 2x Intel D3-S4510 to the DeskMini H470 2021-06-23 ASRock DeskMini H470 as a compact hypervisor Initial post about DeskMini H470 Introduction In my last post, I added two Intel D3-S4510 960 SSDs to my ASRock DeskMini H470 running Proxmox.","title":"Adding a ZFS mirror to Proxmox"},{"content":"Hey! Listen! This post is part of a series on the DeskMini H470 as a hypervisor. Check them all out!\nDate URL Part 2022-09-07 Adding a ZFS mirror to Proxmox Add a ZFS mirror to Proxmox 2022-09-02 Adding data center SSDs to the DeskMini H470 Add 2x Intel D3-S4510 to the DeskMini H470 2021-06-23 ASRock DeskMini H470 as a compact hypervisor Initial post about DeskMini H470 Introduction Last year, I setup the ASRock DeskMini H470 as a compact hypervisor running Proxmox. During setup, I only installed a single NVMe SSD. However, I specifically chose the DeskMini H470 because it had space for more drives, which I knew I would eventually want to make use of. Today is that day.\nCurrent configuration The DeskMini H470 has the following storage options:\n2x SATA 6Gb 2.5-inch 7mm/9.5mm 1x M.2 Socket 2280 PCIe Gen3 (my NVMe SSD is installed here) 1x M.2 Socket 2280 PCIe Gen4 (requires an 11th Gen Intel CPU, which I don\u0026rsquo;t have) Currently, my only storage in the DeskMini H470 is a single Samsung 970 Pro 512GB NVMe SSD.\nBy default, Proxmox uses 25% of the disk for root storage, 12.5% of the disk for swap (max 8GB), then the rest for LVM storage (mainly for VMs/CTs). Below is my current partition layout. Note that backups, ISOs, and container templates are stored on a physically separate NAS, so their storage is not taken into account here.\nNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT nvme0n1 259:0 0 476.9G 0 disk ‚îú‚îÄnvme0n1p1 259:1 0 1007K 0 part ‚îú‚îÄnvme0n1p2 259:2 0 512M 0 part /boot/efi ‚îî‚îÄnvme0n1p3 259:3 0 476.4G 0 part ‚îú‚îÄpve-swap 253:0 0 8G 0 lvm [SWAP] ‚îú‚îÄpve-root 253:1 0 96G 0 lvm / ‚îú‚îÄpve-data_tmeta 253:2 0 3.6G 0 lvm ‚îÇ ‚îî‚îÄpve-data-tpool 253:4 0 349.3G 0 lvm ‚îÇ ‚îú‚îÄpve-data 253:5 0 349.3G 1 lvm ‚îÇ ‚îú‚îÄpve-vm--105--disk--0 253:6 0 4M 0 lvm ‚îÇ ‚îú‚îÄpve-vm--105--disk--1 253:7 0 16G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--100--disk--0 253:8 0 55G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--112--disk--0 253:9 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--101--disk--0 253:10 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--111--disk--0 253:11 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--113--disk--0 253:12 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--102--disk--0 253:13 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--106--disk--0 253:14 0 65G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--103--disk--0 253:15 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--104--disk--0 253:16 0 8G 0 lvm ‚îÇ ‚îî‚îÄpve-vm--104--disk--1 253:17 0 75G 0 lvm ‚îî‚îÄpve-data_tdata 253:3 0 349.3G 0 lvm ‚îî‚îÄpve-data-tpool 253:4 0 349.3G 0 lvm ‚îú‚îÄpve-data 253:5 0 349.3G 1 lvm ‚îú‚îÄpve-vm--105--disk--0 253:6 0 4M 0 lvm ‚îú‚îÄpve-vm--105--disk--1 253:7 0 16G 0 lvm ‚îú‚îÄpve-vm--100--disk--0 253:8 0 55G 0 lvm ‚îú‚îÄpve-vm--112--disk--0 253:9 0 8G 0 lvm ‚îú‚îÄpve-vm--101--disk--0 253:10 0 8G 0 lvm ‚îú‚îÄpve-vm--111--disk--0 253:11 0 8G 0 lvm ‚îú‚îÄpve-vm--113--disk--0 253:12 0 8G 0 lvm ‚îú‚îÄpve-vm--102--disk--0 253:13 0 8G 0 lvm ‚îú‚îÄpve-vm--106--disk--0 253:14 0 65G 0 lvm ‚îú‚îÄpve-vm--103--disk--0 253:15 0 8G 0 lvm ‚îú‚îÄpve-vm--104--disk--0 253:16 0 8G 0 lvm ‚îî‚îÄpve-vm--104--disk--1 253:17 0 75G 0 lvm Goals Without having to reinstall Proxmox, the easiest way to add storage was to add 2x SATA SSDs. My goals were to:\nInstall two SSDs into my case Verify the SSDs work, firmware is up to date, etc\u0026hellip; Setup a ZFS mirror of the two disks Move my VMs/CTs to that storage (this will leave only Proxmox on the 970 Pro) I\u0026rsquo;ll be covering the former two steps in this post, and the latter in another.\nDisks Disk selection I spent way too much time deciding on SSDs. I knew I wanted enterprise-grade SSDs, which have power-loss protection and are generally rated for more writes than consumer SSDs. However, enterprise-grade SSDs are hard to find new on sale to the general public. Although I did look on eBay, I wanted the warranty that came with a new drive. Below were my options (for comparision, I added the 970 Pro to the list).\nMake Model Year introduced NAND type IOPS (4K read) IOPS (4K write) Mean Time Between Failures (MTBF) Endurance Rating (Lifetime Writes) Price Intel D3-S4510 960GB Q3'18 64-layer TLC 3D NAND 95k 36k 2 million hours 3.5 PBW $265 @ Newegg, $261 @ B\u0026amp;H Intel D3-S4610 960GB Q3'18 64-layer TLC 3D NAND 96k 51k 2 million hours 5.8 PBW $351 @ Insight Intel D3-S4520 960GB Q3'21 144-layer TLC 3D NAND 90k 43k 2 million hours 5.3 PBW $285 @ Insight Samsung PM893 960GB Q1'21 128-layer TLC V-NAND 98k 30k 2 million hours 1.752 PBW $171 @ SuperMicro, $218 @ CDW Samsung 970 Pro 512GB Q3'18 64-layer MLC V-NAND 370k 500k 1.5 million hours 0.6 PBW $149 (at time of purchase in 2021) In the end, I ended up choosing the Intel D3-S4510 960GB, as it came recommended on multiple forums. I would have preferred the D3-S4610 960GB (since it\u0026rsquo;s more write-intensive), but I wasn\u0026rsquo;t 100% sure if Insight was selling new drives or not (conflicting reports on Reddit).\nPhysical installation The physical installation was easy enough, although I did need to remove the motherboard from the tray to access the screws. Also, ASRock uses a propriety SATA cable for these ultra-tiny connectors.\nIdentify disks The basic smoke test was to make sure the disks worked and showed up to the kernel.\nls -la /dev/disk/by-id/ | grep sd I ran lshw -class disk, but you could also use hwinfo --disk to see similiar info. We\u0026rsquo;re looking for the sectorsize, which will be important later when we setup ZFS.\nroot@proxmox02:~# lshw -class disk *-disk:0 description: ATA Disk product: INTEL SSDSC2KB96 physical id: 0 bus info: scsi@2:0.0.0 logical name: /dev/sda version: 0132 serial: XXXXXXXXXXXXXXXXXX size: 894GiB (960GB) configuration: ansiversion=5 logicalsectorsize=512 sectorsize=4096 *-disk:1 description: ATA Disk product: INTEL SSDSC2KB96 physical id: 1 bus info: scsi@3:0.0.0 logical name: /dev/sdb version: 0132 serial: XXXXXXXXXXXXXXXXXX size: 894GiB (960GB) configuration: ansiversion=5 logicalsectorsize=512 sectorsize=4096 Firmware In 2018, Intel identified a bug in the 1.92TB and 3.84TB models that caused the SSDs to \u0026ldquo;hang\u0026rdquo; after 1700 hours of power-on time. Even though my drives were not affected, I wanted to make sure the firmware was up-to-date.\nLVFS I tried using LVFS, but Intel/Solidigm don\u0026rsquo;t seem to be contributing a ton of firmware files (compared to vendors like Dell and Lenovo).\nsudo apt -y install fwupd fwupdmgr get-devices fwupdmgr get-updates I kept receiving this.\nNo updatable devices Solidigm Storage Tool Intel sold their NAND flash business to SK Hynix (under the name Solidigm) in November 2020, so I used the Solidigm Storage Tool to update the firmware.\nI followed this guide to install the tool and this guide to use it. The firmware is built into the tool, so there are no external downloads.\nI started by identifying my SSDs (my 970 Pro was SSD 0 in this case).\nsst show -ssd sst show -ssd 1 sst show -ssd 2 From the output above, I was able to see the firmware on each device was out of date.\nFirmware : XCV10132 FirmwareUpdateAvailable : XCV10140 I checked a few sensors and SMART data to make sure the drives were healthy.\nsst show -sensor -ssd 1 sst show -sensor -ssd 2 sst show -smart -ssd 1 sst show -smart -ssd 2 Then, I finally updated the firmware.\nsst load -ssd 1 Once successful, I saw the message below, repeated with the second drive, then rebooted.\nStatus : Firmware updated successfully. Please reboot the system. Now, checking the status, I could see the firmware was up-to-date.\nFirmware : XCV10140 FirmwareUpdateAvailable : The selected drive contains current firmware as of this tool release. I also kicked off SMART tests to double-check the drives.\nsudo smartctl -t long /dev/sda sudo smartctl -t long /dev/sdb Conclusion That\u0026rsquo;s it for now. Below is my new current configuration (see the two drives at the top). In my next post, I\u0026rsquo;ll be setting up a ZFS pool and moving my VMs/CTs to that storage.\nNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 894.3G 0 disk sdb 8:16 0 894.3G 0 disk nvme0n1 259:0 0 476.9G 0 disk ‚îú‚îÄnvme0n1p1 259:1 0 1007K 0 part ‚îú‚îÄnvme0n1p2 259:2 0 512M 0 part /boot/efi ‚îî‚îÄnvme0n1p3 259:3 0 476.4G 0 part ‚îú‚îÄpve-swap 253:0 0 8G 0 lvm [SWAP] ‚îú‚îÄpve-root 253:1 0 96G 0 lvm / ‚îú‚îÄpve-data_tmeta 253:2 0 3.6G 0 lvm ‚îÇ ‚îî‚îÄpve-data-tpool 253:4 0 349.3G 0 lvm ‚îÇ ‚îú‚îÄpve-data 253:5 0 349.3G 1 lvm ‚îÇ ‚îú‚îÄpve-vm--105--disk--0 253:6 0 4M 0 lvm ‚îÇ ‚îú‚îÄpve-vm--105--disk--1 253:7 0 16G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--100--disk--0 253:8 0 55G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--112--disk--0 253:9 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--101--disk--0 253:10 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--111--disk--0 253:11 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--113--disk--0 253:12 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--102--disk--0 253:13 0 8G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--106--disk--0 253:14 0 65G 0 lvm ‚îÇ ‚îú‚îÄpve-vm--103--disk--0 253:15 0 8G 0 lvm ‚îÇ ‚îî‚îÄpve-vm--104--disk--0 253:16 0 8G 0 lvm ‚îî‚îÄpve-data_tdata 253:3 0 349.3G 0 lvm ‚îî‚îÄpve-data-tpool 253:4 0 349.3G 0 lvm ‚îú‚îÄpve-data 253:5 0 349.3G 1 lvm ‚îú‚îÄpve-vm--105--disk--0 253:6 0 4M 0 lvm ‚îú‚îÄpve-vm--105--disk--1 253:7 0 16G 0 lvm ‚îú‚îÄpve-vm--100--disk--0 253:8 0 55G 0 lvm ‚îú‚îÄpve-vm--112--disk--0 253:9 0 8G 0 lvm ‚îú‚îÄpve-vm--101--disk--0 253:10 0 8G 0 lvm ‚îú‚îÄpve-vm--111--disk--0 253:11 0 8G 0 lvm ‚îú‚îÄpve-vm--113--disk--0 253:12 0 8G 0 lvm ‚îú‚îÄpve-vm--102--disk--0 253:13 0 8G 0 lvm ‚îú‚îÄpve-vm--106--disk--0 253:14 0 65G 0 lvm ‚îú‚îÄpve-vm--103--disk--0 253:15 0 8G 0 lvm ‚îî‚îÄpve-vm--104--disk--0 253:16 0 8G 0 lvm -Logan\n","permalink":"https://loganmarchione.github.io/2022/09/adding-data-center-ssds-to-the-deskmini-h470/","summary":"Hey! Listen! This post is part of a series on the DeskMini H470 as a hypervisor. Check them all out!\nDate URL Part 2022-09-07 Adding a ZFS mirror to Proxmox Add a ZFS mirror to Proxmox 2022-09-02 Adding data center SSDs to the DeskMini H470 Add 2x Intel D3-S4510 to the DeskMini H470 2021-06-23 ASRock DeskMini H470 as a compact hypervisor Initial post about DeskMini H470 Introduction Last year, I setup the ASRock DeskMini H470 as a compact hypervisor running Proxmox.","title":"Adding data center SSDs to the DeskMini H470"},{"content":"TL;DR I\u0026rsquo;m frustrated by Mozilla, but don\u0026rsquo;t see many alternative browsers that have such noble goals as Firefox.\nIntroduction I have a confession: I tried really hard to quit Firefox, but I can\u0026rsquo;t.\nI\u0026rsquo;ve been using Firefox since the single-digit release days, and I\u0026rsquo;ve been publishing my Firefox config for five years now. In a recent experiment, I used Brave Browser exclusively for three months, but ended up moving back to Firefox. Here are my thoughts (i.e., a rant) on why I moved, why I moved back, and why I might not be done moving.\nFirefox\u0026rsquo;s rise\u0026hellip; Firefox gained popularity at a time when smartphones were not a thing, Windows XP was still supported, and Internet Explorer (IE) dominated the browser market. Because IE came pre-installed on Windows, it was the browser of choice for most people. Firefox was the only alternative (unless you used a Mac, in which case, you used Safari). At its peak, Firefox was estimated to have around 30% of the global desktop browser market share (see image below) and over 50% in some markets.\nFirefox\u0026rsquo;s fall\u0026hellip; For current reference, here are the stats from July 2022. What happened?\nChrome\u0026rsquo;s dominance In September 2008, Google announced Google Chrome, which exploded in popularity because:\nWeb browsers were slow and Chrome was fast. Google was able to build Chrome completely from scratch (i.e., it had no technical debt like Microsoft\u0026rsquo;s IE), but could borrow tech where needed (e.g., Apple\u0026rsquo;s WebKit engine), and then create tech where needed (e.g., the super-fast V8 Javascript engine). Chrome adhered to web standards (something IE was not known for). Tab sandboxing improved security, but also meant one tab crashing wouldn\u0026rsquo;t kill the entire browser. This also allowed each tab to run in a separate process, which made better use of multi-core CPUs. Google open-sourced Chromium (Google Chrome\u0026rsquo;s base). The tragedy of the default Unlike its competitors, Mozilla (the company that makes Firefox) has no platform on which to advertise Firefox:\nMicrosoft pre-installs Edge and can advertise Edge on Microsoft services (e.g., Bing, Office 365, etc\u0026hellip;) Apple pre-installs Safari on all of their devices Google pre-installs Chrome on Android and can advertise Chrome on Google services (e.g., Search, Gmail, etc\u0026hellip;) Most users can\u0026rsquo;t or won\u0026rsquo;t switch away from anything provided by default.\nMozilla Foundation vs Corporation Before we go on, it\u0026rsquo;s important to understand how Mozilla is structured and how they make money. I\u0026rsquo;ve tried to visualize this in an image below (probably best to open it in a new tab), but will spell out some key details here.\n\u0026ldquo;Mozilla\u0026rdquo; is an ambiguous term. The Mozilla Foundation, which is a 501(c)(3) non-profit, owns three for-profit companies:\nMozilla Corporation (they make Firefox) Mozilla China (they promote Mozilla in China) MZLA Technologies Corporation (as-of early 2020, they make Thunderbird) Mitchell Baker, who started at Netscape, is currently the CEO of both Mozilla Foundation (where she makes $0/yr) and Mozilla Corporation (where she makes $2.75m/yr).\nThe Mozilla Foundation only makes money by donations from users (e.g., when you go to this page) and corporations. The Mozilla Foundation uses the money to fund various internet and open source projects. Donations to the Mozilla Foundation do not fund Firefox development because money cannot be given from the Foundation to the Corporations.\nThe Mozilla Corporation does not accept donations from users. Of their $496m in revenue in 2020, 89% came from search deals, with only 5% coming from subscription services (e.g., Mozilla VPN or Pocket) and advertising (on the Firefox homepage).\nMZLA Technologies Corporation takes donations directly from users to fund Thunderbird development.\nSee these documents (one, two, three) for more financial details.\nMozilla\u0026rsquo;s internal problems Mozilla has mismanaged their money and Firefox\u0026rsquo;s development for the better part of a decade. They are clearly struggling to figure out how to make non-Google money, what to do with their current money, and where Firefox fits in.\nSince 2008, Firefox\u0026rsquo;s market share has fallen 85%, but CEO Mitchell Baker\u0026rsquo;s pay rose over 400% in the same time period (when asked directly, she said it would be a financial burden to lower it). I highly recommend reading Cal Paterson\u0026rsquo;s excellent post about the topic (image below from Cal\u0026rsquo;s site). In 2017, Mozilla Corporation spent an unknown amount of money on Pocket, the read-it-later app. In 2020, in an effort to diversify revenue sources, Mozilla Corporation launched Mozilla VPN, which is a rebranded service of Mullvad VPN. In the meantime, Mozilla Corporation laid off 70 employees in January 2020, then another 250 in August 2020. In terms of products, Mozilla appears to have no direction and seems to be throwing shit at a wall and seeing what sticks (hint: none of it sticks). The following projects have been cancelled: Firefox OS, Firefox Send, Firefox Lockwise, Firefox Reality, Mozilla Persona, Mozilla WebThings, Mozilla Webmaker, and more. Mozilla (a small company in a post-COVID world) pays for office space in some of the most expensive cities in the world (San Francisco, Berlin, Beijing, Toronto, etc\u0026hellip;). Why I tried to quit Firefox (and why I went back) I recently met someone who works for Brave, and after some talking, they convinced me to give Brave a try. It had everything I needed (e.g., all of Chromium, mobile apps, plus things like built-in ad-blocking and sync support, etc\u0026hellip;). While generally not a huge fan of cryptocurrencies, I agree with Brave that web advertising is fundamentally broken. I think Basic Attention Token (BAT), while not perfect, is a step in the right direction (if nothing else, it\u0026rsquo;s different than what we have now).\nI imported my bookmarks into Brave and setup sync between my devices (I really liked the no-account sync setup). Brave was available for all of my devices, loaded pages quickly, no sites were broken, and sync always worked. Hell, I even became a verified Brave Creator. After a few months of use, I had no complaints.\nHowever, as an open source advocate, I honestly felt guilty using Brave.\nBrowsers and browser engines While there might be many browsers, both large and small, there are only a handful actively maintained of browser engines (the things that render the HTML/CSS into what you see on the page):\nWebKit - used by Apple for Safari Gecko - used by Mozilla for Firefox and Thunderbird Blink - used by Google Chrome, Chromium, and all Chromium-based browsers (e.g., Edge, Brave, Vivaldi, Samsung, Opera, etc\u0026hellip;) By having a huge market share, Google (who controls Blink) could create a Blink-based browser monoculture. In fact, right now, many developers don\u0026rsquo;t even test their websites and applications in anything other than Chrome. By using Firefox, I\u0026rsquo;m hoping that I\u0026rsquo;m helping to diversify browser engines and show that choice (and adherence to standards) is important.\nBrowsers based on other browsers As I mentioned, many browsers are based on Chromium. This begs the question: Why aren\u0026rsquo;t there many popular Firefox-based alternatives? I can see two reasons for this:\nBlink was designed to be modular and embeddable, whereas Gecko is practically bound to Firefox. Blink is very permissively licensed, whereas Gecko uses the less-permissive Mozilla Public License. When Brendan Eich (the creator of Javascript and ex-Mozilla CEO), created Brave, he originally based it on Gecko. However, this proved to be too much work and Brave was later switched to Chromium. Even Microsoft abandoned EdgeHTML (their original browser engine for Edge) and switched to Chromium.\nMaking a browser is hard work, costs a lot of money, has high stakes, and most projects want the least resistance. If Chromium/Blink offer a better experience than Firefox/Gecko, you can\u0026rsquo;t blame projects for not basing their products on Firefox/Gecko.\nConclusion I‚Äôm frustrated by Mozilla. I want Firefox to succeed, and I believe in Firefox\u0026rsquo;s goal of creating an open and accessible internet, but I don\u0026rsquo;t know how to help Firefox.\nObviously, Mozilla Corporation exists to make money, but their dependence on Google for search royalties isn\u0026rsquo;t sustainable long-term. At this point, Firefox only exists because Google allows it to exist. As Firefox\u0026rsquo;s market share shrinks, Google will pay Mozilla Corporation less and less, which will cause Mozilla Corporation to layoff more employees, which will cause work on Firefox to stall, which will cause its market share to shrink, etc\u0026hellip;\nI\u0026rsquo;ve debated paying for a Mozilla VPN subscription that I won\u0026rsquo;t use, but there is no guarantee that money will go towards Firefox. I\u0026rsquo;d prefer to be able to donate to Firefox directly, like I can with Thunderbird. For now, I\u0026rsquo;m spreading the Firefox gospel where possible. Although this post was a rant about Mozilla, I\u0026rsquo;m hard on them because I love Firefox and I know they can be better stewards of the only remaining independent browser.\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/08/i-tried-to-quit-firefox-i-cant/","summary":"TL;DR I\u0026rsquo;m frustrated by Mozilla, but don\u0026rsquo;t see many alternative browsers that have such noble goals as Firefox.\nIntroduction I have a confession: I tried really hard to quit Firefox, but I can\u0026rsquo;t.\nI\u0026rsquo;ve been using Firefox since the single-digit release days, and I\u0026rsquo;ve been publishing my Firefox config for five years now. In a recent experiment, I used Brave Browser exclusively for three months, but ended up moving back to Firefox.","title":"I tried to quit Firefox. I can't."},{"content":"TL;DR In my opinion, these self-hosted, open-source applications are the best of what open-source can be.\nHome Assistant Jellyfin Pi-hole Nextcloud WordPress Introduction My hot water tank recently leaked, but (luckily for me) there was a floor drain right next to it. The next day (after having the tank fixed), I purchased a water leak sensor, added it to Home Assistant in under 2 minutes, and was able to get push notifications of future detected leaks.\nThis got me thinking about other self-hosted, open-source applications that are truly amazing works of engineering and community collaboration. Below is what I came up with.\nProject Category Paid tier? Language Home Assistant Home Assistant Home automation Nabu Casa Python Jellyfin Jellyfin Media server N/A C# Pi-hole Pi-hole Network-level ad-block N/A Shell/Python/PHP Nextcloud Nextcloud Personal cloud NextCloud Enterprise PHP/JS WordPress WordPress Blogging WordPress.com PHP/JS I\u0026rsquo;m aware that this is not an exhaustive list, and that most of these applications stand on the shoulders of giants. However, when trying to sell \u0026ldquo;regular people\u0026rdquo; on self-hosted, open-source applications, this is the list to start with.\nHome Assistant I\u0026rsquo;m certainly not a Home Assistant power user, but I will say this is one of the most useful applications that I self-host. Even if I\u0026rsquo;m not logging into the application itself on a consistent basis, Home Assistant is always there, running in the background, automating my life.\nIf you\u0026rsquo;re not aware, Home Assistant, is a home automation tool (e.g., turn on the lights when I get home, if the living room is above 75 F turn on the A/C, etc\u0026hellip;). What makes Home Assistant so special is that it allows you to break out of the walled gardens of vendors (Philips, Aqara, SmartThings, Wyze, etc\u0026hellip;). Home Assistant acts as a \u0026ldquo;hub\u0026rdquo;, allowing you to collect data (and act on it) from multiple different sources.\nWant your Samsung WiFi-connected smart A/C unit to turn on when your Aqara Zibgee-connected temperature sensor reads 75 F? Want your Wyze camera to detect motion and send you snapshot via Telegram message? Want your Philips lights and SmartThings switches to display natively in your iPhone\u0026rsquo;s Home app? Home Assistant can do all of that, and more!\nHome Assistant has a paid tier called Nabu Casa that offers (among other things) secure, remote access to your locally-hosted Home Assistant instance.\nJellyfin For those not in the know, Plex/Jellyfin/Emby, are in the \u0026ldquo;be your own Netflix\u0026rdquo; category.\nI will start off by saying that I\u0026rsquo;m a lifetime Plex Pass holder, but I haven\u0026rsquo;t used it in years. I had grown increasingly frustrated with Plex\u0026rsquo;s internet-connected login requirements, their branching into other services (live TV, DVR, etc\u0026hellip;), and their phone-home requirments, all when I just wanted to play media locally.\nTo that end, I almost cannot believe that something as simple, convenient, and powerful as Jellyfin is a free product. It is a local-first and private-first media server, allowing you to consume your media (movies, TV, music, books, comics, and audiobooks) on almost any device. It offers a ton of clients for all major platforms, including web, iOS, Android, Roku, Android TV, and more. Jellyfin also has hardware-accelerated transcoding, metadata downloading, 4K support, sync-play, plugins, and has a huge community of contributors.\nIn the past year, Jellyfin has really come a long way and is a viable alternative to Plex. Its clients might not be as polished as Plex\u0026rsquo;s, and it may lack some next-level features (skip intros, no-setup remote access), but Jellyfin does 99.9% of what Plex does, while being 100% open-source and local-first.\nPi-hole I don\u0026rsquo;t run Pi-hole personally, but it\u0026rsquo;s mentioned everywhere online. It is a DNS-based sinkhole used to block ads on your entire network. This means that instead of setting up ad-block on every browser, you can setup Pi-hole on your network, and it will block ads on every device on your network (including mobile apps and smart TVs). Because the traffic is blocked on a network level, network performance will be improved and your browsing experience will feel faster (because it is). Blocking ads isn\u0026rsquo;t just about convenience, it\u0026rsquo;s also about security, since Pi-hole\u0026rsquo;s blocklists block potential spam and malware, as well as known bad-actors.\nPi-hole (as the name implies) originally started as a Raspberry Pi project, but now runs on x86 hardware, as well as Docker. It also offers a DHCP server, and a web-based dashboard for configuration and viewing statistics (screenshot below).\nNextcloud I don\u0026rsquo;t run Nextcloud personally, but it\u0026rsquo;s a stand-out in its field. Competing with giants like Google and Microsoft, Nextcloud is a \u0026ldquo;personal cloud\u0026rdquo;, offering self-hosted versions of mail, contact, calendar, kanban, video/audio calls, web hosting, file storage/sync, document editing, an app store, and more. If there is one application you could use to build your digital life around, it would be Nextcloud.\nNextcloud also has a ton of business-centered administration features, such as logging/monitoring, 2FA, file access control, LDAP integration, compliance (e.g., HIPAA, GDPR, etc\u0026hellip;), encryption in-transit and at-rest, and more.\nNextCloud offers a paid tier called NextCloud Enterprise, but the code base for both the home and enterprise versions are the same. The enterprise subscription gets you access to their support and technical teams, as well as some optional features and plugins.\nWordPress I couldn\u0026rsquo;t make this list without mentioning WordPress. WordPress is the platform that powers 43% of all websites in the world. It\u0026rsquo;s used by some huge websites, including Rolling Stone, Time magazine, Snoop Dogg, TechCrunch, and the freaking White House.\nWordPress has a seemingly infinite number of features, including a \u0026ldquo;store\u0026rdquo; with free/paid themes and plugins, WYSIWYG editor, post scheduling and versioning, user management tools, media management tools, comments, SEO, and more. Oh, and did I mention they allow you to import/export your data to/from almost any other blogging platform? No lock-in here.\nWordPress is technically a content-management system (CMS), so it needs a filesystem, MySQL database, and webserver in order to work. However, if that sounds confusing or intimidating to you, WordPress offers a paid tier at WordPress.com to handle everything for you, and let you get down to creating.\nWordPress gets a bad rap because of PHP, but it is the gateway drug to blogging. I started this blog almost 10 years ago, using WordPress. I\u0026rsquo;ve since transitioned away from it (because I\u0026rsquo;m a nerd and like to make things complicated), but I wouldn\u0026rsquo;t be here without it.\nConclusion All of these applications have a few things in common. They are all:\nopen-source privacy-first community-driven They are true technical (as well as collaborative) marvels, and are the first step into self-hosting and the open-source world. I could add 50 other applications to this list (WireGuard, Gitea, Traefik, OPNsense, Proxmox, etc\u0026hellip;), but these five are, in my opinion, success stories that are unrivaled.\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/05/darlings-of-the-self-hosted-open-source-world/","summary":"TL;DR In my opinion, these self-hosted, open-source applications are the best of what open-source can be.\nHome Assistant Jellyfin Pi-hole Nextcloud WordPress Introduction My hot water tank recently leaked, but (luckily for me) there was a floor drain right next to it. The next day (after having the tank fixed), I purchased a water leak sensor, added it to Home Assistant in under 2 minutes, and was able to get push notifications of future detected leaks.","title":"Darlings of the self-hosted, open-source world"},{"content":"Update: 2022-04-15 I typically average around 100 unique visitors to this site per day. Below is a screenshot from my Plausible analytics setup showing the traffic spike up to almost 14k unique visitors from HackerNews (and other sources).\nUpdate: 2022-04-12 I posted this article to that orange site and it blew up more than I expected. I reached #3 of the front page (screenshot below) and am officially on the top 10 list for 2022-04-11. When I migrated from WordPress to Hugo, I lost comments on this blog, but the HackerNews post has some really good discussion and recommendations that I highly encourage you to check out.\nTL;DR ‚ö†Ô∏è Warning Apple fanboys: this is a rant ‚ö†Ô∏è\nHardware = Good\nSoftware = Bad\nIntroduction I recently started a new job where my employer provided me with a brand-new 2021 16‚Äëinch MacBook Pro. A little background on me: I\u0026rsquo;ve been using Windows and Linux my entire professional life, I have been daily-driving various Linux desktops at home for 10+ years, all of my servers run Linux, but I have never used a Mac in my life. These are my impressions of using a Mac for the first time.\nFor reference, below are the specs of the machine I am using:\n2021 16‚Äëinch MacBook Pro Apple M1 Pro (8 performance cores and 2 efficiency cores) 16GB memory 512GB SSD macOS Monterey I\u0026rsquo;m using this Macbook almost exclusively with the lid closed, with a USB-C adapter to connect my keyboard/mouse/monitor. The Good Hardware build quality This machine is insanely well-built. In fact, I have probably never owned anything this well-built. Holding it in your hands feels like holding a solid piece of aluminum, there isn\u0026rsquo;t a millimeter of flex. There isn\u0026rsquo;t a single imperfection on the finish. The indentation where you put your finger to open the lid is so well machined that the edges are actually sharp. Closing the lid feels like closing the door of a German car. The display is bright and vibrant with very deep blacks. The M1 Pro chip sips power when asleep, but can handle anything I ask of it.\nBattery life Does this machine actually have a battery, or there some sort of magic arc reactor inside? Seriously, the battery on this thing lasts forver, whether I\u0026rsquo;m doing work, or if the lid is closed and it\u0026rsquo;s sleeping. I can easily get through an 8-10hr day with no problems.\nBSD base I won\u0026rsquo;t claim to be a Unix or BSD historian, but I do know that macOS is based on Darwin, which itself is based on BSD. While macOS isn\u0026rsquo;t POSIX-certified, it is Single Unix Specification UNIX 03 registered and compliant. This means if you\u0026rsquo;re comfortable with a Linux command line, you\u0026rsquo;ll probably be just fine for about 95% of your tasks.\nThe Medicore Connectivity Apple decided to grace the 2021 Macbook Pro with ports that any PC laptop user has had for years (HDMI?! SD card reader?! gasp!).\nThat being said, MagSafe is a genius idea. It should be a standard (like USB-C) on every laptop in existence. I know USB-C is supposed to be \u0026ldquo;one cable to rule them all\u0026rdquo;, but anyone who has tripped over their power cord while charging knows what I\u0026rsquo;m talking about.\nSpeaking of USB-C, if you\u0026rsquo;re buying a Macbook Pro, think about picking up a Thunderbolt or USB-C hub/dock/adapter. There are zero USB-A ports on the Macbook Pro. I can almost guarantee that you don\u0026rsquo;t have a USB-C flash drive, but you probably have ten USB-A flash drives laying around. What about your wired keyboard, webcam, USB DAC, or USB chargers? I bet they\u0026rsquo;re all USB-A. The dongle meme (one, two, three, four, five) is overplayed at this point, but it\u0026rsquo;s not wrong.\nExpansion With the new M1 Macs, the CPU, memory, and storage are all unified, meaning they are soldered together and cannot be upgraded. However, the trade off is that because everything is so tightly coupled, you get better speeds than you would from traditional components that communicate over a slower bus. Also, because Thunderbolt 4 has so much bandwidth (up to 40Gb/s), you really aren\u0026rsquo;t limited to what you can plug in (as long as it\u0026rsquo;s over Thunderbolt).\nThe Bad macOS window management There is no other way to say this: window management is painful on macOS.\nSnapping I\u0026rsquo;m accustomed to virtual desktops on both Windows and Linux, so it was nice to see that on macOS. However, multi-tasking within the same virtual desktop (i.e., having multiple windows open side-by-side) is awful. Windows and Linux both have what I would call \u0026ldquo;sane\u0026rdquo; window snapping (shown here), where you drag the window to the left or right edge of the desktop to snap left or right. You can even do this with three or four windows.\nOn the other hand, macOS has a weird snapping implementation where you need to click and hold the green \u0026ldquo;zoom\u0026rdquo; button, then choose to \u0026ldquo;tile\u0026rdquo; left or right. But, once you pick another window to fill the other half, both of those windows (together as one) move to their own virtual desktop. I want them split on my current desktop, not on a separate desktop.\nAlso, unlike Windows or Linux, you can\u0026rsquo;t \u0026ldquo;maximize\u0026rdquo; a window using the green \u0026ldquo;zoom\u0026rdquo; button, it will only make the current window fullscreen (and again, on its own desktop). Confusingly, you need to again click and hold the green \u0026ldquo;zoom\u0026rdquo; button, then choose \u0026ldquo;Zoom\u0026rdquo;. Apple calls the green button \u0026ldquo;zoom\u0026rdquo; in their documentation, but its default function is fullscreen, not zoom.\nFor all the Apple fanboys screaming \u0026ldquo;There\u0026rsquo;s an app for that!\u0026rdquo;, I hear you, but remember, this is a work machine and I need to get everything I install blessed by IT security. Easy for large applications like Slack or Chrome, but harder for the small tools that only fix my niche issues (I\u0026rsquo;ve already found Rectangle, BetterSnapTool, and Magnet).\nCommand+Tab If you want to switch between windows, you can use Command (‚åò)+Tab (the equivalent is Alt+Tab on Windows). If you open two of the same window (e.g., two Chrome windows), they appear as one in the dock. However, when you press Command (‚åò)+Tab, this will only show one entry for Chrome, even though you have two windows of Chrome open. Selecting Chrome via Command (‚åò)+Tab will then show both Chrome windows, but make you move your mouse (or press Command+`) to select the Chrome window you want to work in. Why the extra step? Just show me both windows in Command (‚åò)+Tab.\nI found this flowchart showing the window switching workflow, which I thought was pretty hilarious. Again, I found AltTab to fix this, but can\u0026rsquo;t install it due to policy.\nThe Undecided External peripherals I\u0026rsquo;m using my Macbook with a USB-C adapter so that I can use my PC keyboard/mouse/monitor. However, that keyboard doesn\u0026rsquo;t have the Option (‚å•) or Command (‚åò) keys like on my Macbook. This makes using keyboard shortcuts difficult due to the keys being switched, but I don\u0026rsquo;t blame Apple for this. I tried changing the modifier keys in System Preferences\u0026ndash;\u0026gt;Keyboard, but that broke other keyboard shortcuts.\nTwo-finger scrolling on the trackpad is like scrolling on your phone (what Apple calls \u0026ldquo;natural\u0026rdquo;). However, plugging in a mouse with a scroll wheel means the scroll wheel is \u0026ldquo;backward\u0026rdquo;. Thankfully, I was able to download Logitech\u0026rsquo;s Options software to reverse this.\nPackage management Coming from a Linux background, I\u0026rsquo;m spoiled by Linux package managers. Not trying to start a package management flame war, but apt/yum/pacman are all better than anything Microsoft or Apple provide (which is nothing). Homebrew is a lifesaver on macOS and is the only thing not making me pull my hair out.\nConclusion While the hardware is great, I\u0026rsquo;d give anything to replace macOS with Linux (or even Windows). Unfortunately, this is a work machine, and I don\u0026rsquo;t have that option, so I need to make due with what I\u0026rsquo;ve been provided.\nAre some of my criticisms due to my lack of knowledge about macOS? Almost definitely. Will I eventually become accustomed to macOS? Almost definitely.\nThe entire design of macOS feels like the Gnome desktop: you use what they give you, how they give it to you, using their workflows, barely customizing anything. Apple products are supposed to be revered the world over as the pinnacle of design, used by artists, engineers, professionals, and creators. Why do I feel like there are training wheels on a machine I use for productivity? Not that I had any plans on it, but after this experience, I would personally never purchase a macOS product.\n-Logan\nMy website is an independent blog and has not been authorized, sponsored, or otherwise approved by Apple Inc.\nApple, Mac, Macbook, Macbook Pro, and macOS are trademarks of Apple Inc., registered in the U.S. and other countries and regions.\n","permalink":"https://loganmarchione.github.io/2022/04/impressions-from-a-first-time-mac-user/","summary":"Update: 2022-04-15 I typically average around 100 unique visitors to this site per day. Below is a screenshot from my Plausible analytics setup showing the traffic spike up to almost 14k unique visitors from HackerNews (and other sources).\nUpdate: 2022-04-12 I posted this article to that orange site and it blew up more than I expected. I reached #3 of the front page (screenshot below) and am officially on the top 10 list for 2022-04-11.","title":"Impressions from a first-time Mac user"},{"content":"Introduction I\u0026rsquo;ve been trying to get my homelab applications moved from running on VM/LXC to Docker. There\u0026rsquo;s nothing wrong with VMs or LXC containers, but I\u0026rsquo;m trying to manage fewer servers and \u0026ldquo;snowflakes\u0026rdquo; (even though I do my installs with Ansible).\nThe application that started my homelab journey was DokuWiki. It\u0026rsquo;s a self-hosted wiki, written in PHP, that requires no database. You write in a Markdown-like syntax (not Markdown) and your data is stored in plain TXT files on the filesystem. DokuWiki, however, is not 100% straightforward to Dockerize.\nThe DokuWiki in Docker problem DokuWiki is very simple: a bunch of PHP files sit in a directory to be served by a PHP-capable webserver (e.g., Nginx or Apache). It\u0026rsquo;s so simple (and old, from 2004) that you\u0026rsquo;d think it would be easy to run in Docker in 2022, right?\nIf you search on Docker Hub, there are almost 400 DokuWiki images, none of which are the official image (because there isn\u0026rsquo;t one). An official image was requested via a GitHub issue back in 2017. However, because DokuWiki is so simple and pre-dates Docker, it wasn\u0026rsquo;t really designed to be run inside a container (see this for more details).\nAs Andreas Gohr (the creator of DokuWiki) posted in his Patreon, the best way to install DokuWiki in Docker is to setup a generic PHP+web server container with a volume, then install DokuWiki into that volume. This is approximately 0.1% more work than pulling a pre-baked, unofficial Docker image from Docker Hub, and it\u0026rsquo;s what the creator of DokuWiki himself recommends.\nOther wikis Before anyone asks, yes, I know there are other wikis out there, and they almost certainly have more features than DokuWiki, and are probably nicer looking. However, they all require a database to store content, whereas DokuWiki stores everything in plaintext files.\nMediaWiki (The wiki that Wikipedia uses) Wiki.js Bookstack Outline Installation We\u0026rsquo;re basically going to run a PHP container with a webserver, then exec into the container and install DokuWiki.\nDocker container This simple Docker Compose file will get you up and running. It\u0026rsquo;s nothing more than the official PHP image with Apache.\nversion: \u0026#39;3\u0026#39; services: dokuwiki: container_name: dokuwiki image: php:7-apache-bullseye restart: unless-stopped networks: - dokuwiki ports: - \u0026#39;8888:80\u0026#39; volumes: - \u0026#39;dokuwiki_config:/var/www/html\u0026#39; networks: dokuwiki: volumes: dokuwiki_config: driver: local Once this is completed, visit http://your_docker_server_IP:8888 and you should see this error (since there is nothing for Apache to serve).\nDokuWiki install First, exec into the container.\ndocker exec -it dokuwiki /bin/bash Next, download DokuWiki.\ncd /var/www/html curl --remote-name https://download.dokuwiki.org/src/dokuwiki/dokuwiki-stable.tgz tar -xzvf dokuwiki-stable.tgz --strip-components=1 rm dokuwiki-stable.tgz chown -R www-data:www-data /var/www/ Now, visit http://your_docker_server_IP:8888/install.php and you will see the DokuWiki install page. Done!\nConclusion The only caveats I can think of running this way are:\nUpgrades - Normally you upgrade DokuWiki by downloading a newer tgz file and overwriting your current setup. However, this kind of a pain in Docker. It\u0026rsquo;s much easier to install the Upgrade plugin and use that from the web interface. Plugins - I don\u0026rsquo;t have a ton of plugins (I don\u0026rsquo;t use LDAP, databases, galleries, etc..). Because of this, the default PHP modules are more than enough for me. However, if you needed more, PHP offers instructions on how to build your own PHP image. -Logan\n","permalink":"https://loganmarchione.github.io/2022/03/the-best-way-to-run-dokuwiki-in-docker/","summary":"Introduction I\u0026rsquo;ve been trying to get my homelab applications moved from running on VM/LXC to Docker. There\u0026rsquo;s nothing wrong with VMs or LXC containers, but I\u0026rsquo;m trying to manage fewer servers and \u0026ldquo;snowflakes\u0026rdquo; (even though I do my installs with Ansible).\nThe application that started my homelab journey was DokuWiki. It\u0026rsquo;s a self-hosted wiki, written in PHP, that requires no database. You write in a Markdown-like syntax (not Markdown) and your data is stored in plain TXT files on the filesystem.","title":"The 'best' way to run DokuWiki in Docker"},{"content":"Hey! Listen! This post is part of a series on my journey into K3s. Check them all out!\nDate URL Part 2022-03-29 Kubernetes GUIs Exploring Kubernetes GUIs 2022-03-11 K3s single-node cluster for noobs Deploying K3s Introduction In my last post, I setup a K3s single-node cluster and an example application. While everything was done through the command-line, as a noob, it\u0026rsquo;s nice to have a graphical user interface (GUI) of some kind. I\u0026rsquo;m not a fan of ClickOps, but it\u0026rsquo;s convenient to have a GUI to be able to quickly view status, instead of hunting for the right kubectl command.\n‚ö†Ô∏è WARNING ‚ö†Ô∏è\nI am not a Kubernetes expert! This is solely for my own learning. If you get something useful out of my ramblings, that\u0026rsquo;s great, but it\u0026rsquo;s not my primary goal. Nothing I setup here should be considered production-ready or secure. Comparison There are a ton of k8s GUIs, but I\u0026rsquo;m going to be covering what I\u0026rsquo;ve found to be the easiest to setup and use.\nProduct Language Type Source model Comments Kubernetes Dashboard Go/Typescript GUI Open source Browser-based Lens Typescript GUI Open source Octant Go/Typescript GUI Open source Browser-based Infra App ??? GUI Closed source Kubenav Go/Typescript GUI Open source Has mobile apps K9s Go TUI Open source Kubernetes Dashboard Because K3s is upstream k8s (with some bits stripped out), we can setup the official k8s web dashboard.\nFirst, we need to apply the dashboard manifest to the cluster by running the command below on our personal machine (again, kubectl on our personal machine connects to the cluster).\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.1/aio/deploy/recommended.yaml Next, we need to create a user and role to login to the dashboard. I recommend storing all of your manifests in a directory for easy management and version control. You can copy/paste the commands below to create the directory and the manifest.\nmkdir -p ~/k8s/dashboard cat \u0026lt;\u0026lt; EOF \u0026gt; ~/k8s/dashboard/admin.yml --- apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard EOF Now, apply the manifest and get your token.\nkubectl apply -f ~/k8s/dashboard/admin.yml kubectl -n kubernetes-dashboard describe secret admin-user-token | grep \u0026#39;^token\u0026#39; | awk \u0026#39;{print $2}\u0026#39; By default, the web dashboard is only accessible from within the cluster, which isn\u0026rsquo;t particularly useful because we\u0026rsquo;re on a separate machine. We need to open a second terminal on our personal machine and run kubectl proxy, which will open a proxy to the K3s cluster. With kubectl proxy still running in the background, click on the link below.\nhttp://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/\nYou\u0026rsquo;ll be prompted to enter your token.\nFinally, you\u0026rsquo;ll see the dashboard. Click around to explore your setup.\nLens Lens is probably the next-most popular k8s GUI. It is made by Mirantis, the same people who make k0s and who recently purchased Docker Enterprise. It is open source, but also offers a paid cloud service called Lens Spaces.\nLens is Electron-based, which means it\u0026rsquo;s available for a ton of platforms, but it\u0026rsquo;s also Electron-based, so there\u0026rsquo;s that slow memory leak to look forward to. ü§∑‚Äç‚ôÇÔ∏è\nSee the installation instructions here. I\u0026rsquo;m using Arch, btw, so I\u0026rsquo;m using the version from the AUR.\nyay -s lens-bin Lens reads your ~/.kube/config file, so no setup or proxy is required.\nOctant Octant is made by the good folks at VMware, as part of their Tanzu portfolio of cloud/DevOps products. It is open source and written in Go.\nInstallation instructions are here, but it\u0026rsquo;s available via the AUR.\nyay -s octant-bin Octant reads your ~/.kube/config file and will open a proxy to 127.0.0.1:7777 in your default web browser.\nInfra App Infra App is certainly beautiful to look at, but it appears to be closed source. For free, you can connect to one cluster. The paid plan offers unlimited clusters, but is a subscription at $100/yr.\nInfra App reads your ~/.kube/config file, so no setup or proxy is required.\nKubenav Kubenav is a stand-alone project that is open source and written in Typescript. It also appears to be Electron-based, but its claim to fame is that it offers mobile apps for iOS and Android (since it\u0026rsquo;s basically a website in a wrapper).\nThe version in the AUR was out of date (shock!), so I downloaded the binary from the releases page.\nKubenav reads your ~/.kube/config file, so no setup or proxy is required.\nK9s K9s is technically a terminal UI (TUI), not a GUI.\nI installed K9s via the Arch repos with pacman, but K9s offers installation instructions for other operating systems on their GitHub page.\nsudo pacman -S k9s K9s reads your ~/.kube/config file, so no setup or proxy is required.\nConclusion I\u0026rsquo;m going to stick with Lens, since that\u0026rsquo;s what we\u0026rsquo;re using at work, but I\u0026rsquo;m probably going to keep looking at other products as they are improved over time.\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/03/kubernetes-guis/","summary":"Hey! Listen! This post is part of a series on my journey into K3s. Check them all out!\nDate URL Part 2022-03-29 Kubernetes GUIs Exploring Kubernetes GUIs 2022-03-11 K3s single-node cluster for noobs Deploying K3s Introduction In my last post, I setup a K3s single-node cluster and an example application. While everything was done through the command-line, as a noob, it\u0026rsquo;s nice to have a graphical user interface (GUI) of some kind.","title":"Kubernetes GUIs"},{"content":"Hey! Listen! This post is part of a series on my journey into K3s. Check them all out!\nDate URL Part 2022-03-29 Kubernetes GUIs Exploring Kubernetes GUIs 2022-03-11 K3s single-node cluster for noobs Deploying K3s Introduction I\u0026rsquo;m starting a new job in the next few days that will require me to learn Kubernetes (often stylized as k8s). This post is not about what k8s is or why you want it (you can read about that here). My only objective for now is to have a single-node k8s cluster running in my homelab.\n‚ö†Ô∏è WARNING ‚ö†Ô∏è\nI am not a Kubernetes expert! This is solely for my own learning. If you get something useful out of my ramblings, that\u0026rsquo;s great, but it\u0026rsquo;s not my primary goal. Nothing I setup here should be considered production-ready or secure. Lightweight k8s Production k8s installations can vary in size and complexity, but upstream k8s has a ton of components and moving pieces (etcd, kube-apiserver, kube-scheduler, kubelet, DNS, etc\u0026hellip;). As you can imagine, it\u0026rsquo;s complicated to setup correctly, especially on resource-limited or single-node clusters. Out of necessity, there are now quite a few lightweight k8s distributions that not only strip out the features most people won\u0026rsquo;t use, but also simplify installation and setup.\nk0s (made by Mirantis, who owns Docker, Inc.) MicroK8s (made by Canonical, who also makes Ubuntu) K3s (made by Rancher, which was recently purchased by SUSE) minikube (the \u0026ldquo;official\u0026rdquo; mini-k8s distribution) I\u0026rsquo;m going with K3s because it seems to have the largest community, it\u0026rsquo;s CNCF-certified, and it\u0026rsquo;s lightweight (~60MB binary).\nSingle-node? Why? Obviously, a single-node cluster provides no H/A or failover capability. However, you interact with a single-node cluster the same way you do a 100-node cluster. This is all about learning, not about being highly-available, efficient, or practical.\nInstall K3s (on the server) These commands should be entered on the server that will run K3s. In my case, this is a virtual machine running Debian 11.\nRun the command below to install K3s on your server. Pro-tip: If you\u0026rsquo;re doing this in a VM, take a snapshot now so you can roll back later if you mess up!\ncurl -sfL https://get.k3s.io | sh - Once it\u0026rsquo;s done, check that K3s is running.\nsudo systemctl status k3s.service Verify your cluster and node info.\nsudo kubectl cluster-info sudo kubectl get node Congrats! Your single-node cluster is running! Now, view the contents of the /etc/rancher/k3s/k3s.yaml file, we\u0026rsquo;ll need this later.\nsudo cat /etc/rancher/k3s/k3s.yaml Also, if there is a firewall on your server, you\u0026rsquo;ll need to open 6443/tcp for external cluster access (I\u0026rsquo;m using UFW).\nsudo ufw allow 6443/tcp sudo ufw reload Setup kubectl (on your personal machine) These commands should be entered on the machine that will interact with your K3s cluster. In my case, this is a desktop running Arch Linux.\nThe tool used to interact with a k8s (or K3s) cluster is called kubectl, which is included with K3s. However, you typically don\u0026rsquo;t SSH to the server to interact with the cluster. Instead, you install kubectl on your personal machine (desktop, laptop, etc\u0026hellip;) and connect to the cluster remotely.\nI\u0026rsquo;m running Arch, so I installed kubectl with pacman.\nsudo pacman -S kubectl Run the command below to make sure kubectl works. For now, ignore the error about the connection to the server not working.\nkubectl version --output=yaml Next, create an empty directory to hold the configuration file for kubectl.\nmkdir -p ~/.kube touch ~/.kube/config chown $(id -u):$(id -g) ~/.kube/config chmod 600 ~/.kube/config Now, copy/paste the contents of /etc/rancher/k3s/k3s.yaml from the server into ~/.kube/config on your personal machine. While you\u0026rsquo;re doing this, replace the IP (which is probably 127.0.0.1) with your server\u0026rsquo;s IP (mine was 10.10.1.51).\nRun the commands below and you should be able to see cluster info from your personal machine.\nkubectl version --output=yaml kubectl cluster-info kubectl get node Congrats! You can now interact with your cluster remotely!\nDeploy example application We\u0026rsquo;re going to deploy three instances of an example application called traefik/whoami. This is a webserver written in Go that prints operating system information and HTTP request to output. This is a very simplified setup of how traffic will flow from your client to the containers in the pods.\nKubernetes resources (pods, deployments, services, etc\u0026hellip;) are written in plaintext JSON or YAML files called manifests. Think of manifests like docker-compose files. I recommend storing all of your manifests in a directory for easy management and version control (again, like docker-compose files).\nmkdir -p ~/k8s/whoami We\u0026rsquo;re going to create the following resources in one manifest file:\nNamespace - This is a best-practice way to segment the cluster (both in software and in administration) Deployment - This is where we define our container image and how many replicas we want. This is what creates the pods, which will have our containers in them. Service - This exposes our pods to eachother, as well as to the cluster itself. Remember, the pods can come and go, so their IP addresses might change over time. A service is a reliable address. Ingress - This exposes the services inside the cluster to the outside world. An ingress is a set of rules for traffic, while the ingress controller is the thing doing the work (e.g., nginx, Traefik, etc..). You can copy/paste the command below to create the manifest.\ncat \u0026lt;\u0026lt; EOF \u0026gt; ~/k8s/whoami/whoami.yml --- apiVersion: v1 kind: Namespace metadata: name: k3s-test --- apiVersion: apps/v1 kind: Deployment metadata: name: whoami-deploy namespace: k3s-test labels: app: whoami spec: replicas: 3 selector: matchLabels: app: whoami template: metadata: labels: app: whoami spec: containers: - name: whoami image: traefik/whoami:v1.8.0 ports: - name: whoami containerPort: 80 --- apiVersion: v1 kind: Service metadata: name: whoami-svc namespace: k3s-test labels: service: whoami spec: type: ClusterIP ports: - name: http port: 80 protocol: TCP selector: app: whoami --- apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: whoami-ingress namespace: k3s-test annotations: traefik.ingress.kubernetes.io/router.entrypoints: web spec: rules: - http: paths: - path: /test pathType: Prefix backend: service: name: whoami-svc port: number: 80 EOF Next, deploy the manifest (again, kubectl on our personal machine connects to the cluster).\nkubectl apply -f ~/k8s/whoami/whoami.yml Using the commands below, you can see the namespace, pods, deployment, service, and ingress (as well as their respective IP addresses).\nkubectl get namespaces kubectl get pods --namespace k3s-test -o wide kubectl get deployments --namespace k3s-test -o wide kubectl get services --namespace k3s-test -o wide kubectl get ingress --namespace k3s-test -o wide In a browser, visit http://your_node_ip/test (replace your_node_ip with your single-node cluster\u0026rsquo;s IP, which should be the same IP from the kubectl get ingress command). Refresh this page, and you should see the IP changing (a total of three different addresses, since we specified three replicas and Traefik is load balancing between them).\nWhen finished, delete the deployment.\nkubectl delete -f ~/k8s/whoami/whoami.yml Conclusion Like I mentioned, this cluster is for learning. I have my homelab (more about that setup here) running mostly on docker-compose. My plan is to make this a multi-part series (learning K3s as I go), then slowly start migrating applications to K3s. Before I do that, I\u0026rsquo;ll need to investigate the following things:\nPersistent storage (i.e., volumes) Secret storage (e.g., passwords, database connection strings, etc\u0026hellip;) Ingress (accessing applications from outside the cluster) SSL/TLS Backups If you\u0026rsquo;re running K3s (or any k8s distribution) at home, I\u0026rsquo;d love to hear about it!\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/03/k3s-single-node-cluster-for-noobs/","summary":"Hey! Listen! This post is part of a series on my journey into K3s. Check them all out!\nDate URL Part 2022-03-29 Kubernetes GUIs Exploring Kubernetes GUIs 2022-03-11 K3s single-node cluster for noobs Deploying K3s Introduction I\u0026rsquo;m starting a new job in the next few days that will require me to learn Kubernetes (often stylized as k8s). This post is not about what k8s is or why you want it (you can read about that here).","title":"K3s single-node cluster for noobs"},{"content":"Hey! Listen! This post is part of a series on deploying Hugo. Check them all out!\nDate URL Part 2022-02-08 Deploying Hugo with Netlify Deploying on Netlify 2021-10-13 Deploying Hugo with CloudFront and S3 Deploying on CloudFront and S3 2021-09-21 Deploying Hugo with AWS Amplify Deploying on Amplify Introduction In my last post, I was testing the deployment of Hugo with CloudFront and S3. My main complaints came from the complicated Terraform setup and the lack of easy redirects. Since Amplify and CloudFront+S3 are the only AWS-based offerings, I decided to check out alternatives outside of the AWS umbrella.\nStatic site hosting As I\u0026rsquo;ve mentioned before, this is a static site. This site doesn\u0026rsquo;t need to be hosted on a VPS (which I need to patch and maintain), it could be hosted in the cloud, or completely on a CDN. There are a ton of developer-focused static hosts out there. A few I considered are below:\nNetlify Surge Render Firebase Vercel CloudFlare Pages GitHub Pages They generally all offer a git-based workflow where you make commits to a branch, the host builds your website from the latest commit, and then publishes it to their CDN. Each has their quirks, but Netlify seemed to have the most features and came the most recommended via Reddit. On a side note, check out this excellent post by Kev Quirk comparing static site host performance.\nNetlify Setup The setup couldn‚Äôt have been easier. Again, following Hugo‚Äôs official documentation, you basically tell Netlify what GitHub repo you want to use and it will rebuild your site any time there is a commit.\nThe site URL Netlify gives you is something like brave-curie-671954.netlify.app, but you also have the option to use a custom domain (like loganmarchione.com).\nWhat I liked Ease of setup - Like AWS Amplify, this took less than 5 minutes to setup. Within 10 minutes, I had the site running on my custom test domain. Couldn\u0026rsquo;t have been easier. Git-aware by default - Like the other static site hosts, git is a first-class citizen here. Plenty of features around branches, pull requests, etc\u0026hellip; HTTPS - Netlify offers free SSL certificates (via Let\u0026rsquo;s Encrypt) for all their sites. They also support HTTP/2 when HTTPS is enabled. IPv6 - Netlify doesn\u0026rsquo;t enable IPv6 by default, but it\u0026rsquo;s available if you use their DNS manager. Redirects - No serverless functions here, just a simple config file to do redirects and URL rewrites. Custom headers - The same config file also supports custom headers. What I didn\u0026rsquo;t like IPv6 support only when using their DNS manager - I\u0026rsquo;m very particular about my infrastructure and manage my DNS with Route53 using Terraform. This is probably a niche use case, but if you want to use Netlify with a custom domain, with external DNS, you can\u0026rsquo;t have IPv6. Netlify offers an IPv4 load balancer IP, but no equivalent for IPv6. I found a few forum posts requesting this feature (one, two, three), so I can\u0026rsquo;t be the only one who wants this. I\u0026rsquo;d like to see Netlify add an IPv6 endpoint to their load balancer (apparently this is a limit of their DNS provider, NS1) or create a Terraform provider to allow programmatic management of DNS records. Conclusion Ultimately, I choose the tear down my Netlify demo site in favor of my plain-old Nginx server. If you\u0026rsquo;re keeping track, the score is:\nProduct Score Nginx 3 Serverless 0 If you host a Hugo site, tell me how! I\u0026rsquo;m open to any options!\n-Logan\n","permalink":"https://loganmarchione.github.io/2022/02/deploying-hugo-with-netlify/","summary":"Hey! Listen! This post is part of a series on deploying Hugo. Check them all out!\nDate URL Part 2022-02-08 Deploying Hugo with Netlify Deploying on Netlify 2021-10-13 Deploying Hugo with CloudFront and S3 Deploying on CloudFront and S3 2021-09-21 Deploying Hugo with AWS Amplify Deploying on Amplify Introduction In my last post, I was testing the deployment of Hugo with CloudFront and S3. My main complaints came from the complicated Terraform setup and the lack of easy redirects.","title":"Deploying Hugo with Netlify"},{"content":"Hey! Listen! This post is part of a series on deploying Hugo. Check them all out!\nDate URL Part 2022-02-08 Deploying Hugo with Netlify Deploying on Netlify 2021-10-13 Deploying Hugo with CloudFront and S3 Deploying on CloudFront and S3 2021-09-21 Deploying Hugo with AWS Amplify Deploying on Amplify Introduction In my last post, I was testing the deployment of Hugo with AWS Amplify. My only complaint was that Amplify doesn\u0026rsquo;t support IPv6. Because of this, I wanted to explore other deployment options under the AWS umbrella.\nCloudFront and S3 As I said in my last post, you can host a site directly from S3, but it won\u0026rsquo;t have HTTPS. If you put CloudFront in front of S3, you get all the benefits of HTTPS and Amazon\u0026rsquo;s CDN.\nSetup I won\u0026rsquo;t cover the technical details of the setup here, you can Google for that.\nFor the admin user (i.e., me), I used Terraform to create the AWS infrastructure (DNS, certificates, S3 bucket, CloudFront distribution, etc\u0026hellip;) and GitHub/GitHub Actions to host, build, and deploy the code to S3.\nFor visitors, CloudFront handled HTTPS and redirects from the www site. The HTML files hosted in S3 were not directly accessible (i.e., I used a CloudFront origin access identity to restrict access).\nBelow was the minimum viable product I setup for my testing. There were other things missing from here that would be in a production setup, like buckets for logging, Lambda functions, etc\u0026hellip;\nIn practice, this setup was difficult to get going. In Terraform, I had to create the following items:\nDNS entries (using Route53) S3 bucket (for static files generated by Hugo) S3 bucket policy (to allow CloudFront access) Certificates (and automatic validation) CloudFront distribution IAM user (for GitHub Actions) IAM user policy (to allow access only to S3) Then, I had to setup GitHub Actions and my Hugo deployment settings, which took a few tries to get right.\nWhat I liked Fine-grained control - CloudFront has some pretty powerful options, like geo restrictions, web application firewalls, price classes, and more. I was very impressed with the amount of control it offered. IPv6 - As I said in my last post, I wanted IPv6 support, and CloudFront checked that box for me. S3 - S3 is addictive and way too convenient. It\u0026rsquo;s like having an unlimited hard drive in the cloud. I\u0026rsquo;ll probably keep using it to store other assets for my site, even if the site isn\u0026rsquo;t hosted on S3 itself. What I didn\u0026rsquo;t like Complicated setup - The Terraform code required for setup was complicated. Especially frustrating was the nugget of information I missed about CloudFront certificates only working if they were created in the us-east-1 region (I was using a different region). URL redirects - I have a few custom URL redirects setup, and CloudFront doesn\u0026rsquo;t support those natively without an edge function (while Amplify does). Right now, if I\u0026rsquo;m going to switch, it needs to be easier than Nginx. Conclusion Ultimately, I choose the tear down my CloudFront and S3 demo site in favor of my plain-old Nginx server. If you\u0026rsquo;re keeping track, the score is:\nProduct Score Nginx 2 Serverless 0 If you host a Hugo site, tell me how! I\u0026rsquo;m open to any options!\n-Logan\n","permalink":"https://loganmarchione.github.io/2021/10/deploying-hugo-with-cloudfront-and-s3/","summary":"Hey! Listen! This post is part of a series on deploying Hugo. Check them all out!\nDate URL Part 2022-02-08 Deploying Hugo with Netlify Deploying on Netlify 2021-10-13 Deploying Hugo with CloudFront and S3 Deploying on CloudFront and S3 2021-09-21 Deploying Hugo with AWS Amplify Deploying on Amplify Introduction In my last post, I was testing the deployment of Hugo with AWS Amplify. My only complaint was that Amplify doesn\u0026rsquo;t support IPv6.","title":"Deploying Hugo with CloudFront and S3"},{"content":"Hey! Listen! This post is part of a series on deploying Hugo. Check them all out!\nDate URL Part 2022-02-08 Deploying Hugo with Netlify Deploying on Netlify 2021-10-13 Deploying Hugo with CloudFront and S3 Deploying on CloudFront and S3 2021-09-21 Deploying Hugo with AWS Amplify Deploying on Amplify Introduction Since I migrated from WordPress to Hugo, I\u0026rsquo;ve dropped the need to run PHP and MySQL on my server. This means my server is now only running Nginx, serving up static HTML/CSS/JS files. For a simple site like mine, even a VPS running Nginx is overkill. This site doesn\u0026rsquo;t need to be hosted on a VPS, it could be hosted in the cloud, or completely on a CDN.\nThis will be the first of a small series of posts about my future hosting options for this site.\nHosting evolution of this site I\u0026rsquo;ve changed hosts and methods of hosting over the years, so here is an abbreviated history of my past hosting adventures.\n2014-2015: Vendor-managed WordPress on Bluehost - Easy to get started, but not very flexible (couldn\u0026rsquo;t change webserver or PHP settings). I migrated away after 6 months. Bluehost managed the OS and application updates. 2015-2021: Self-managed WordPress on DigitalOcean VPS - I installed a LEMP stack on a DigitalOcean VPS, then installed WordPress on top of that. I managed the OS and application updates. 2021: Self-managed Hugo on DigitalOcean VPS - I migrated to Hugo, which meant I could remove PHP and MySQL from my server. I setup GitHub Actions based on this post to rebuild and push my site to the VPS whenever there was a commit. I managed the OS and application updates (just not PHP and MySQL anymore). Ways to host a static site on AWS Why AWS? As much as I don\u0026rsquo;t like to give Jeff Bezos more money, my new employer (post on that coming soon!) is heavily invested in AWS. As such, I thought this would be the perfect time to migrate my site. I could simplify my site\u0026rsquo;s workflow, and learn AWS/Terraform at the same time. Plus, AWS has many ways to host a site, so I can explore multiple options under one vendor.\nLightsail or EC2 Lightsail and EC2 are both classes of virtual machines in AWS (Lightsail being more simple, EC2 being more complex). Choosing either of these would basically be like what I\u0026rsquo;m doing now with DigitalOcean, but on AWS instead. There\u0026rsquo;s nothing wrong with this, but also no compelling reason to switch.\nS3 + CloudFront S3 is Amazon\u0026rsquo;s object storage, while CloudFront is their CDN. You can host a site directly from S3, but it won\u0026rsquo;t have HTTPS. If you put CloudFront in front of S3, you get all the benefits of HTTPS and Amazon\u0026rsquo;s CDN.\nAmplify AWS Amplify was what I was most excited to try. Amplify has a ton of features that I won\u0026rsquo;t make use of, but for the sake of a static site, think of Amplify as S3 + CloudFront + Git + CI/CD. In addition, Hugo has official documentation for hosting a site on Amplify.\nAmplify Setup The setup couldn\u0026rsquo;t have been easier. Again, following Hugo\u0026rsquo;s official documentation, you basically tell Amplify what GitHub repo you want to use, configure Amplify\u0026rsquo;s own CI/CD language (like GitHub Actions), and it will rebuild your site any time there is a commit.\nThe site URL Amplify gives you is something like https://branch-name.d1m7bkiki6tdw1.amplifyapp.com, but you also have the option to use a custom domain (like loganmarchione.com). If your DNS is through Route53 (like mine), Amplify will even setup your DNS records and generate a SSL/TLS certificate for you!\nWhat I liked Ease of setup - I can\u0026rsquo;t explain to you how easy this was. I had the site running in 2 minutes, and had it hosted on my domain with SSL/TLS in 10 minutes. Git-aware by default - Amplify is super-intuitive to setup if you are used to CI/CD pipelines. Besides GitHub, it supports Bitbucket, GitLab, and AWS CodeCommit. Custom HTTP headers - Amplify allows you to set custom HTTP headers, including security headers to prevent XSS attacks and clickjacking. Separate TEST/PROD sites - Amplify can setup one URL for testing and one for production, based on the branches you specify. Password protection - You can setup HTTP basic authentication to protect development or test sites so that the public can\u0026rsquo;t access them. What I didn\u0026rsquo;t like Lack of IPv6 support - As far as I can find, Amplify does not support IPv6 (yet). There was a GitHub issue that was closed as stale, so I\u0026rsquo;m guessing it\u0026rsquo;s not high on the AWS priority list. Even though I don\u0026rsquo;t browse my own site over IPv6 (my ISP doesn\u0026rsquo;t offer it), I want to offer IPv6 to my readers. The ability to arbitrarily host files on my VPS - I can\u0026rsquo;t understate how nice it is to have a VPS in the cloud. I can uploads some random files and then quickly create an Nginx alias to access them. I could replace that with S3, but I\u0026rsquo;m already paying for the VPS, might as well use it. Conclusion The lack of IPv6 support was the kicker for me, so I switched back to a DigitalOcean VPS for now. I\u0026rsquo;m considering the following things to try to get IPv6 working:\nTry to enable CloudFront in front of Amplify Test S3 + CloudFront If you host a Hugo site, tell me how! I\u0026rsquo;m open to any options!\n-Logan\n","permalink":"https://loganmarchione.github.io/2021/09/deploying-hugo-with-aws-amplify/","summary":"Hey! Listen! This post is part of a series on deploying Hugo. Check them all out!\nDate URL Part 2022-02-08 Deploying Hugo with Netlify Deploying on Netlify 2021-10-13 Deploying Hugo with CloudFront and S3 Deploying on CloudFront and S3 2021-09-21 Deploying Hugo with AWS Amplify Deploying on Amplify Introduction Since I migrated from WordPress to Hugo, I\u0026rsquo;ve dropped the need to run PHP and MySQL on my server. This means my server is now only running Nginx, serving up static HTML/CSS/JS files.","title":"Deploying Hugo with AWS Amplify"},{"content":"Introduction If you\u0026rsquo;ve ever used a Raspberry Pi, you\u0026rsquo;ve probably used the raspi-config configuration tool. This text-based user interface (TUI) is great for changing 99% of basic settings on the Raspberry Pi, such as the hostname, WiFi country, locale, memory split, etc\u0026hellip;\nHowever, if you\u0026rsquo;re managing a fleet of Raspberry Pi devices, or just really like configuration management tools, you\u0026rsquo;re probably looking for a way to automate setting these items from the command line. I\u0026rsquo;m not sure how I\u0026rsquo;ve never come across this, but I just learned that raspi-config has a mostly undocumented non-interactive mode that will do precisely that.\nMostly undocumented When I say \u0026ldquo;mostly undocumented\u0026rdquo;, I\u0026rsquo;m referring specifically to the non-interactive (nonint) mode of raspi-config. The raspi-config tool itself is documented, and the config.txt file (where a lot of Raspberry Pi settings are saved) is also documented. In fact, the only raspberrypi.org page I could find that referenced nonint was this issue of The MagPi.\nThe rest of the documentation for the non-interactive mode is from reading code. First was here, in the GTK version of the raspi-config tool. You can see all the commands that start with raspi-config nonint, such as raspi-config nonint do_wifi_country. Second was here, in the raspi-config tool itself. Since raspi-config is just a shell script, this was useful for getting function names, such as get_can_expand() and do_change_locale().\nThe non-interactive mode is basically split into two modes: get and do. get is for checking current settings, and do is for writing new settings.\nExamples Keep in mind that some of these changes will need a reboot to take effect.\nHostname To get the current hostname: sudo raspi-config nonint get_hostname To set a new hostname: sudo raspi-config nonint do_hostname NEW_HOSTNAME WiFi country To get the current WiFi country: sudo raspi-config nonint get_wifi_country To set a new WiFi country: sudo raspi-config nonint do_wifi_country US Locale I didn\u0026rsquo;t see a raspi-config command to get the current locale, but you can just run locale.\nTo set a new locale: sudo raspi-config nonint do_change_locale en_US.UTF-8 Memory split To get current GPU memory split: sudo raspi-config nonint get_config_var gpu_mem /boot/config.txt To set a new GPU memory split: sudo raspi-config nonint do_memory_split 256 Wait for network on boot To get current network on boot setting: sudo raspi-config nonint get_boot_wait To enable waiting for network on boot: sudo raspi-config nonint do_boot_wait 0 Pi hardware These commands won\u0026rsquo;t return any output to the terminal, but exit code 0 means true, exit code 1 means false. Interestingly, I didn\u0026rsquo;t see a command to check for a Pi 3.\nTo see if your device is a Pi 1: sudo raspi-config nonint is_pione To see if your device is a Pi 2: sudo raspi-config nonint is_pitwo To see if your device is a Pi Zero: sudo raspi-config nonint is_pizero To see if your device is a Pi 4: sudo raspi-config nonint is_pifour Use cases If you had a cluster of Raspberry Pi devices and wanted to see the GPU memory split on them, you could use an Ansible playbook or ad-hoc command.\nansible host_or_group_name_here -a \u0026#34;raspi-config nonint get_config_var gpu_mem /boot/config.txt\u0026#34; Then, if you wanted to change the devices in that cluster to have a minimal memory split, you could use another ad-hoc command (this assumes you have SSH and sudo setup on the target device(s)).\nansible host_or_group_name_here -a \u0026#34;raspi-config nonint do_memory_split 16\u0026#34; --become --ask-become-pass I\u0026rsquo;m using this exact setup in my homelab to keep my Pi settings the same across the board.\nConclusion Because these command are undocumented, I\u0026rsquo;m guessing they\u0026rsquo;re unsupported from the command line and could change at any time (see changes to raspi-config here). However, if you\u0026rsquo;re feeling adventurous and/or want to keep your settings in scripts or configuration management, this might be the option for you.\n-Logan\n","permalink":"https://loganmarchione.github.io/2021/07/raspi-configs-mostly-undocumented-non-interactive-mode/","summary":"Introduction If you\u0026rsquo;ve ever used a Raspberry Pi, you\u0026rsquo;ve probably used the raspi-config configuration tool. This text-based user interface (TUI) is great for changing 99% of basic settings on the Raspberry Pi, such as the hostname, WiFi country, locale, memory split, etc\u0026hellip;\nHowever, if you\u0026rsquo;re managing a fleet of Raspberry Pi devices, or just really like configuration management tools, you\u0026rsquo;re probably looking for a way to automate setting these items from the command line.","title":"Raspi-config's mostly undocumented non-interactive mode"},{"content":"Hey! Listen! This post is part of a series on the DeskMini H470 as a hypervisor. Check them all out!\nDate URL Part 2022-09-07 Adding a ZFS mirror to Proxmox Add a ZFS mirror to Proxmox 2022-09-02 Adding data center SSDs to the DeskMini H470 Add 2x Intel D3-S4510 to the DeskMini H470 2021-06-23 ASRock DeskMini H470 as a compact hypervisor Initial post about DeskMini H470 Introduction My hypervisor since 2017 has been an Intel NUC7i3BNH. It has a 2c/4t 15W laptop CPU (Core i3-7100U), with 2x 16GB Crucial DDR4, and a 512GB Samsung 860 Pro. While it served me well over these years, I\u0026rsquo;ve outgrown the CPU and cooling solution.\nThe search for a new hypervisor Size, noise, and power As outlined in my homelab mini-rack post, my homelab devices (router, switch, AP, NAS, and hypervisor) all sit on the bottom shelf of the entertainment center in my living room. Because of this, everything needs to be small, quiet, power efficient, and have a high WAF.\nWhen searching for a new hypervisor, my first requirements were size, noise, and power draw. Luckily for me, ServeTheHome has an excellent series called TinyMiniMicro where they review Lenovo Tiny, HP Mini, and Dell Micro PCs as servers. The ServeTheHome series gave me a great insight into the differences between manufacturers and models, as well as a starting point when looking for ultra-small form-factor (USFF) PCs.\nAMD vs Intel Normally, I would recommend AMD for almost any application, since the cores-per-dollar ratio is so good. However, in this case, one of the applications I will be running is Jellyfin, which can greatly benefit from hardware-enabled video transcoding. While AMD has its own hardware transcoding engine, it is nowhere near as efficient or as supported as Intel\u0026rsquo;s QuickSync. Because of that, I specifically looked for an Intel CPU with an integrated GPU.\nHardware comparison This Reddit post convinced me to go with the ASRock DeskMini H470, as it was almost exactly the same build as what I was looking for.\nBelow is a comparison of my current NUC and the new hypervisor (it\u0026rsquo;s obviously not a like-for-like comparison because of the CPU, cooler, and RAM differences).\nComponent Current (2017 prices) New (2021 pandemic prices) Base kit Intel NUC NUC7i3BNH - $282.99 ASRock DeskMini H470 - $200.99 CPU Intel Core i3-7100U (2c/4t @ 2.40GHz) Intel Core i5-10400 (6c/12t @ 2.90GHz) - $164.99 Memory Crucial 32GB Kit (2x 16GB) DDR4-2400 SODIMM - $173.00 Corsair 64GB Kit (2x 32GB) DDR4-2666 SODIMM - $358.99 Storage Samsung 860 Pro 2.5\" 512GB SATA SSD - $138.07 Samsung 970 Pro 512GB M.2 NVMe SSD - $149.99 Accessories N/A Noctua NH-L9i - $44.95 Total price $594.06 $919.91 Comments U-Series processor (laptop chip) Mediocre cooling Smallest footprint Standard processor (desktop chip) CPU socket (so I can upgrade the CPU later) Excellent cooling (due to aftermarket cooler) Build pics Other devices that didn\u0026rsquo;t make the cut 11th Generation Intel NUC This was an upgrade of the problems I had to begin with: U-Series processors (laptop chip) with poor cooling. Lenovo Tiny, HP Mini, and Dell Micro These were all basically the same devices, with different physical layouts: T-Series processors (low-power chip), a poor CPU heatsink, a blower fan, and limited expansion options. Dell Precision 3240 Compact I really wanted to like this. It offered Intel Core or Xeon processors, the latter of which could use ECC memory, in a super-small form-factor. It had different heatsinks for the Core vs Xeon models, but both the Core (one, two, three) and Xeon (one) models suffered from poor thermals and loud fans. HPE ProLiant MicroServer Gen10 Plus The included Xeon processor (Xeon E-2224) was only 4c/4t and it didn\u0026rsquo;t support QuickSync. Although you could physically replace the CPU, there was a BIOS limitation by HP that prevented QuickSync from working. The included cooler and external PSU (180W) probably couldn\u0026rsquo;t handle processors rated for more than 71W, which really limited my options for CPUs with more cores. There was a single PCIe slot which I could use to install a small GPU (e.g., Nvidia Quadro P400), or run a PCIe-to-NVMe card for a boot drive, but not both. Hardware-specific things 11th Generation CPUs General issues According to this post, there may be some problems with 11th Generation CPUs on the DeskMini H470. I purchased a 10th Generation CPU, so I can\u0026rsquo;t confirm this. Just something to be aware of.\nBIOS update The DeskMini H470 BIOS was recently updated to version v2.00 to support Intel 11th Generation CPUs. However, as confirmed by this post, if your BIOS is v1.x, you can\u0026rsquo;t update it to v2.x with an 11th Generation CPU installed. You would need a 10th Generation CPU to perform the update (unless you got lucky and your DeskMini H470 shipped with the v2.x BIOS already installed).\nMy device shipped with BIOS v2.10 (see the red circle below), so it should support Intel 11th Generation CPUs out of the box.\nStorage The DeskMini H470 has four storage connections:\n2x 2.5\u0026quot; HDD/SSD (proprietary SATA connector) 1x 2280 PCIe Gen3 NVMe SSD (M.2 connector) 1x 2280 PCIe Gen4 NVMe SSD (M.2 connector) This only works when using 11th Generation CPUs. Right now, I\u0026rsquo;m running Proxmox and the VM storage on the same NVMe SSD. However, I will probably end up purchasing 2x SATA SSDs to run in RAID1 for VM storage.\nMotherboard flex There is a little bit of motherboard flex from the cooler because this cooler does not have a backplate. Not sure if that will be a problem, I guess we\u0026rsquo;ll see.\nIf you zoom in, the red line is drawn between the two motherboard screws, and you can see a tiny gap between the red line and the motherboard.\nSensors and VRM temperatures According to this post, the temperature sensor kernel driver (nct6683) is not loaded by default. I confirmed this was the case and loaded it manually.\nBoth KitGuru and AnandTech commented about the high VRM temperatures on the DeskMini H470. However, ASRock is known to produce motherboards with fake sensors, so I\u0026rsquo;m not sure if this is related. I\u0026rsquo;m also not sure which of these (if any) are the VRM sensors.\nnct6683-isa-0a20 Adapter: ISA adapter VIN0: +0.58 V (min = +0.00 V, max = +0.00 V) VIN1: +1.01 V (min = +0.00 V, max = +0.00 V) VIN2: +1.02 V (min = +0.00 V, max = +0.00 V) VIN3: +1.01 V (min = +0.00 V, max = +0.00 V) VIN7: +1.20 V (min = +0.00 V, max = +0.00 V) VIN16: +1.07 V (min = +0.00 V, max = +0.00 V) VCC: +3.33 V (min = +0.00 V, max = +0.00 V) fan1: 1498 RPM (min = 0 RPM) fan2: 0 RPM (min = 0 RPM) Thermistor 12: +43.0¬∞C (low = +0.0¬∞C) (high = +0.0¬∞C, hyst = +0.0¬∞C) (crit = +0.0¬∞C) sensor = thermistor Thermistor 13: +37.0¬∞C (low = +0.0¬∞C) (high = +0.0¬∞C, hyst = +0.0¬∞C) (crit = +0.0¬∞C) sensor = thermistor PECI 0.0: +45.5¬∞C (low = +0.0¬∞C) (high = +0.0¬∞C, hyst = +0.0¬∞C) (crit = +0.0¬∞C) sensor = Intel PECI intrusion0: OK beep_enable: disabled pch_cometlake-virtual-0 Adapter: Virtual device temp1: +63.0¬∞C coretemp-isa-0000 Adapter: ISA adapter Package id 0: +49.0¬∞C (high = +84.0¬∞C, crit = +100.0¬∞C) Core 0: +47.0¬∞C (high = +84.0¬∞C, crit = +100.0¬∞C) Core 1: +41.0¬∞C (high = +84.0¬∞C, crit = +100.0¬∞C) Core 2: +49.0¬∞C (high = +84.0¬∞C, crit = +100.0¬∞C) Core 3: +44.0¬∞C (high = +84.0¬∞C, crit = +100.0¬∞C) Core 4: +42.0¬∞C (high = +84.0¬∞C, crit = +100.0¬∞C) Core 5: +47.0¬∞C (high = +84.0¬∞C, crit = +100.0¬∞C) Linux e1000e driver There is a known issue where the Intel NIC e1000e kernel driver can crash/hang when under heavy load. In my case, this happened when my VM for backups was pushing data up to the cloud. Below is what I saw in dmesg on the Proxmox host.\nJun 22 21:40:32 proxmox02 kernel: [37615.515931] e1000e 0000:00:1f.6 eno1: Detected Hardware Unit Hang: Jun 22 21:40:32 proxmox02 kernel: [37615.515931] TDH \u0026lt;a5\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] TDT \u0026lt;40\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] next_to_use \u0026lt;40\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] next_to_clean \u0026lt;a4\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] buffer_info[next_to_clean]: Jun 22 21:40:32 proxmox02 kernel: [37615.515931] time_stamp \u0026lt;1008e50da\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] next_to_watch \u0026lt;a5\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] jiffies \u0026lt;1008e5848\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] next_to_watch.status \u0026lt;0\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] MAC Status \u0026lt;40080083\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] PHY Status \u0026lt;796d\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] PHY 1000BASE-T Status \u0026lt;3c00\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] PHY Extended Status \u0026lt;3000\u0026gt; Jun 22 21:40:32 proxmox02 kernel: [37615.515931] PCI Status \u0026lt;10\u0026gt; Below is the output from lspci -v on the Proxmox host. You can see I\u0026rsquo;m using the e1000e driver.\n00:1f.6 Ethernet controller: Intel Corporation Device 0d4d Subsystem: ASRock Incorporation Device 0d4d Flags: bus master, fast devsel, latency 0, IRQ 137 Memory at b1200000 (32-bit, non-prefetchable) [size=128K] Capabilities: [c8] Power Management version 3 Capabilities: [d0] MSI: Enable+ Count=1/1 Maskable- 64bit+ Kernel driver in use: e1000e Kernel modules: e1000e This crash/hang happens because the NIC has hardware offload capabilities, but it can\u0026rsquo;t keep up with the amount of data being pushed through. The fix (as documented in this large Proxmox-specific thread) is to disable offloading and let everything be handled by the CPU. In my case, I only disabled tcp-segmentation-offload, generic-segmentation-offload, and generic-receive-offload.\nThe following snippet is from my /etc/network/interfaces file on the Proxmox host.\nauto eno1 iface eno1 inet manual offload-tso off offload-gso off offload-gro off After a reboot of the host, you can verify the settings using ethtool -k eno1. Again, this is not specific to ASRock or Proxmox, it seems to be any Linux distribution using the e1000e driver.\nConclusion So far, I\u0026rsquo;m only a few days into this new hypervisor, but it\u0026rsquo;s already leaps and bounds better than the NUC, especially under any sort of load.\n-Logan\n","permalink":"https://loganmarchione.github.io/2021/06/asrock-deskmini-h470-as-a-compact-hypervisor/","summary":"Hey! Listen! This post is part of a series on the DeskMini H470 as a hypervisor. Check them all out!\nDate URL Part 2022-09-07 Adding a ZFS mirror to Proxmox Add a ZFS mirror to Proxmox 2022-09-02 Adding data center SSDs to the DeskMini H470 Add 2x Intel D3-S4510 to the DeskMini H470 2021-06-23 ASRock DeskMini H470 as a compact hypervisor Initial post about DeskMini H470 Introduction My hypervisor since 2017 has been an Intel NUC7i3BNH.","title":"ASRock DeskMini H470 as a compact hypervisor"},{"content":"Introduction When I was running WordPress, I was using Matomo (formerly Piwik) for analytics. This solution worked for me, but was more complicated than I needed, and I didn\u0026rsquo;t make use of 99% of the features. It also required PHP and MySQL/MariaDB, which were not installed on the new server hosting my Hugo-based blog. Because of this, I wanted to switch to a simpler analytics solution.\nSelf-hosted vs SaaS For a long time, I\u0026rsquo;ve hosted a Matomo instance on my server and proudly stated in my privacy policy:\nI host my own Matomo instance. Your data never leaves my server.\nI did this to protect my users and respect their privacy. Additionally, if a user didn\u0026rsquo;t want to be tracked: I set Matomo to respect their browser\u0026rsquo;s Do Not Track header, or they could install something like NoScript or uBlock Origin, or they could disable JavaScript completely.\nI started to look for a self-hosted, privacy-respecting analytics solution. In the end, however, the technical cost of installing, maintaining, and securing a self-hosted solution wasn\u0026rsquo;t worth it (not to mention the technical debt of PHP plus MySQL), so I decided to switch to SaaS.\nComparison Hugo comes with built-in support for Google Analytics, which I obviously didn\u0026rsquo;t use. While I found quite a few quality analytics products, I only specifically looked at solutions that allowed self-hosting. My reasoning was: if they\u0026rsquo;re confident enough in their product to open-source it and allow me to host it, I\u0026rsquo;m confident enough to pay them for it.\nSoftware Hosting type Self-hosted version? Stack Pricing (lowest tier) Google Analytics SaaS No N/A Free tier Simple Analytics SaaS No N/A $19/month Matomo Self-hosted and SaaS Yes PHP and MySQL Free (self-hosted) or $29/month (SaaS) Fathom Self-hosted and SaaS Yes Go and MySQL Free (self-hosted) or $14/month (SaaS) Plausible Self-hosted and SaaS Yes Elixir and PostgreSQL Free (self-hosted) or $6/month (SaaS) GoatCounter Self-hosted and SaaS Yes Go and PostgreSQL Free (self-hosted) or Free (SaaS) userTrack Self-hosted and SaaS Yes (but not open-source) PHP and MySQL $99 lifetime (self-hosted) or $25/month (SaaS) Open Web Analytics Self-hosted Yes PHP and MySQL Free (self-hosted) Umami Self-hosted Yes Node and MySQL Free (self-hosted) Ackee Self-hosted Yes Node and MongoDB Free (self-hosted) In the end, I decided on Plausible analytics because:\nthey are privacy-respecting they are GDPR-compliant (e.g., no cookies, no individual user tracking, no PII, etc\u0026hellip;) and don\u0026rsquo;t require a pop-up for consent they are the most affordable SaaS solution (and offer a 30-day free trial) they have a lightweight (\u0026lt;1KB) JavaScript tag they offer simple dashboards they are independent developers Plausible setup From Plausible\u0026rsquo;s Hugo documentation, installation was pretty easy and I chose to simply add the tracking code to my theme\u0026rsquo;s \u0026lt;head\u0026gt; section.\n\u0026lt;script async defer data-domain=\u0026#34;loganmarchione.com\u0026#34; src=\u0026#34;https://plausible.io/js/plausible.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; I\u0026rsquo;m still on the 30-day free trial, but I don\u0026rsquo;t see myself switching to anything else. They offer a ton of useful features that I may take advantage of in the future:\nCustom domains (to serve the script from loganmarchione.com instead of plausible.io) Email reports Traffic spike notification Public website stats Google Search console integration (to see the Google search terms) 404 page tracking -Logan\n","permalink":"https://loganmarchione.github.io/2021/03/analytics-with-hugo/","summary":"Introduction When I was running WordPress, I was using Matomo (formerly Piwik) for analytics. This solution worked for me, but was more complicated than I needed, and I didn\u0026rsquo;t make use of 99% of the features. It also required PHP and MySQL/MariaDB, which were not installed on the new server hosting my Hugo-based blog. Because of this, I wanted to switch to a simpler analytics solution.\nSelf-hosted vs SaaS For a long time, I\u0026rsquo;ve hosted a Matomo instance on my server and proudly stated in my privacy policy:","title":"Analytics with Hugo"},{"content":"Introduction Hopefully this page is coming at you blazing fast, and with a new look! If so, you\u0026rsquo;re seeing my static site generated by Hugo. Here\u0026rsquo;s some high-level thoughts about the migration from WordPress, which I\u0026rsquo;ve been using since 2014, to Hugo.\nWhy I\u0026rsquo;m switching You can Google \u0026ldquo;wordpress to hugo\u0026rdquo; and read 1000 posts about why people make the switch. Here are my reasons:\nSecurity WordPress is written in PHP, which has an unfairly bad reputation. I think the WordPress core codebase is actually pretty good. If you\u0026rsquo;re running a vanilla blog with no plugins or custom themes, you\u0026rsquo;re probably safe enough (as long as you turn on auto-update).\nHowever, the plugin community scares me. Some plugins are written by professional developers, but most are written by hobbyists. A quick search for \u0026ldquo;wordpress plugin vulnerability\u0026rdquo; will lead to endless pages of problems.\nSpeed Every time you visit a WordPress page, PHP takes the request, gets the content from the database, gets the images from the filesystem, bundles it all into an HTML file, and ships it to your browser.\nThis process is fast, especially with PHP7, but it will never be as fast as pre-rendered HTML.\nMiscellaneous Constant bot spam (even with Akismet) Terrible new editor (Gutenberg) No version control High-level overview of cutover process My cutover process involved:\nInstall Hugo locally Find a Hugo theme Export WordPress content Convert WordPress content Fix small mistakes in each post (hint - this was the longest step) Publish to webserver More details on each step are below.\nInstall Hugo locally I run Arch Linux, so installing Hugo was easy.\nFind a Hugo theme On WordPress, I happily paid for the GeneratePress theme. It was super light, fast, and customizable. With Hugo, I was looking for the following:\nSearch Table of Contents Light/dark mode RSS Featured image I found the equally-excellent PaperMod on GitHub and it met all my needs. The developer accepts donations, so I\u0026rsquo;m happy to support their work!\nExport WordPress content Exporting content from WordPress was easy, no problems there.\nConvert WordPress content This is where the trouble started. There are numerous \u0026ldquo;WordPress-to-Hugo\u0026rdquo; converters online, but none of them are perfect. In fact, Hugo doesn\u0026rsquo;t even have an official tool, they rely on community projects. While many tools will produce some useable content, their quality varies depending on how customized your WordPress content is. As such, you really can\u0026rsquo;t blame any single tool for not working 100%.\nI first tried the tool SchumacherFM/wordpress-to-hugo-exporter. The output it produced was a mix of Markdown and HTML, so I wasn\u0026rsquo;t a fan of that. However, as a huge plus, it did allow the export of comments for each post, which I did make use of.\nI then found the lonekorean/wordpress-export-to-markdown converter, which produced much cleaner output, but no comments. This is the tool I ultimately used.\nI also tried these tools as well, but settled on the two above:\nhttps://github.com/palaniraja/blog2md https://github.com/kylekarpack/wp-to-md Fix small mistakes in each post This was the worst part and took about 10-12 hours total. Each post needed a ton of small fixes, including, but not limited to:\nFix frontmatter (date, URL slugs, categories, featured image, etc\u0026hellip;) Make sure the new URL slug matched the old slug (e.g., DEV site vs PRD site) Remove WordPress shortcodes and replace with Hugo shortcodes Find/replace images from the URL path (e.g., loganmarchione.com/wp-contents/uploads) to the relative path (e.g., /wp-content/uploads) Later realize that was dumb and I should have used Page Bundles from the start. Spend hours redoing the images. Correcting code snippets created with \u0026lt;pre\u0026gt; tags Find/replace random character strings created by escape characters (e.g., \\_, \\*, \\[, \\-, \\` , \u0026lt;_, ._) Use a ton of regexes to search for inter-blog links, bold text, underlined text, strikethrough text, etc\u0026hellip; Publish to webserver This was pretty easy, just run hugo server and you\u0026rsquo;ll get a /public folder you can zip up and SFTP to the webserver. I also setup a GitHub Actions workflow based on this post to build the site and rsync it to my webserver.\nThings I\u0026rsquo;m losing Comments - This is the thing I will miss the most. I really liked the comments and interacting with my readers, but spam was a constant problem. I have archived the comments on the pages that had them, but won\u0026rsquo;t be accepting new comments. I was considering Disqus, but heard bad things about privacy as well as speed. Analytics - I was using a self-hosted instance of Matomo, but will probably remove that because I\u0026rsquo;m removing PHP and MariaDB from the server. I may switch to something privacy-respecting like Plausible or Fathom. I setup Plausible, read about it here! To-do I still need to work on:\nGit LFS for storing images Find a spell-checker for VSCode Speedtest Here are the PageSpeed Insights scores for my latest post while on WordPress (mobile then desktop):\nAnd again on Hugo (mobile then desktop):\n-Logan\n","permalink":"https://loganmarchione.github.io/2021/02/migrating-from-wordpress-to-hugo/","summary":"Introduction Hopefully this page is coming at you blazing fast, and with a new look! If so, you\u0026rsquo;re seeing my static site generated by Hugo. Here\u0026rsquo;s some high-level thoughts about the migration from WordPress, which I\u0026rsquo;ve been using since 2014, to Hugo.\nWhy I\u0026rsquo;m switching You can Google \u0026ldquo;wordpress to hugo\u0026rdquo; and read 1000 posts about why people make the switch. Here are my reasons:\nSecurity WordPress is written in PHP, which has an unfairly bad reputation.","title":"Migrating from WordPress to Hugo"},{"content":"Hey! Listen! This post is part of a series on 10\u0026quot; mini-racks. Check them all out!\nDate URL Part 2022-09-16 Homelab 10\u0026quot; mini-rack shelves Comparison of 10\u0026quot; shelves 2021-01-05 Homelab 10\u0026quot; mini-rack Initial post about mini-rack Update: 2021-01-10 I made the following changes and updated the post below (not the pictures) to reflect those changes:\nReplaced side vent panels with metal bars Added labels to patch panel One of the RJ45 couplers was stuck in 100Mbps mode and would not transfer full 1Gbps. I switched it around to a device that only has a 100Mbps NIC (IP camera) Introduction I don\u0026rsquo;t have space in my house for a full-size 19\u0026quot; server rack (but a man can dream). My fiber internet service comes into the basement and terminates at the ONT. A Cat6 cable runs from the ONT in the basement, up through the ceiling directly above it where it plugs into my router. The hole drilled through the first floor is hidden by the entertainment center that houses all the equipment. My entire homelab lives on the bottom shelf of that piece of furniture and is designed to be low-power and quiet (since it\u0026rsquo;s in my living room):\npfSense router (APU2D4) Netgear switch (GS108PE) UniFi AP (UAP-AC-PRO) Intel NUC (NUC7i3BNH) Synology DS 718+ CyberPower UPS (CP1500PFCLCD) It\u0026rsquo;s a pretty small setup that only draws 50-60 watts, but lets me run 10+ VMs and 25+ containers. However, physically organizing it has been a pain. I\u0026rsquo;ve been using a small cabinet shelf (made for kitchen plates) and zip-ties to separate the router, switch, and AP, but it was ugly and various lengths of Cat6 were everywhere.\nRacks typically come in 19\u0026quot; widths, but I had seen a few Reddit posts about 10\u0026quot; racks (one, two) and a bunch of 3D printed solutions (one, two, three, four, five, six). However, these racks were usually custom-made, or typically sourced from parts in Europe (apparently 10\u0026quot; is a popular rack size there).\nThen, I stumbled onto this post. It stuck out to me because the user was based in the US, it required very little metal-work, no 3D printing, and he included a parts list. It was a proper rack, just shrunk down to 10\u0026quot;. This is my attempt to recreate that rack.\nPresenting: The mini-rack Pictures And here is the obligatory GIF of the blinkenlights.\nYour browser does not support video. Parts This rack is based on the post from u/othugmuffin, but I changed a few things to better suit my needs.\nPart Link Quantity Price (per unit) Total price Comments Rack posts Penn Elcom Online 4 $1.94 $7.76 The shelf where this rack is going only fits a full 4U rack (5U is too tall), but I was able to cut off 1/3-of-a-U on a 5U rack (for a total of 4.66U height) Cage nuts Penn Elcom Online 50 $0.18 $9.00 I\u0026rsquo;m only using 24 Cage screws (M6) Penn Elcom Online 1 $12.24 $12.24 The ones with the tapered ends make catching the threads so much easier Cage nut tool Penn Elcom Online 1 $16.05 $16.05 Optional, but makes life much easier 10\u0026quot; blank patch panel Amazon 1 $25.39 $25.39 This patch panel has a mounting plate for the keystones, whereas the panel u/othugmuffin used did not (which would cause the keystones to stick out in the front) 10\u0026quot; rack shelf Amazon 3 $15.95 $47.85 I wish these were a little deeper 10\u0026quot; vent panel Amazon 2 $12.00 $24.00 These are used on the back (where u/othugmuffin used aluminum bars that he had to cut/drill) 7.8‚Äù mending plate 6-pack Amazon 1 $14.97 $14.97 Used on the sides. I was originally using the 10\u0026quot; vent panels but ended up switching to these Cat6 RJ45 shielded coupler keystones FS.com 12 $2.00 $24.00 I only used shielded because I liked the silver color Cat6 patch cables 5-pack (1ft) Amazon 2 $9.99 $19.98 I tried 6-inch cables, but they were so stiff they lifted the switch off the shelf Rubber feet Amazon 1 $8.22 $8.22 To cover the cut ends of the rack posts Misc screws/washers/nuts Lowes ~$8 ~$8 $217.46 total Physical layout Here is how everything is physically connected.\n----------------------------------------------------------- | | | ------------ | ------|-\u0026gt;| UniFi AP | | | | ------------ | | | | | ----------------------------------------------------------- | | | ----------------------------------------------------------- | | AP Camera NAS NUC Roku LAN | | | ------ ------ ------ ------ ------ ------ ------ ------ | ----------------- | | | 01 | | 02 | | 03 | | 04 | | 05 | | 06 | | 07 | | 08 | | | | | | ------ ------ ------ ------ ------ ------ ------ ------ | | FiOS Internet | | | ^ ^ ^ ^ ^ ^ | | ^ | | -----|------|--------------------|------|------|------|---- ------------|---- | | | | | | | | | | | | | | -------------------------------------- | | | | | | | | | -----|------|--------------------|------|------|----------------------------------|---- | | | v v v v v v | | | | ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ | | | | | 01 | | 02 | | 03 | | 04 | | 05 | | 06 | | 07 | | 08 | | 09 | | 10 | | 11 | | 12 | | | | | ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ | | | | ^ ^ | | | -----|----------------------------------------------------------------------------|---- | | | | | ------------ | | | | ----------------------------------------------------------- | | | | | | | ------- ------- ------- | | | | | WAN | | LAN | | OPT | | | | | ------- ------- ------- | | | | ^ ^ | | | --------|--------------------|----------------------------- | | | | | | ---------------------|----------------------------------------------------- | | | --------------------------------------------------------------- To-do Replace side vent panels with metal bars (will require cutting and drilling) Cheaper Custom length Add labels to patch panel Try Monoprice SlimRun Cat6 patch cables (which should bend easier) Find deeper shelves https://commsonline.co.uk/products/1u-10-inch-mini-cabinet-shelf Conclusion If you have a 10\u0026quot; rack, let me know about it! I\u0026rsquo;m looking to improve mine and would love to find other parts retailers in the US.\nAlso, shout-out to my wife for letting me put this monstrosity in the living room. Her only complaint during the whole thing was \u0026ldquo;it\u0026rsquo;s no uglier than what you have there now\u0026rdquo;.\nThanks for reading!\n-Logan\n","permalink":"https://loganmarchione.github.io/2021/01/homelab-10-mini-rack/","summary":"Hey! Listen! This post is part of a series on 10\u0026quot; mini-racks. Check them all out!\nDate URL Part 2022-09-16 Homelab 10\u0026quot; mini-rack shelves Comparison of 10\u0026quot; shelves 2021-01-05 Homelab 10\u0026quot; mini-rack Initial post about mini-rack Update: 2021-01-10 I made the following changes and updated the post below (not the pictures) to reflect those changes:\nReplaced side vent panels with metal bars Added labels to patch panel One of the RJ45 couplers was stuck in 100Mbps mode and would not transfer full 1Gbps.","title":"Homelab 10\" mini-rack"},{"content":"Introduction I\u0026rsquo;m on a quest to SSL all the things on my local network. I work in IT security, and am more than paranoid when it comes to my homelab (shout-out to r/homelab and r/selfhosted).\nFor my web applications, everything is accessed through a Nginx reverse proxy that uses Let\u0026rsquo;s Encrypt wildcard certificates (using the DNS challenge) for encryption. It provides a single choke-point for all my traffic, all using one wildcard certificate, and all my clients accept it with the green lock.\nHowever, connections between servers/applications are usually not encrypted. For example, I run a bunch of applications in Docker, but one thing I keep on a separate VM are my databases (specifically, PostgreSQL). Some of my Docker containers (specifically, Gitea, Drone, and Miniflux) connect to this database, but these connections are not encrypted.\n------------------ | Docker | | | | ------------ | | | | | | | Gitea |--|-\\ | | | | \\ | ------------ | \\ | | \\ | ------------ | \\ ------------ | | | | \\ | (VM) | | | Drone |--|-------------\u0026gt; | Postgres | | | | | / | | | ------------ | / ------------ | | / | ------------ | / | | | | / | | Miniflux |--|-/ | | | | | ------------ | | | ------------------ My plan is to:\nget a certificate on the database server make Postgres use those certificates make my applications connect to Postgres over SSL Get a certificate I could generate a self-signed SSL certificate on the database server, and just tell the clients to trust it (even though it is not signed). However, since Let\u0026rsquo;s Encrypt is so easy to use, I figured I\u0026rsquo;d try that first, and go from there.\nI won\u0026rsquo;t go over how to request a certificate from Let\u0026rsquo;s Encrypt. I used Certbot, requesting the certificate only (since there\u0026rsquo;s no webserver needed). In the end, we need the two certificate files below (where postgres.yourdomain.com is the name of the Postgres server from the certificate request).\n/etc/letsencrypt/live/postgres.yourdomain.com/fullchain.pem /etc/letsencrypt/live/postgres.yourdomain.com/privkey.pem Configure Postgres Edit Postgres configuration First, edit the configuration file at /etc/postgresql/VERSION/main/pg_hba.conf, where VERSION is your Postgres version (mine is 11). Change host to hostssl on the line where the server listens for external connections (e.g., 0.0.0.0/0).\nhostssl all all 0.0.0.0/0 md5 Normally, you would set the certificate and key paths in the Postgres configuration file, restart, and be good to go. However, Postgres won\u0026rsquo;t have permissions to read the certificates, but if we change the permissions, Certbot won\u0026rsquo;t renew the certificates. Also, symlinks won\u0026rsquo;t work (I tried).\nEdit the configuration file at /etc/postgresql/VERSION/main/postgresql.conf, where VERSION is your Postgres version (mine is 11). Find the SSL section, then edit it to enable SSL and specify the locations of the certificate and key.\nssl = on ssl_cert_file = \u0026#39;/etc/postgresql/11/main/fullchain.pem\u0026#39; ssl_key_file = \u0026#39;/etc/postgresql/11/main/privkey.pem\u0026#39; Next, run the commands below to copy the certificates from their original location to the Postgres configuration folder, change their permissions, then restart Postgres (change the paths as necessary).\ncp /etc/letsencrypt/live/postgres.yourdomain.com/fullchain.pem /etc/postgresql/11/main/fullchain.pem cp /etc/letsencrypt/live/postgres.yourdomain.com/privkey.pem /etc/postgresql/11/main/privkey.pem chmod 600 /etc/postgresql/11/main/fullchain.pem /etc/postgresql/11/main/privkey.pem chown postgres:postgres /etc/postgresql/11/main/fullchain.pem /etc/postgresql/11/main/privkey.pem systemctl restart postgresql Test Postgres connection Check the logs for Postgres (probably located at /var/log/postgresql) to make sure there were no errors starting. You may see errors from your applications trying to connect in a non-secure way, but we\u0026rsquo;ll fix that shortly. From a separate server, check that Postgres is communicating with a certificate (OpenSSL recently added this feature).\nopenssl s_client -starttls postgres -connect postgres.yourdomain.com:5432 \u0026lt;/dev/null Configure clients Luckily for me, Gitea, Drone, and Miniflux are all written in Go. Because of this, they use the lib/pq library to connect to Postgres databases, which means they all use the same connection string. All I needed to change was the sslmode option from disable to verify-full, then restart the applications (in my case, the Docker containers).\npostgres://user:password@postgres.yourdomain.com:5432/database_name?sslmode=verify-full As long as the Docker image you\u0026rsquo;re using has the ca-certificates package installed, you\u0026rsquo;re good to use verify-full or verify-ca, since Let\u0026rsquo;s Encrypt is in the list of valid root certificates.\nCheck clients (on the database) Now, back on the Postgres database, run the command below.\nSELECT ssl.pid, usename, datname, ssl, ssl.version, ssl.cipher, ssl.bits, ssl.compression, client_addr FROM pg_catalog.pg_stat_ssl ssl, pg_catalog.pg_stat_activity activity WHERE ssl.pid = activity.pid; Here, we can see the clients are all connected via SSL.\npid | usename | datname | ssl | version | cipher | bits | compression | client_addr -----+----------+------------+-----+---------+------------------------+------+-------------+------------- 4880 | | | f | | | | | 4882 | postgres | | f | | | | | 5270 | postgres | postgres | f | | | | | 5927 | miniflux | dbminiflux | t | TLSv1.3 | TLS_AES_256_GCM_SHA384 | 256 | f | 10.10.1.32 5931 | gitea | dbgitea | t | TLSv1.3 | TLS_AES_256_GCM_SHA384 | 256 | f | 10.10.1.32 5937 | drone | dbdrone | t | TLSv1.3 | TLS_AES_256_GCM_SHA384 | 256 | f | 10.10.1.32 5939 | drone | dbdrone | t | TLSv1.3 | TLS_AES_256_GCM_SHA384 | 256 | f | 10.10.1.32 5935 | gitea | dbgitea | t | TLSv1.3 | TLS_AES_256_GCM_SHA384 | 256 | f | 10.10.1.32 4878 | | | f | | | | | 4877 | | | f | | | | | 4879 | | | f | | | | | (11 rows) Certbot post-renew hook The keen-eyed among you may have noticed that we copied the certificates from the Let\u0026rsquo;s Encrypt directory to the Postgres directory. In 90 days when these certificates renew, we\u0026rsquo;ll need to re-copy them. Conveniently, Certbot includes a way to run commands after a certificate is renewed, called a post-hook. In my case, I\u0026rsquo;ll renew the certificate via cronjob, and run the same copy commands as before, but all in one line. It\u0026rsquo;s not pretty, but it gets the job done (you could also make this into a bash script).\n# LE cert renewal 14 08 * * * /opt/certbot/bin/certbot renew --post-hook \u0026#34;cp /etc/letsencrypt/live/postgres.yourdomain.com/fullchain.pem /etc/postgresql/11/main/fullchain.pem \u0026amp;\u0026amp; cp /etc/letsencrypt/live/postgres.yourdomain.com/privkey.pem /etc/postgresql/11/main/privkey.pem \u0026amp;\u0026amp; chmod 600 /etc/postgresql/11/main/fullchain.pem /etc/postgresql/11/main/privkey.pem \u0026amp;\u0026amp; chown postgres:postgres /etc/postgresql/11/main/fullchain.pem /etc/postgresql/11/main/privkey.pem \u0026amp;\u0026amp; systemctl restart postgresql\u0026#34; --quiet Conclusion My other solution to this problem was to run Postgres in the same Docker stack as the application, eliminating the need for any traffic to cross the network. I still may do this in the future, but then it requires managing three instances of Postgres instead of one.\n--------------------------------- | Docker | | | | ------------ ------------ | | | | | | | | | Gitea |--\u0026gt;| Postgres | | | | | | | | | ------------ ------------ | | | | ------------ ------------ | | | | | | | | | Drone |--\u0026gt;| Postgres | | | | | | | | | ------------ ------------ | | | | ------------ ------------ | | | | | | | | | Miniflux |--\u0026gt;| Postgres | | | | | | | | | ------------ ------------ | | | --------------------------------- Thanks for reading!\n-Logan\n","permalink":"https://loganmarchione.github.io/2020/10/securing-postgres-connections-using-lets-encrypt-certificates/","summary":"Introduction I\u0026rsquo;m on a quest to SSL all the things on my local network. I work in IT security, and am more than paranoid when it comes to my homelab (shout-out to r/homelab and r/selfhosted).\nFor my web applications, everything is accessed through a Nginx reverse proxy that uses Let\u0026rsquo;s Encrypt wildcard certificates (using the DNS challenge) for encryption. It provides a single choke-point for all my traffic, all using one wildcard certificate, and all my clients accept it with the green lock.","title":"Securing Postgres connections using Let's Encrypt certificates"},{"content":"Introduction I have a small homelab in my home that runs pfSense, Proxmox, Docker, a Synology NAS, UniFi wireless, etc\u0026hellip; I already monitor my pfSense firewall logs using Graylog, but I was looking for a solution to monitor hardware (e.g., CPU usage, RAM usage, etc\u0026hellip;) as well as software processes (e.g., containers using network, current download/upload speed, etc\u0026hellip;).\nI stumbled upon two separate software stacks for this. First is the TICK stack, which is composed of open-source products from InfluxData:\nTelegraf - collect and send metrics InfluxDB - database to store metrics Chronograf - graph metrics Kapacitor - alerting based on metrics Second is the TIG stack:\nTelegraf - collect and send metrics InfluxDB - database to store metrics Grafana - graph metrics Ultimately, I chose the TIG stack because Grafana can handle more data sources than Chronograf (e.g., ElasticSearch, Prometheus, SQL, etc\u0026hellip;). I setup my TIG stack pretty easily, and Grafana has a marketplace where users can upload dashboards, so I was able to quickly find some working examples.\nHowever, to monitor my homelab, I needed to be logged into Grafana, which would distract from my primary display. Instead, I wanted a separate display with a mini-version of the Network Operations Center from somewhere like NASA or Akamai.\nHardware setup For this setup, I purchased the following hardware:\nRaspberry Pi - $35.00 (I had a 3B+ lying around from a kit) MicroSD card - $5.79 Raspberry Pi 7\u0026quot; Touchscreen Display - $61 Pibow Touchscreen Frame - $12.20 Be warned, however, the power supply with my kit was giving me the Under-voltage detected! warning. I will eventually upgrade to the official Raspberry Pi Universal Power Supply and a dual microB USB power cable.\nThe assembly was pretty easy:\nRemove the display from the package (leave the protective film on for now) Follow these instructions to install the display in the Pibow frame Follow these instructions to attach the Raspberry Pi to the display Raspbian setup Raspbian Because I\u0026rsquo;m using the official Raspberry Pi touchscreen, I wanted to use Raspbian to ensure the touchscreen would work properly (e.g., drivers, calibration, etc\u0026hellip;). Because the Raspberry Pi is limited on both memory and storage space, I always prefer to use Raspbian Lite and then add a desktop, as opposed to using Raspbian Desktop and then stripping out unneeded packages (e.g., LibreOffice, Wolfram, Sonic Pi, Scratch, etc\u0026hellip;).\nI won\u0026rsquo;t cover how to install Raspbian to a SD card, since the Raspberry Pi Foundation already has a pretty good guide on their site. I\u0026rsquo;ll be assuming you have already:\nInstalled Raspbian and have it booted properly (you can login via SSH, or a local keyboard/mouse) Used sudo raspi-config to Expand the filesystem Set the hostname Set the locale Setup a network connection or WiFi Set boot mode to Desktop Autologin Screen rotation My screen was upside-down on the initial boot. Use the command below to rotate both the screen and touch input 180¬∞.\necho \u0026#34;lcd_rotate=2\u0026#34; | sudo tee -a /boot/config.txt sudo reboot Here is the boot process (ignore my bad GIF-making skills, the bright spot on the screen is a light in my kitchen).\nYour browser does not support video. Desktop installation First, make sure you\u0026rsquo;re up-to-date with all packages.\nsudo apt update \u0026amp;\u0026amp; sudo apt dist-upgrade \u0026amp;\u0026amp; sudo apt autoclean Next, install the X Window server.\nsudo apt install --no-install-recommends xserver-xorg xinit Next, install the LXDE desktop. This will pull in all the required dependencies.\nsudo apt install --no-install-recommends task-lxde-desktop lxappearance lxsession raspberrypi-ui-mods rpd-icons unclutter Now, reboot the Pi and you should see it boot up and auto-login to a desktop.\nBrowser installation We need a browser that supports launching a web page automatically, at fullscreen, with no other controls on the page (this is commonly called kiosk-mode). For a long time, only Chromium had this, but Mozilla finally fixed an 11yr old request and added kiosk mode in Firefox 71. Unfortunately, Firefox on the Raspberry Pi is using the Extended Support Release (ESR) version, which is stuck at 68.8.0 (as-of this writing), so we need to install Chromium.\nsudo apt install chromium-browser Grafana setup Grafana server Because there an a million ways to setup Grafana, I\u0026rsquo;m going to assume you already have the following things setup:\nA Grafana instance (mine is running on a separate Docker server hosted internally at https://grafana.mydomain.com) One or more dashboards A playlist (allows you to auto-cycle through dashboards) A user that is not admin (the username/password will be stored on the Raspberry Pi in plain-text) The viewer role setup for that user (so this user will be view-only) Grafana kiosk mode Conveniently, Grafana provides an official tool to run Grafana in kiosk mode called Grafana Kiosk. This tool will use Chromium to login to Grafana and display a dashboard/playlist (as well as control LXDE) on a local or remote Grafana instance.\nStart by downloading Grafana Kiosk. As-of this writing, it is currently at version 1.0.1, but check for updates and substitute the version number as needed. The commands below will place the executables (for all architectures) in ~/grafana-kiosk/bin.\ncd ~ wget https://github.com/grafana/grafana-kiosk/releases/download/v1.0.1/grafana-kiosk-1.0.1.zip unzip grafana-kiosk-1.0.1.zip \u0026amp;\u0026amp; rm grafana-kiosk-1.0.1.zip Next, you need to determine the architecture of your CPU. Run the command below on your Raspberry Pi.\nlscpu | grep Architecture My Raspberry Pi is a 3B+, so my architecture is armv7l., which means my executable will be ~/grafana-kiosk/bin/grafana-kiosk.linux.armv7.\nAutostart I tried using the session-based startup method, but it wasn\u0026rsquo;t working. For me, the easiest way was to use systemd startup and place a slight pause in the startup (without it, I was getting errors about the display not being ready).\nFirst, create the new systemd service file.\nsudo touch /etc/systemd/system/grafana-kiosk.service sudo chmod 600 /etc/systemd/system/grafana-kiosk.service Run the command below to create the new service. Replace the user\u0026rsquo;s path (in two places), the URL, the username, and the password as needed.\nsudo bash -c \u0026#39;cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; /etc/systemd/system/grafana-kiosk.service [Unit] Description=Grafana Kiosk Documentation=https://github.com/grafana/grafana-kiosk Documentation=https://grafana.com/blog/2019/05/02/grafana-tutorial-how-to-create-kiosks-to-display-dashboards-on-a-tv After=network.target [Service] User=logan Environment=\u0026#34;DISPLAY=:0\u0026#34; Environment=\u0026#34;XAUTHORITY=/home/pi/.Xauthority\u0026#34; ExecStartPre=/bin/sleep 30 ExecStart=/home/pi/grafana-kiosk/bin/grafana-kiosk.linux.armv7 -URL https://grafana.mydomain.com/playlists/play/1 -login-method local -username username_here -password password_here -playlist true -lxde [Install] WantedBy=graphical.target EOF\u0026#39; Reload systemd and then start the service. After sleeping for 30 seconds, Grafana should start.\nsudo systemctl daemon-reload sudo systemctl enable grafana-kiosk sudo systemctl start grafana-kiosk sudo systemctl status grafana-kiosk If you have any issues, use the command below to look at the logs.\njournalctl -u grafana-kiosk Here is my completed display with my first dashboard loading (ignore my bad GIF-making skills, the bright spot on the screen is a light in my kitchen).\nYour browser does not support video. Timed display control You can also configure the display settings using cron. For example, I have setup a pair of cronjobs to turn the display off and on at specific times (e.g., off at 11pm, on at 7am), as well as another job to set the brightness. This should be added under root\u0026rsquo;s crontab.\n#Crontab Schedule # +---------------- minute (0 - 59) *=all # | +------------- hour (0 - 23) *=all # | | +---------- day of month (1 - 31) *=all # | | | +------- month (1 - 12) *=all # | | | | +---- day of week (0 - 6) *=all # | | | | | # * * * * * command to be executed # -- -- -- -- - --------------------------------- # 00 12 * * * some_command # will run some_command at 12:00 (noon) daily ##============================================================================ #Turn display off at 11pm every day 0 23 * * * echo 1 \u0026gt; /sys/class/backlight/rpi_backlight/bl_power #Turn display on at 7am every day 0 7 * * * echo 0 \u0026gt; /sys/class/backlight/rpi_backlight/bl_power #Set the display brightness on every reboot #Choose a value between 0 (min) and 255 (max) @reboot echo 75 \u0026gt; /sys/class/backlight/rpi_backlight/brightness Conclusion I\u0026rsquo;ve had this running for the past few days without issue. My only complaint is that the screen resolution is only 800x480, so the dashboards are pretty small. Looking around, there a number of larger displays available, but I could also use a spare monitor connected via HDMI.\nThanks for reading!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2020/05/always-on-grafana-dashboard-using-raspberry-pi-touchscreen/","summary":"Introduction I have a small homelab in my home that runs pfSense, Proxmox, Docker, a Synology NAS, UniFi wireless, etc\u0026hellip; I already monitor my pfSense firewall logs using Graylog, but I was looking for a solution to monitor hardware (e.g., CPU usage, RAM usage, etc\u0026hellip;) as well as software processes (e.g., containers using network, current download/upload speed, etc\u0026hellip;).\nI stumbled upon two separate software stacks for this. First is the TICK stack, which is composed of open-source products from InfluxData:","title":"Always-on Grafana dashboard using Raspberry Pi touchscreen"},{"content":"Introduction In my last post, I went over linting Ansible playbooks manually. In this post, I\u0026rsquo;m going to give you a brief introduction on how to lint playbooks automatically, using Drone.\nI was inspired to post this after watching Jeff Geerling\u0026rsquo;s (geerlingguy on Github) Ansible 101 YouTube series. In it, he mentions using automated testing/linting of his playbooks. If you haven\u0026rsquo;t seen it, give it a watch.\nAs with before, I\u0026rsquo;m not a developer or professional DevOps person. I know just enough to be dangerous, but this should be enough to get you going.\nWhat is Drone? Drone is continuous integration and continuous delivery/deployment (often written as CI/CD) software. It allows you to take automated actions when code is pushed to a repository (e.g., test the code, push to a Docker registry, push to production, alert if failed, etc\u0026hellip;).\nThere are many popular CI/CD solutions, including, but not limited to:\nJenkins GitLab CI/CD Concourse CircleCI TeamCity Bamboo Travis CI However, most of these solutions were overkill for my workload. Considering I\u0026rsquo;m a noob at this, I was looking for something lightweight, minimal, and most importantly, easy to setup. Drone fit my requirements perfectly.\nWhy automate linting? As I said in my last post, I lint my playbooks because I‚Äôd like to have some confidence that updates to my playbooks will work, without having to run them after every update. However, I currently have to manually lint any playbooks after updates are made.\nSince my Ansible playbooks are all checked into git, I can setup this workflow.\nMy self-hosted Gitea instance notifies Drone of changes via a webhook Drone spins up a Docker container of a pre-built Ubuntu image with Ansible installed Drone runs a command to lint my playbooks using that container\u0026rsquo;s Ansible installation Installation Version Control System You need some sort of version control system (VCS) that supports webhooks. I\u0026rsquo;m using Gitea at home, running on Docker. Drone supports providers other than Gitea, including GitHub, GitLab, Gogs, and Bitbucket.\nNote - Drone needs to be notified by your VCS via a webhook. For me, both Gitea and Drone are self-hosted at home. If you\u0026rsquo;re using GitHub (or other public VCS), you need to either:\nexpose your self-hosted Drone instance to the world (e.g., put your Drone instance in your network\u0026rsquo;s DMZ) host Drone yourself in the cloud (e.g., on a VPS) use the hosted instance of Drone OAuth key Once you select a VCS provider, you\u0026rsquo;ll need to create an OAuth key. This will allow you to login to Drone using your VCS provider of choice.\nThe instructions will be different for each provider, so I\u0026rsquo;ll just link the top-level installation page here.\nDrone Everything in Drone is Docker-first. As such, Drone is designed to be installed in a Docker container. Below is a sanitized version of my docker-compose.yml file to run Drone and the Docker runner (the runner is the application that actually executes the CI/CD pipeline steps). By Default, Drone uses a SQLite database, but also supports PostgreSQL and MySQL as well. I didn\u0026rsquo;t post my PostgreSQL configuration here to keep things simple.\nversion: \u0026#39;3\u0026#39; services: drone: container_name: drone image: drone/drone:1 restart: unless-stopped environment: - DRONE_SERVER_HOST=drone.internal.mydomain.com - DRONE_SERVER_PROTO=https - DRONE_GITEA_SERVER=https://git.internal.mydomain.com - DRONE_GITEA_CLIENT_ID=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX - DRONE_GITEA_CLIENT_SECRET=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\t- DRONE_RPC_SECRET=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX networks: - drone ports: - \u0026#39;80:80\u0026#39; volumes: - \u0026#39;drone_data:/data\u0026#39; drone-runner-docker: container_name: drone-runner-docker image: drone/drone-runner-docker:1 restart: unless-stopped environment: - DRONE_RPC_HOST=drone.internal.mydomain.com - DRONE_RPC_PROTO=https - DRONE_RUNNER_NAME=runner1 - DRONE_UI_DISABLE=true - DRONE_RPC_SECRET=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX networks: - drone ports: - \u0026#39;3000:3000\u0026#39; volumes: - \u0026#39;/var/run/docker.sock:/var/run/docker.sock\u0026#39; networks: drone: volumes: drone_data: driver: local Once you startup your containers and try to login to Drone (my instance is behind a reverse proxy), you should be greeted with your VCS provider\u0026rsquo;s login page. Once you login, you should be able to click Sync to sync your repositories to Drone.\nI\u0026rsquo;m going to assume you already have an ansible repository, so click on it, and click Activate.\nConfiguration Next, we need to create a configuration file for Drone. This file is usually called .drone.yml, and it\u0026rsquo;s right in the root of your git repository.\nThis configuration file needs to point to a Docker image that already has ansible and ansible-lint pre-installed. Luckily, Jeff Geerling already hosts an image on Docker Hub for this exact purpose (specifically, we need the image with the testing tag).\n--- kind: pipeline type: docker name: default steps: - name: test image: geerlingguy/docker-ubuntu1804-ansible:testing commands: - \u0026#34;find . -maxdepth 1 -name \u0026#39;*.yml\u0026#39; | sort | grep -v \u0026#39;.drone.yml\u0026#39; | xargs ansible-playbook --syntax-check --list-tasks\u0026#34; - \u0026#34;find . -maxdepth 1 -name \u0026#39;*.yml\u0026#39; | sort | grep -v \u0026#39;.drone.yml\u0026#39; | xargs ansible-lint\u0026#34; The configuration file above basically says:\nUse a Docker pipeline (so all these steps happen in Docker containers that go away after the run is completed) Run a step named test Download an image called geerlingguy/docker-ubuntu1804-ansible:testing Run the two commands for syntax checking and linting inside that container If there are any errors (non-zero exit codes), throw an error Based on the output (pass/fail), you\u0026rsquo;ll see a symbol in your VCS provider\u0026rsquo;s web interface (usually a ‚úÖ or ‚ùå symbol). Now, every time I commit anything to my Ansible repository, it is automatically checked for syntax and linted. The only remaining step (which I have yet to setup) is alerting. Drone has plugins to notify you via email, Slack, Telegram, etc\u0026hellip;\nBonus: Run you own Ansible test images Since I already run a Docker registry at home and have a Gitea server, I build my own Ubuntu images to test against. In fact, the image for Ubuntu is built with Drone as well!\nFROM ubuntu:bionic ARG BUILD_DATE LABEL \\ maintainer=\u0026#34;Logan Marchione\u0026#34; \\ org.opencontainers.image.authors=\u0026#34;Logan Marchione\u0026#34; \\ org.opencontainers.image.title=\u0026#34;docker-ubuntu1804-ansible\u0026#34; \\ org.opencontainers.image.description=\u0026#34;Installs Ansible for testing playbooks\u0026#34; \\ org.opencontainers.image.created=$BUILD_DATE RUN apt-get update \u0026amp;\u0026amp; apt-get install -y --no-install-recommends \\ apt-utils \\ python3-pip \\ python3-setuptools \\ software-properties-common \u0026amp;\u0026amp; \\ rm -rf /var/lib/apt/lists/* \u0026amp;\u0026amp; \\ pip3 install ansible ansible-lint In my case, I\u0026rsquo;m able to reference my local internal registry instead of Docker Hub. I can also test against more than one version of Linux, or in my case, Ubuntu.\n--- kind: pipeline type: docker name: default steps: - name: test-ubuntu1804 image: registry.internal.mydomain.com/loganmarchione/docker-ansible-ubuntu1804:1.0 commands: - \u0026#34;find . -maxdepth 1 -name \u0026#39;*.yml\u0026#39; | sort | grep -v \u0026#39;.drone.yml\u0026#39; | xargs ansible-playbook --syntax-check --list-tasks\u0026#34; - \u0026#34;find . -maxdepth 1 -name \u0026#39;*.yml\u0026#39; | sort | grep -v \u0026#39;.drone.yml\u0026#39; | xargs ansible-lint\u0026#34; - name: test-ubuntu2004 image: registry.internal.mydomain.com/loganmarchione/docker-ansible-ubuntu2004:1.0 commands: - \u0026#34;find . -maxdepth 1 -name \u0026#39;*.yml\u0026#39; | sort | grep -v \u0026#39;.drone.yml\u0026#39; | xargs ansible-playbook --syntax-check --list-tasks\u0026#34; - \u0026#34;find . -maxdepth 1 -name \u0026#39;*.yml\u0026#39; | sort | grep -v \u0026#39;.drone.yml\u0026#39; | xargs ansible-lint\u0026#34; Conclusion I hope this was a good introduction to Ansible linting and Drone. As a mentioned, I\u0026rsquo;m not an expert, so if you spot anything wrong or see anything I could improve, I\u0026rsquo;m open to criticism.\nThanks for reading!\n-Logan\n","permalink":"https://loganmarchione.github.io/2020/04/linting-ansible-playbooks-using-drone/","summary":"Introduction In my last post, I went over linting Ansible playbooks manually. In this post, I\u0026rsquo;m going to give you a brief introduction on how to lint playbooks automatically, using Drone.\nI was inspired to post this after watching Jeff Geerling\u0026rsquo;s (geerlingguy on Github) Ansible 101 YouTube series. In it, he mentions using automated testing/linting of his playbooks. If you haven\u0026rsquo;t seen it, give it a watch.\nAs with before, I\u0026rsquo;m not a developer or professional DevOps person.","title":"Linting Ansible playbooks using Drone"},{"content":"Introduction What is Ansible? If you\u0026rsquo;re reading this, you probably already know what Ansible is, so I won\u0026rsquo;t spend a lot of time here.\nAnsible is open-source configuration management software. It lets you configure one machine, or 100 machines, in the same way, every time. You can use Ansible to install software, create users, update files, etc\u0026hellip; Basically, if it\u0026rsquo;s a task that can be automated, Ansible can do it.\nI\u0026rsquo;m using Ansible in my homelab to:\nProvision virtual machines (e.g., setup basic packages, create users, setup SSH keys, etc\u0026hellip;) Install applications (e.g., Docker host, Graylog, Nginx, LEMP stack, etc\u0026hellip;) Install updates (e.g., apt-get upgrade) What is linting? Linting is a way to analyze code to look for potential errors before the code executes. Generally, linting uses a set of known rules, and compares your code against those rules. For example, linting is used for:\nimproving readability finding syntax errors (before execution) code standardizing (relevant XKCD) finding security issues Linting can (and usually does) include some level of syntax checking, but it can also test for more things. However, linting is not the same as debugging, which generally takes place when the code compiles or executes, whereas linting takes places before code runs.\nWhy lint Ansible? Ansible uses YAML files to describe playbooks, roles, variables, and just about everything else. YAML is easy to read, but is picky about things like whitespace, indentation, and syntax in general. I\u0026rsquo;d like to have some confidence that updates to my playbooks will work, without having to run them after every update.\nLet me preface this by saying, I\u0026rsquo;m not a developer and I don\u0026rsquo;t write code for a living. Expect some of this to be slightly wrong, but it should be right enough to get you started.\nInstallation I\u0026rsquo;m going to assume you already have ansible installed and working. To install ansible-lint, use the documentation on the Github repo. Don\u0026rsquo;t use your distribution\u0026rsquo;s package manager, as the version of ansible-lint is probably very old.\npip3 install ansible-lint Verify the installation with the command below.\nansible-lint --version Manual linting First, view all the rules that ansible-lint will use by running ansible-lint -L. I was able to see 31 different rules that my code would be checked against.\n101: Deprecated always_run Instead of ``always_run``, use ``check_mode`` 102: No Jinja2 in when ``when`` lines should not include Jinja2 variables 103: Deprecated sudo Instead of ``sudo``/``sudo_user``, use ``become``/``become_user``. 104: Using bare variables is deprecated Using bare variables is deprecated. Update your playbooks so that the environment value uses the full variable syntax ``{{ your_variable }}`` 105: Deprecated module These are deprecated modules, some modules are kept temporarily for backwards compatibility but usage is discouraged. For more details see: https://docs.ansible.com/ansible/latest/modules/list_of_all_modules.html 201: Trailing whitespace There should not be any trailing whitespace 202: Octal file permissions must contain leading zero or be a string Numeric file permissions without leading zero can behave in unexpected ways. See http://docs.ansible.com/ansible/file_module.html 203: Most files should not contain tabs Tabs can cause unexpected display issues, use spaces 204: Lines should be no longer than 160 chars Long lines make code harder to read and code review more difficult 205: Use \u0026#34;.yml\u0026#34; or \u0026#34;.yaml\u0026#34; playbook extension Playbooks should have the \u0026#34;.yml\u0026#34; or \u0026#34;.yaml\u0026#34; extension 206: Variables should have spaces before and after: {{ var_name }} Variables should have spaces before and after: ``{{ var_name }}`` 301: Commands should not change things if nothing needs doing Commands should either read information (and thus set ``changed_when``) or not do something if it has already been done (using creates/removes) or only do it if another check has a particular result (``when``) 302: Using command rather than an argument to e.g. file Executing a command when there are arguments to modules is generally a bad idea 303: Using command rather than module Executing a command when there is an Ansible module is generally a bad idea 304: Environment variables don\u0026#39;t work as part of command Environment variables should be passed to ``shell`` or ``command`` through environment argument 305: Use shell only when shell functionality is required Shell should only be used when piping, redirecting or chaining commands (and Ansible would be preferred for some of those!) 306: Shells that use pipes should set the pipefail option Without the pipefail option set, a shell command that implements a pipeline can fail and still return 0. If any part of the pipeline other than the terminal command fails, the whole pipeline will still return 0, which may be considered a success by Ansible. Pipefail is available in the bash shell. 401: Git checkouts must contain explicit version All version control checkouts must point to an explicit commit or tag, not just ``latest`` 402: Mercurial checkouts must contain explicit revision All version control checkouts must point to an explicit commit or tag, not just ``latest`` 403: Package installs should not use latest Package installs should use ``state=present`` with or without a version 404: Doesn\u0026#39;t need a relative path in role ``copy`` and ``template`` do not need to use relative path for ``src`` 501: become_user requires become to work as expected ``become_user`` without ``become`` will not actually change user 502: All tasks should be named All tasks should have a distinct name for readability and for ``--start-at-task`` to work 503: Tasks that run when changed should likely be handlers If a task has a ``when: result.changed`` setting, it is effectively acting as a handler 504: Do not use \u0026#39;local_action\u0026#39;, use \u0026#39;delegate_to: localhost\u0026#39; Do not use ``local_action``, use ``delegate_to: localhost`` 601: Don\u0026#39;t compare to literal True/False Use ``when: var`` rather than ``when: var == True`` (or conversely ``when: not var``) 602: Don\u0026#39;t compare to empty string Use ``when: var`` rather than ``when: var != \u0026#34;\u0026#34;`` (or conversely ``when: not var`` rather than ``when: var == \u0026#34;\u0026#34;``) 701: meta/main.yml should contain relevant info meta/main.yml should contain: ``author, description, license, min_ansible_version, platforms`` 702: Tags must contain lowercase letters and digits only Tags must contain lowercase letters and digits only, and ``galaxy_tags`` is expected to be a list 703: meta/main.yml default values should be changed meta/main.yml default values should be changed for: ``author, description, company, license, license`` 704: meta/main.yml video_links should be formatted correctly Items in ``video_links`` in meta/main.yml should be dictionaries, and contain only keys ``url`` and ``title``, and have a shared link from a supported provider Then, simply pass a playbook or role to ansible-lint and it will tell you about possible problems. You can pass all of your playbooks at once, with the command below (assuming you\u0026rsquo;re in the directory where your YML files reside).\nansible-lint *.yml When you get your results, the output will be on three lines:\nThe rule that triggered The file that contains the error and the line number (it may not always be this exact line, but it\u0026rsquo;s usually around here) The offending line For example, the code below is used to install a few packages, but it has an error that could cause some breakage. Can you spot it?\n- name: Install pip packages pip: name: - certbot - certbot_dns_nsone - cryptography state: latest In this code above, I\u0026rsquo;m using pip to install packages for Certbot. However, I\u0026rsquo;m using the latest tag, which means if I run this playbook across multiple machines at different times, I could get different packages (depending on what is hosted on PyPi). This could produce inconsistencies between machines. Imagine if you\u0026rsquo;re Google and running this on 1000 servers: you could have 500 servers with one version, and 500 servers with another version (which may or may not be compatible with your software).\n[403] Package installs should not use latest roles/certs_certbot/tasks/main.yml:2 Task/Handler: Install pip packages Ideally, I would specify a version number after each package (as shown below).\n- name: Install pip packages pip: name: - certbot==1.0 - certbot_dns_nsone==1.0 - cryptography==1.0 state: present Linting vs syntax-checking As I mentioned earlier, linting is more detailed than syntax checking. Ansible has a built-in syntax checker that you should be using, but it may not catch everything.\nansible-playbook --syntax-check --list-tasks playbook.yml As an example, below is a task from a playbook to setup a PHP configuration file. This code passed Ansible\u0026rsquo;s syntax check, but ansible-lint caught two issues. Can you spot them?\n- name: Update application configuration from template template: src: templates/php_99-custom_no_opcache.j2 dest: /etc/php/{{php_upstream_version}}/fpm/conf.d/99-custom.ini backup: yes owner: root group: root mode: 0644 First, there is an extra space after the name of the .ini file (on a desktop, click and drag in the code above and you\u0026rsquo;ll see it).\n[201] Trailing whitespace roles/install_php_no_opcache/tasks/main.yml:26 dest: /etc/php/{{php_upstream_version}}/fpm/conf.d/99-custom.ini Second, I am missing spaces before and after the variable name in curly brackets.\n[206] Variables should have spaces before and after: {{ var_name }} roles/install_php_no_opcache/tasks/main.yml:26 dest: /etc/php/{{php_upstream_version}}/fpm/conf.d/99-custom.ini These two issues are technically OK as far as YML syntax is concerned, but they\u0026rsquo;re not consistent across all my playbooks. This is especially important if you\u0026rsquo;re working on code that has multiple contributors.\nConclusion That\u0026rsquo;s it for now. In part two, I\u0026rsquo;ll explore using Drone to automate linting of Ansible playbooks!\nThanks for reading!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2020/04/how-and-why-you-should-lint-your-ansible-playbooks/","summary":"Introduction What is Ansible? If you\u0026rsquo;re reading this, you probably already know what Ansible is, so I won\u0026rsquo;t spend a lot of time here.\nAnsible is open-source configuration management software. It lets you configure one machine, or 100 machines, in the same way, every time. You can use Ansible to install software, create users, update files, etc\u0026hellip; Basically, if it\u0026rsquo;s a task that can be automated, Ansible can do it.","title":"How and why you should lint your Ansible playbooks"},{"content":"Introduction Hey! Listen! This post is part of a series on pfSense. Check them all out!\nDate URL Part 2019-08-25 pfSense on the PC Engines APU2 Migrated to a PC Engines APU2D4 2019-07-17 My SG-1100 died Migrated back the the EdgeRouter Lite 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 In the past few weeks, I replaced my EdgeRouter Lite with a Netgate SG-1100. Two weeks later, my SG-1100 died, and I had to put the EdgeRouter Lite back. However, I still wanted to replace the ERL with a pfSense device (albeit, not Netgate hardware).\nPC Engines APU2 Again, my requirements for hardware were as follows:\nHardware that is small, low power, and fanless (this device is in my living room, not a server rack) Have Intel NICs (they generally have better compatibility with Linux/BSD than Realtek) Be around $250 or less, including RAM (but not storage) Going back to my hardware chart, I further narrowed it down to the PC Engines APU2 and the Shuttle DS77U (in fact, the DS10U was just released, which is a DS77U with an 8th Gen Intel processor). While the Shuttle DS77U/DS10U would have better hardware (newer CPU, DDR4 instead of DDR3, etc\u0026hellip;), I chose to go with the APU2. The APU2 comes highly recommended on reddit and the pfSense forums, and it receives frequent BIOS updates (including Coreboot support, and most recently AMD Core Performance Boost).\nThere are four main differentiators of the APU2 lineup (thanks to commenter Cee Jay for clearing this up):\nthe APU platform generation (e.g., 2, 3, 4, etc\u0026hellip;) - this is where you get APU2, APU3, APU4, etc\u0026hellip; the board revision (e.g., a, b, c, d, etc\u0026hellip;) - this is where you get APU2A, APU2B, APU2C, etc\u0026hellip; the amount of RAM (2GB or 4GB) - this is where you get APU2D2, APU2D4, etc\u0026hellip; the type of NIC (Intel i210AT vs i211AT) When purchasing an APU model, do not assume that a bigger model number is better. For example, the APU4 is not \u0026ldquo;better\u0026rdquo; than the APU2 because the model number is larger. You should always do your research to determine what model you need for your application.\nFor networking applications, it\u0026rsquo;s generally known that the i210AT is considered \u0026ldquo;better\u0026rdquo; than the i211AT because it has four transmit and four receive queues per port, while the i211AT only has two transmit and two receive queues per port. So when purchasing an APU, I made sure to look for one with an i210AT.\nI ended up purchasing the following items directly from PC Engines directly. Shipping took a total of 10 days from Switzerland to Pennsylvania. It arrived via USPS and required a signature, since it originated outside the United States.\napu2d4 - $120 (this has the i210AT) case1d2blku - $10 ac12vus2 - $4.40 Samsung 860 EVO 250GB mSATA SSD - $67.90 usbcom1a - $8.00 (optional - the drivers for Windows 10 are here) apufix1a - $5.00 (optional - this makes positioning the thermal pad much easier) hexbit - $3.50 (optional) Pre-install Assembly I chose to assemble my APU2 myself, but there is an option to pay to have it assembled. If you choose to assemble it yourself, there is a really good video here. Pro-tip, make sure you remove the screws on the serial connection before you try to assemble anything.\nConnect to serial Connect the serial cable using the settings from the manual. These are the same settings that pfSense uses as well.\nSpeed: 115200 Data Bits: 8 Parity Bits: None Stop Bits: 1 These are the PuTTY settings I used (your COM port may be different).\nPress F10 at boot when connected via the console cable and you will see the boot menu.\nMemtest86 I always test my memory before I use it, and I always recommend Memtest86 (not to be confused with Memtest86+, which is no longer maintained). There is a build of Memtest86 built-in to the APU2 BIOS, just press F10 at boot when connected via the console cable and you can run a memory test with option 3.\nSetup Install Installing pfSense was easy enough, especially if you\u0026rsquo;re using the amazing install guide (seriously, use it). For my install, I chose the options below from the download page. The APU2 does not have a VGA port, so you don\u0026rsquo;t have any option other than to do an install over serial.\nConfiguration The initial configuration was easy. The middle port is the LAN port, which will give you a 192.168.1.1/24 address. From a browser, follow the prompts to do your initial setup. I won\u0026rsquo;t detail exactly what I did to my setup, since everyone\u0026rsquo;s install will be different.\nI recommend getting a cheap label maker and labeling the interfaces, since they are not marked on the case anywhere. I also make a label for the boot menu shortcut key and the serial settings.\nBIOS update This is personal preference, but I always try to update the BIOS on my devices. With the recent Meltdown and Spectre vulnerabilities, it is crucial to keep your BIOS updated (since these vulnerabilities can only be mitigated with firmware updates). For the APU2, the BIOS updates are located here.\nPC Engines recommends you flash the firmware from a separate Linux-based USB drive, but you can do it from inside pfSense, after pfSense is installed, as shown here.\nSpeedtest Here are the iPerf results when running a test with my ERL as the router. Keep in mind, my internet at home is only 400/400, so that\u0026rsquo;s my current maximum speed.\nConnecting to host loganmarchione.com, port 5201 [ 4] local 10.10.2.34 port 55818 connected to 68.183.148.132 port 5201 [ ID] Interval Transfer Bandwidth Retr Cwnd [ 4] 0.00-1.00 sec 48.0 MBytes 402 Mbits/sec 28 1.62 MBytes [ 4] 1.00-2.00 sec 64.8 MBytes 543 Mbits/sec 23 1.35 MBytes [ 4] 2.00-3.00 sec 67.2 MBytes 564 Mbits/sec 0 1.42 MBytes [ 4] 3.00-4.00 sec 67.2 MBytes 564 Mbits/sec 0 1.47 MBytes [ 4] 4.00-5.00 sec 67.2 MBytes 564 Mbits/sec 0 1.50 MBytes [ 4] 5.00-6.00 sec 67.2 MBytes 564 Mbits/sec 0 1.52 MBytes [ 4] 6.00-7.00 sec 66.4 MBytes 557 Mbits/sec 0 1.53 MBytes [ 4] 7.00-8.00 sec 66.6 MBytes 559 Mbits/sec 0 1.54 MBytes [ 4] 8.00-9.00 sec 67.2 MBytes 564 Mbits/sec 0 1.54 MBytes [ 4] 9.00-10.00 sec 67.2 MBytes 564 Mbits/sec 0 1.56 MBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Retr [ 4] 0.00-10.00 sec 649 MBytes 544 Mbits/sec 51 sender [ 4] 0.00-10.00 sec 647 MBytes 542 Mbits/sec receiver And here are the results of same test, but with the APU2 acting as the router. As you can see, it\u0026rsquo;s able to max out my connection without breaking a sweat.\nConnecting to host loganmarchione.com, port 5201 [ 4] local 10.10.2.34 port 51548 connected to 68.183.148.132 port 5201 [ ID] Interval Transfer Bandwidth Retr Cwnd [ 4] 0.00-1.00 sec 53.7 MBytes 450 Mbits/sec 9 2.21 MBytes [ 4] 1.00-2.00 sec 67.2 MBytes 563 Mbits/sec 1 2.23 MBytes [ 4] 2.00-3.00 sec 67.2 MBytes 564 Mbits/sec 0 2.25 MBytes [ 4] 3.00-4.00 sec 67.2 MBytes 564 Mbits/sec 0 2.27 MBytes [ 4] 4.00-5.00 sec 67.2 MBytes 563 Mbits/sec 0 2.29 MBytes [ 4] 5.00-6.00 sec 67.2 MBytes 564 Mbits/sec 0 2.32 MBytes [ 4] 6.00-7.00 sec 67.2 MBytes 563 Mbits/sec 0 2.34 MBytes [ 4] 7.00-8.00 sec 67.2 MBytes 564 Mbits/sec 0 2.38 MBytes [ 4] 8.00-9.00 sec 67.1 MBytes 563 Mbits/sec 0 2.47 MBytes [ 4] 9.00-10.00 sec 67.2 MBytes 564 Mbits/sec 1 2.51 MBytes - - - - - - - - - - - - - - - - - - - - - - - - - [ ID] Interval Transfer Bandwidth Retr [ 4] 0.00-10.00 sec 658 MBytes 552 Mbits/sec 11 sender [ 4] 0.00-10.00 sec 657 MBytes 551 Mbits/sec receiver I have heard nothing but good things about the APU2, and am so far impressed!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2019/08/pfsense-on-the-pc-engines-apu2/","summary":"Introduction Hey! Listen! This post is part of a series on pfSense. Check them all out!\nDate URL Part 2019-08-25 pfSense on the PC Engines APU2 Migrated to a PC Engines APU2D4 2019-07-17 My SG-1100 died Migrated back the the EdgeRouter Lite 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 In the past few weeks, I replaced my EdgeRouter Lite with a Netgate SG-1100. Two weeks later, my SG-1100 died, and I had to put the EdgeRouter Lite back.","title":"pfSense on the PC Engines APU2"},{"content":"Hey! Listen! This post is part of a series on pfSense. Check them all out!\nDate URL Part 2019-08-25 pfSense on the PC Engines APU2 Migrated to a PC Engines APU2D4 2019-07-17 My SG-1100 died Migrated back the the EdgeRouter Lite 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 Introduction I recently wrote about how I was dropping the Ubiquiti EdgeRouter Lite for a Netgate SG-1100 running pfSense. However, on July 9th (about two weeks after installing my SG-1100) I noticed my internet connection died, and I was unable to ping the router. I used a micro-USB cable to view the console and noticed it was not pulling an IP address from my FiOS ONT.\nAt first, I thought it was an issue with Verizon, so I opened a ticket and had them reset/reboot my ONT remotely, without resolution. However, I then noticed the device randomly rebooted while I was connected to the console. After it started back up, it rebooted again. Thinking it was not an issue with Verizon, I removed the SG-1100 and replaced it with my EdgeRouter Lite, which immediately pulled an IP and restored my connectivity.\nNetgate\u0026rsquo;s response I opened a ticket with Netgate and attached my boot log. While I waited, I did some Googling and found this post, where Netgate acknowledged a power problem with the SG-1100. In less than 10 minutes, a support person from Netgate sent me a RMA. However, since this is a hardware issue, I declined a new SG-1100 and requested a refund, which they approved without issue.\nTo Netgate\u0026rsquo;s credit, they did the right thing here. They publicly disclosed the issue on their forums and immediately offered a replacement device. Again, their support is amazing.\nBack to the ERL For now, I\u0026rsquo;m using my EdgeRouter Lite, with the full intent to still move to pfSense (albeit, on new hardware). I declined a new SG-1100, because I\u0026rsquo;m not sure if the new device will be affected by the same issue. My other choice is install pfSense on an x86 box, as I had originally planned. This option, however, does not include Netgate support, which I\u0026rsquo;d have to do without or purchase separately.\nBoot log I\u0026rsquo;m posting this log in the event someone else has this issue and stumbles upon this. Some interesting points from the log:\nLine 22 shows the Enter an option prompt, then the device starts to reboot. Lines 76, 79, and 91 show an issue with voltage. Line 279 shows that / was not dismounted correctly (from being rebooted). Line 338 shows the SG-1100 not pulling an IP from my ONT (not sure if this was a side effect the power issue or not). The full log from the console connection is below (with line numbers inserted).\n00000001 FreeBSD/arm64 (pfsense.domain.local) (ttyu0) 00000002 00000003 Netgate SG-1100 Netgate Device ID: XXXXXXXXXXXXXXXXXXXX 00000004 Serial: XXXXXXXXXXXXX Netgate Crypto ID: XXXXXXXXXXXXXXXXXX 00000005 00000006 *** Welcome to pfSense 2.4.4-RELEASE-p3 (arm64) on pfsense *** 00000007 00000008 WAN (wan) -\u0026gt; mvneta0.4090 -\u0026gt; 00000009 LAN (lan) -\u0026gt; mvneta0.4091 -\u0026gt; v4: 10.10.2.1/24 00000010 OPT (opt1) -\u0026gt; mvneta0.4092 -\u0026gt; 00000011 00000012 0) Logout (SSH only) 9) pfTop 00000013 1) Assign Interfaces 10) Filter Logs 00000014 2) Set interface(s) IP address 11) Restart webConfigurator 00000015 3) Reset webConfigurator password 12) PHP shell + pfSense tools 00000016 4) Reset to factory defaults 13) Update from console 00000017 5) Reboot system 14) Disable Secure Shell (sshd) 00000018 6) Halt system 15) Restore recent configuration 00000019 7) Ping host 16) Restart PHP-FPM 00000020 8) Shell 00000021 00000022 Enter an option: TIM-1.0 00000023 WTMI-armada-17.10.5-34ce216 00000024 WTMI: system early-init 00000025 SVC REV: 5, CPU VDD voltage: 1.202V 00000026 00000027 Fill memory before self refresh...done 00000028 00000029 Now in Self-refresh Mode 00000030 Exited self-refresh ... 00000031 00000032 00000033 Self refresh Pass. 00000034 DDR self test mode test done!! 00000035 Vref read training 00000036 =================== 00000037 Final vdac_value 0x0000001F 00000038 00000039 Vref write training 00000040 =================== 00000041 Final vref_value 0x0000001F 00000042 00000043 DLL TUNING 00000044 ============== 00000045 DLL 0xc0001050[21:16]: [4,32,1b] 00000046 DLL 0xc0001050[29:24]: [9,2f,1c] 00000047 DLL 0xc0001054[21:16]: [5,32,1b] 00000048 DLL 0xc0001054[29:24]: [a,30,1d] 00000049 DLL 0xc0001074[21:16]: [0,3f,1f] 00000050 DLL 0xc0001074NOTICE: Booting Trusted Firmware 00000051 NOTICE: BL1: v1.3(release):armada-17.10.8:34247e0 00000052 NOTICE: BL1: Built : 16:19:41, Nov 1 2NOTICE: BL2: v1.3(release):armada-17.10.8:34247e0 00000053 NOTICE: BL2: Built : 16:19:45, Nov 1 20NOTICE: BL31: v1.3(release):armada-17.10.8:34247e0 00000054 NOTICE: BL31: 00000055 00000056 U-Boot 2017.03-armada-17.10.2-g6a6581a-dirty (Nov 01 2018 - 16:04:57 -0300) 00000057 00000058 Model: Marvell Armada 3720 Community Board ESPRESSOBin 00000059 CPU @ 1200 [MHz] 00000060 L2 @ 800 [MHz] 00000061 TClock @ 200 [MHz] 00000062 DDR @ 750 [MHz] 00000063 DRAM: 1 GiB 00000064 U-Boot DT blob at : 000000003f716298 00000065 Comphy-0: USB3 5 Gbps 00000066 Comphy-1: PEX0 2.5 Gbps 00000067 Comphy-2: SATA0 6 Gbps 00000068 SATA link 0 timeout. 00000069 AHCI 0001.0300 32 slots 1 ports 6 Gbps 0x1 impl SATA mode 00000070 flags: ncq led only pmp fbss pio slum part sxs 00000071 PCIE-0: Link down 00000072 MMC: sdhci@d0000: 0, sdhci@d8000: 1 00000073 SF: Detected mx25u3235f with page size 256 Bytes, erase size 64 KiB, total 4 MiB 00000074 Net: eth0: neta@30000 [PRIME] 00000075 Hit any key to stop autoboot: 0 00000076 Card did not respond to voltage select! 00000077 mmc_init: -95, time 41 00000078 ** Bad device mmc 0 ** 00000079 Card did not respond to voltage select! 00000080 mmc_init: -95, time 23 00000081 ** Bad device mmc 0 ** 00000082 ## Starting EFI application at 05000000 ... 00000083 efi_load_pe: Invalid DOS Signature 00000084 ## Application terminated, r = -2 00000085 sdhci_transfer_data: Error detected in status(0x408000)! 00000086 reading efi/boot/bootaa64.efi 00000087 393216 bytes read in 31 ms (12.1 MiB/s) 00000088 reading armada-3720-sg1100.dtb 00000089 13772 bytes read in 12 ms (1.1 MiB/s) 00000090 ## Starting EFI application at 05000000 ... 00000091 Card did not respond to voltage select! 00000092 mmc_init: -95, time 23 00000093 Scanning disk sdhci@d8000.blk... 00000094 Found 4 disks 00000095 00000096 00000097 00000098 00000099 00000100 00000101 00000102 00000103 00000104 00000105 00000106 00000107 00000108 00000109 00000110 00000111 00000112 00000113 00000114 00000115 00000116 00000117 00000118 00000119 00000120 00000121 00000122 00000123 00000124 00000125 00000126 00000127 00000128 00000129 00000130 00000131 00000132 00000133 00000134 00000135 00000136 00000137 00000138 00000139 00000140 00000141 \u0026gt;\u0026gt; FreeBSD EFI boot block 00000142 Loader path: /boot/loader.efi 00000143 00000144 Initializing modules: ZFS UFS 00000145 Probing 4 block devices......* done 00000146 ZFS found no pools 00000147 UFS found 1 partition 00000148 command args: -S115200 00000149 00000150 Consoles: EFI console 00000151 Command line arguments: loader.efi -S115200 00000152 Image base: 0x3c595008 00000153 EFI version: 2.05 00000154 EFI Firmware: Das U-boot (rev 0.00) 00000155 00000156 FreeBSD/arm64 EFI loader, Revision 1.1 00000157 (Thu Oct 4 10:04:04 EDT 2018 root@buildbot2.nyi.netgate.com) 00000158 BootCurrent: 0000 00000159 BootOrder: 03e8 0000[*] 0000[*] 0000[*] 03e8 0000[*] 0000[*] 0000[*] 5170 3f71 0000[*] 0000[*] 30d4 0000[*] 0000[*] 0000[*] 5190 3f71 0000[*] 0000[*] 1158 3ff8 0000[*] 0000[*] 51c0 3f71 0000[*] 0000[*] 853c 3ff7 0000[*] 0000[*] 0000[*] 0000[*] 0000[*] 0000[*] 0004 0000[*] 0000[*] 0000[*] 35b8 3ffa 0000[*] 0000[*] 0001 0000[*] 0000[*] 0000[*] 42d0 3ff7 0000[*] 0000[*] 0000[*] 0000[*] 0000[*] 0000[*] 5200 3f71 0000[*] 0000[*] 853c 3ff7 0000[*] 0000[*] 4260 3f7a 0000[*] 0000[*] 0004 0000[*] 0000[*] 0000[*] 35b8 3ffa 0000[*] 0000[*] 0001 0000[*] 0000[*] 0000[*] 42d0 3ff7 0000[*] 0000[*] f000 3c52 0000[*] 0000[*] 4260 3f7a 0000[*] 0000[*] 080c 3ff6 0000[*] 0000[*] 5310 3f71 0000[*] 0000[*] 00000160 Setting currdev to disk0p3: 00000161 Loading /boot/defaults/loader.conf 00000162 /boot/kernel/kernel text=0x9802a8 data=0x877c70+0x3c7a14 syms=[0x8+0x116bf8+0x8+0xf0f51] 00000163 | 00000164 Hit [Enter] to boot immediately, or any other key for command prompt. 00000165 Booting [/boot/kernel/kernel]... 00000166 Using DTB provided by EFI at 0x7ffb000. 00000167 Copyright (c) 1992-2018 The FreeBSD Project. 00000168 Copyright (c) 1979, 1980, 1983, 1986, 1988, 1989, 1991, 1992, 1993, 1994 00000169 The Regents of the University of California. All rights reserved. 00000170 FreeBSD is a registered trademark of The FreeBSD Foundation. 00000171 FreeBSD 11.2-RELEASE-p10 #21 10fea60fdde(factory-RELENG_2_4_4): Thu May 16 06:26:11 EDT 2019 00000172 root@buildbot1-nyi.netgate.com:/build/factory-crossbuild-244/obj/aarch64/upm8hD25/arm64.aarch64/build/factory-crossbuild-244/pfSense/tmp/FreeBSD-src/sys/pfSense arm64 00000173 FreeBSD clang version 6.0.0 (tags/RELEASE_600/final 326565) (based on LLVM 6.0.0) 00000174 VT: init without driver. 00000175 Starting CPU 1 (1) 00000176 FreeBSD/SMP: Multiprocessor System Detected: 2 CPUs 00000177 random: entropy device external interface 00000178 ipw_bss: You need to read the LICENSE file in /usr/share/doc/legal/intel_ipw.LICENSE. 00000179 ipw_bss: If you agree with the license, set legal.intel_ipw.license_ack=1 in /boot/loader.conf. 00000180 module_register_init: MOD_LOAD (ipw_bss_fw, 0xffff00000016bec0, 0) error 1 00000181 ipw_ibss: You need to read the LICENSE file in /usr/share/doc/legal/intel_ipw.LICENSE. 00000182 ipw_ibss: If you agree with the license, set legal.intel_ipw.license_ack=1 in /boot/loader.conf. 00000183 module_register_init: MOD_LOAD (ipw_ibss_fw, 0xffff00000016bf6c, 0) error 1 00000184 ipw_monitor: You need to read the LICENSE file in /usr/share/doc/legal/intel_ipw.LICENSE. 00000185 ipw_monitor: If you agree with the license, set legal.intel_ipw.license_ack=1 in /boot/loader.conf. 00000186 module_register_init: MOD_LOAD (ipw_monitor_fw, 0xffff00000016c018, 0) error 1 00000187 iwi_bss: You need to read the LICENSE file in /usr/share/doc/legal/intel_iwi.LICENSE. 00000188 iwi_bss: If you agree with the license, set legal.intel_iwi.license_ack=1 in /boot/loader.conf. 00000189 module_register_init: MOD_LOAD (iwi_bss_fw, 0xffff00000016c0c4, 0) error 1 00000190 iwi_ibss: You need to read the LICENSE file in /usr/share/doc/legal/intel_iwi.LICENSE. 00000191 iwi_ibss: If you agree with the license, set legal.intel_iwi.license_ack=1 in /boot/loader.conf. 00000192 module_register_init: MOD_LOAD (iwi_ibss_fw, 0xffff00000016c170, 0) error 1 00000193 iwi_monitor: You need to read the LICENSE file in /usr/share/doc/legal/intel_iwi.LICENSE. 00000194 iwi_monitor: If you agree with the license, set legal.intel_iwi.license_ack=1 in /boot/loader.conf. 00000195 module_register_init: MOD_LOAD (iwi_monitor_fw, 0xffff00000016c21c, 0) error 1 00000196 wlan: mac acl policy registered 00000197 kbd0 at kbdmux0 00000198 ofwbus0: \u0026lt;Open Firmware Device Tree\u0026gt; 00000199 simplebus0: \u0026lt;Flattened device tree simple bus\u0026gt; on ofwbus0 00000200 simplebus1: \u0026lt;Flattened device tree simple bus\u0026gt; on simplebus0 00000201 psci0: \u0026lt;ARM Power State Co-ordination Interface Driver\u0026gt; on ofwbus0 00000202 gic0: \u0026lt;ARM Generic Interrupt Controller v3.0\u0026gt; mem 0x1d00000-0x1d0ffff,0x1d40000-0x1d7ffff,0x1d80000-0x1d81fff,0x1d90000-0x1d91fff,0x1da0000-0x1dbffff irq 27 on simplebus1 00000203 generic_timer0: \u0026lt;ARMv8 Generic Timer\u0026gt; irq 0,1,2,3 on ofwbus0 00000204 Timecounter \u0026#34;ARM MPCore Timecounter\u0026#34; frequency 12500000 Hz quality 1000 00000205 Event timer \u0026#34;ARM MPCore Eventtimer\u0026#34; frequency 12500000 Hz quality 1000 00000206 cpulist0: \u0026lt;Open Firmware CPU Group\u0026gt; on ofwbus0 00000207 cpu0: \u0026lt;Open Firmware CPU\u0026gt; on cpulist0 00000208 cpu1: \u0026lt;Open Firmware CPU\u0026gt; on cpulist0 00000209 pmu0: \u0026lt;Performance Monitoring Unit\u0026gt; irq 4 on ofwbus0 00000210 spi0: \u0026lt;Armada 37x0 SPI controller\u0026gt; mem 0x10600-0x10fff irq 6 on simplebus1 00000211 iichb0: \u0026lt;Marvell Armada 37x0 IIC controller\u0026gt; mem 0x11000-0x11023 irq 7 on simplebus1 00000212 iicbus0: \u0026lt;OFW I2C bus\u0026gt; on iichb0 00000213 iic0: \u0026lt;I2C generic I/O\u0026gt; on iicbus0 00000214 uart0: \u0026lt;Marvell Armada 3700 UART\u0026gt; mem 0x12000-0x121ff irq 9,10,11 on simplebus1 00000215 uart0: console (115200,n,8,1) 00000216 pinctl0: \u0026lt;Armada 37x0 North Bridge pinctl Controller\u0026gt; mem 0x13800-0x138ff,0x13c00-0x13c1f on simplebus1 00000217 gpio0: \u0026lt;Armada 37x0 GPIO Controller\u0026gt; on pinctl0 00000218 gpiobus0: \u0026lt;OFW GPIO bus\u0026gt; on gpio0 00000219 gpioc0: \u0026lt;GPIO controller\u0026gt; on gpio0 00000220 pinctl1: \u0026lt;Armada 37x0 South Bridge pinctl Controller\u0026gt; mem 0x18800-0x188ff,0x18c00-0x18c1f on simplebus1 00000221 gpio1: \u0026lt;Armada 37x0 GPIO Controller\u0026gt; on pinctl1 00000222 gpiobus1: \u0026lt;OFW GPIO bus\u0026gt; on gpio1 00000223 gpioc1: \u0026lt;GPIO controller\u0026gt; on gpio1 00000224 mvneta0: \u0026lt;NETA controller\u0026gt; mem 0x30000-0x33fff irq 14 on simplebus1 00000225 mvneta0: version is 10 00000226 mvneta0: Ethernet address: f0:ad:4e:0a:9e:98 00000227 mdio0: \u0026lt;MDIO\u0026gt; on mvneta0 00000228 e6000sw: readreg timeout 00000229 e6000sw0: Unrecognized device, id 0xfff0. 00000230 e6000sw: readreg timeout 00000231 e6000sw0: Unrecognized device, id 0xfff0. 00000232 xhci0: \u0026lt;Marvell Integrated USB 3.0 controller\u0026gt; mem 0x58000-0x5bfff irq 16 on simplebus1 00000233 xhci0: 32 bytes context size, 32-bit DMA 00000234 usbus0 on xhci0 00000235 ehci0: \u0026lt;Marvell Integrated USB 2.0 controller\u0026gt; mem 0x5e000-0x5ffff irq 17 on simplebus1 00000236 usbus1: EHCI version 1.0 00000237 usbus1 on ehci0 00000238 sdhci_xenon0: \u0026lt;Armada Xenon SDHCI controller\u0026gt; mem 0xd0000-0xd02ff,0x1e808-0x1e80b irq 24 on simplebus1 00000239 mmc0: \u0026lt;MMC/SD bus\u0026gt; on sdhci_xenon0 00000240 sdhci_xenon1: \u0026lt;Armada Xenon SDHCI controller\u0026gt; mem 0xd8000-0xd82ff,0x17808-0x1780b irq 25 on simplebus1 00000241 mmc1: \u0026lt;MMC/SD bus\u0026gt; on sdhci_xenon1 00000242 ahci0: \u0026lt;AHCI SATA controller\u0026gt; mem 0xe0000-0xe1fff irq 26 on simplebus1 00000243 ahci0: AHCI v1.30 with 1 6Gbps ports, Port Multiplier supported with FBS 00000244 ahcich0: \u0026lt;AHCI channel\u0026gt; at channel 0 on ahci0 00000245 gpioled0: \u0026lt;GPIO LEDs\u0026gt; on ofwbus0 00000246 cryptosoft0: \u0026lt;software crypto\u0026gt; 00000247 Timecounters tick every 1.000 msec 00000248 mvneta0: link state changed to UP 00000249 spibus0: \u0026lt;OFW SPI bus\u0026gt; on spi0 00000250 mx25l0: \u0026lt;M25Pxx Flash Family\u0026gt; at cs 0 mode 0 on spibus0 00000251 mx25l0: device type mx25u3235f, size 4096K in 64 sectors of 64K, erase size 4K 00000252 usbus0: 5.0Gbps Super Speed USB v3.0 00000253 usbus1: 480Mbps High Speed USB v2.0 00000254 ugen0.1: \u0026lt;Marvell XHCI root HUB\u0026gt; at usbus0 00000255 uhub0: \u0026lt;Marvell XHCI root HUB, class 9/0, rev 3.00/1.00, addr 1\u0026gt; on usbus0 00000256 ugen1.1: \u0026lt;Marvell EHCI root HUB\u0026gt; at usbus1 00000257 uhub1: \u0026lt;Marvell EHCI root HUB, class 9/0, rev 2.00/1.00, addr 1\u0026gt; on usbus1 00000258 mmc0: No compatible cards found on bus 00000259 mmcsd0: 8GB \u0026lt;MMCHC M8G1GC 0.3 SN F49C4805 MFG 07/2013 by 21 0x0000\u0026gt; at mmc1 50.0MHz/4bit/65535-block 00000260 mmcsd0boot0: 4MB partion 1 at mmcsd0 00000261 mmcsd0boot1: 4MB partion 2 at mmcsd0 00000262 mmcsd0rpmb: 524kB partion 3 at mmcsd0 00000263 uhub0: 2 ports with 2 removable, self powered 00000264 uhub1: 1 port with 1 removable, self powered 00000265 Release APs 00000266 CPU 0: ARM Cortex-A53 r0p4 affinity: 0 00000267 Instruction Set Attributes 0 = \u0026lt;AES+PMULL,SHA1,SHA2,CRC32\u0026gt; 00000268 Instruction Set Attributes 1 = \u0026lt;0\u0026gt; 00000269 Processor Features 0 = \u0026lt;GIC,AdvSIMD,Float,EL3 32,EL2 32,EL1 32,EL0 32\u0026gt; 00000270 Processor Features 1 = \u0026lt;0\u0026gt; 00000271 Memory Model Features 0 = \u0026lt;4k Granule,64k Granule,MixedEndian,S/NS Mem,16bit ASID,1TB PA\u0026gt; 00000272 Memory Model Features 1 = \u0026lt;\u0026gt; 00000273 Debug Features 0 = \u0026lt;2 CTX Breakpoints,4 Watchpoints,6 Breakpoints,PMUv3,Debug v8\u0026gt; 00000274 Debug Features 1 = \u0026lt;0\u0026gt; 00000275 Auxiliary Features 0 = \u0026lt;0\u0026gt; 00000276 Auxiliary Features 1 = \u0026lt;0\u0026gt; 00000277 CPU 1: ARM Cortex-A53 r0p4 affinity: 1 00000278 Trying to mount root from ufs:/dev/ufsid/5c11689b7c8fb123 [rw,noatime]... 00000279 WARNING: / was not properly dismounted 00000280 Warning: no time-of-day clock registered, system time will not be set accurately 00000281 Configuring crash dumps... 00000282 dumpon: /dev/label/swap*: No such file or directory 00000283 Unable to specify /dev/label/swap* as a dump device. 00000284 No suitable dump device was found. 00000285 ** SU+J Recovering /dev/ufsid/5c11689b7c8fb123 00000286 ** Reading 11730944 byte journal from inode 4. 00000287 ** Building recovery table. 00000288 ** Resolving unreferenced inode list. 00000289 ** Processing journal entries. 00000290 ** 288 journal records in 38912 bytes for 23.68% utilization 00000291 ** Freed 1 inodes (0 dirs) 4 blocks, and 0 frags. 00000292 00000293 ***** FILE SYSTEM MARKED CLEAN ***** 00000294 Filesystems are clean, continuing... 00000295 Mounting filesystems... 00000296 random: unblocking device. 00000297 00000298 __ 00000299 _ __ / _|___ ___ _ __ ___ ___ 00000300 | \u0026#39;_ \\| |_/ __|/ _ \\ \u0026#39;_ \\/ __|/ _ \\ 00000301 | |_) | _ \\__ \\ __/ | | \\__ \\ __/ 00000302 | .__/|_| |___/\\___|_| |_|___/\\___| 00000303 |_| 00000304 00000305 00000306 Welcome to pfSense 2.4.4-RELEASE (Patch 3)... 00000307 00000308 ...ELF ldconfig path: /lib /usr/lib /usr/lib/compat /usr/local/lib /usr/local/lib/ipsec /usr/local/lib/perl5/5.26/mach/CORE 00000309 done. 00000310 \u0026gt;\u0026gt;\u0026gt; Removing vital flag from lang/php72... done. 00000311 External config loader 1.0 is now starting... mmcsd0s1 mmcsd0s2 mmcsd0s3 00000312 Launching the init system......... done. 00000313 Initializing.................. done. 00000314 Starting device manager (devd)...done. 00000315 Loading configuration......done. 00000316 Updating configuration...done. 00000317 Checking config backups consistency.................................done. 00000318 Setting up extended sysctls...done. 00000319 Setting timezone...done. 00000320 Configuring loopback interface...done. 00000321 Starting syslog...done. 00000322 Starting Secure Shell Services...done. 00000323 Configuring switch...done. 00000324 Setting up interfaces microcode...done. 00000325 Configuring loopback interface...done. 00000326 Creating wireless clone interfaces...done. 00000327 Configuring LAGG interfaces...done. 00000328 Configuring VLAN interfaces...done. 00000329 Configuring QinQ interfaces...done. 00000330 Configuring IPsec VTI interfaces...done. 00000331 Configuring WAN interface...done. 00000332 Configuring LAN interface...done. 00000333 Configuring CARP settings...done. 00000334 Syncing OpenVPN settings...done. 00000335 Configuring firewall......done. 00000336 Starting PFLOG...done. 00000337 Setting up gateway monitors...done. 00000338 Setting up static routes...route: writing to routing socket: Network is unreachable 00000339 route: route has not been found 00000340 done. 00000341 Setting up DNSs... 00000342 Starting DNS Resolver...done. 00000343 Synchronizing user settings...done. 00000344 Starting webConfigurator...done. 00000345 Configuring CRON...done. 00000346 Starting NTP time client...done. 00000347 Starting DHCP service...done. 00000348 Configuring firewall......done. 00000349 Generating RRD graphs...done. 00000350 Starting syslog...done. 00000351 Starting CRON... done. 00000352 Starting package acme...done. 00000353 pfSense 2.4.4-RELEASE (Patch 3) arm64 Thu May 16 06:01:19 EDT 2019 00000354 Bootup complete 00000355 00000356 FreeBSD/arm64 (pfsense.domain.local) (ttyu0) 00000357 00000358 Netgate SG-1100 Netgate Device ID: XXXXXXXXXXXXXXXXXXXX 00000359 Serial: XXXXXXXXXXXXX Netgate Crypto ID: XXXXXXXXXXXXXXXXXX 00000360 00000361 *** Welcome to pfSense 2.4.4-RELEASE-p3 (arm64) on pfsense *** 00000362 00000363 WAN (wan) -\u0026gt; mvneta0.4090 -\u0026gt; 00000364 LAN (lan) -\u0026gt; mvneta0.4091 -\u0026gt; v4: 10.10.2.1/24 00000365 OPT (opt1) -\u0026gt; mvneta0.4092 -\u0026gt; 00000366 00000367 0) Logout (SSH only) 9) pfTop 00000368 1) Assign Interfaces 10) Filter Logs 00000369 2) Set interface(s) IP address 11) Restart webConfigurator 00000370 3) Reset webConfigurator password 12) PHP shell + pfSense tools 00000371 4) Reset to factory defaults 13) Update from console 00000372 5) Reboot system 14) Disable Secure Shell (sshd) 00000373 6) Halt system 15) Restore recent configuration 00000374 7) Ping host 16) Restart PHP-FPM 00000375 8) Shell 00000376 00000377 Enter an option: -Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2019/07/my-sg-1100-died/","summary":"Hey! Listen! This post is part of a series on pfSense. Check them all out!\nDate URL Part 2019-08-25 pfSense on the PC Engines APU2 Migrated to a PC Engines APU2D4 2019-07-17 My SG-1100 died Migrated back the the EdgeRouter Lite 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 Introduction I recently wrote about how I was dropping the Ubiquiti EdgeRouter Lite for a Netgate SG-1100 running pfSense.","title":"My SG-1100 died"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction For years, I\u0026rsquo;ve been using and loving my Ubiquiti EdgeRouter Lite. For about $100, you\u0026rsquo;re not going to find a router with more features. In fact, most of Ubiquiti\u0026rsquo;s offerings are a very good value for the money. However, in the past year or so, Ubiquiti has seemed to have some issues with what direction they want to take as a company:\nA (seemingly pointless) re-brand from Ubiquiti/UBNT to UI.com (I wonder how much that domain name cost them) A (seemingly pointless) re-work of their forum software (it\u0026rsquo;s much more unorganized now) They (Ubiquiti) regularly ignored some of the most upvoted/requested ideas on their forums (which ironically, don\u0026rsquo;t exist on the new forum) to pursue new products They released the FrontRow wearable camera (not sure who asked for this product to exist) They released a series of network-connected LED lights and dimmer switches They released a series of VoIP phones They released the EdgeMax v2.0.0 firmware and almost immediately pulled it because of its beta-level quality. All releases since v2.0.0 seem to have had issues as well. They deprecated UniFi Video in favor of UniFi Protect (which only runs on Ubiquiti hardware) They put ads for UniFi Protect inside existing UniFi Video installations They removed SNMP from EdgeSwitch firmware They added phone-home telemetry to the UniFi Wireless firmware It seems that Ubiquiti is throwing shit at a wall and seeing what sticks. Don\u0026rsquo;t get me wrong, I\u0026rsquo;d still recommend the EdgeRouter line to anyone who is currently using a router from BestBuy. However, I was growing tired and nervous of Ubiquiti\u0026rsquo;s decision making, so I resolved to replace my EdgeRouter with something slightly more stable and focused.\nRequirements Hardware In terms of raw power, the EdgeRouter Lite is only a 500Mhz dual core MIPS CPU with 512MB of DDR2 RAM, so the bar was set pretty low. I knew I was going to be looking for a mini-PC form-factor, and only had a few requirements:\nHardware that is small, low power, and fanless (this device is in my living room, not a server rack) Have Intel NICs (they generally have better compatibility with Linux/BSD than Realtek) Be around $250 or less, including RAM (but not storage) With that said, below are the devices that I came up with in my search.\nDevice Link Price CPU RAM Storage NICs Price with 4GB RAM, no storage BIOS updates Comments Jetway JBC313U591W-3160-B Amazon $249 Quad Core Intel Celeron N3160 @ 1.60GHz Up to 8GB DDR3 mSATA 2x Intel i211-AT $273 Infrequent APU2D4 PC Engines $134 Quad Core AMD GX-412TC @ 1.00 GHz 4GB DDR3 (included) mSATA 3x Intel i210-AT $134 Very frequent Supports Coreboot Fitlet 2 Fitlet $193 Quad Core Intel Celeron J3455 @ 1.50GHz Up to 16GB DDR3 M.2 2x Intel i211-AT $222 Infrequent Protectli FW2B Protectli $179 Dual Core Intel Celeron J3060 @ 1.60 GHz Up to 8GB DDR3 mSATA 2x Intel i211-AT $206 Infrequent Supports Coreboot Shuttle DS77U Amazon $262 Dual Core Intel Celeron 3865U @ 1.80 GHz Up to 32GB DDR4 2.5\u0026quot; SATA and M.2 1x Intel i211 and 1x Intel i219-LM $281 Frequent Netgate SG-1100 Netgate $159 Dual Core ARM Cortex A53 @ 1.20 GHz 1GB DDR4 (included) 8GB eMMC 3x NICs (assuming Intel?) $159 Unknown A customized ESPRESSObin Software I have a relatively simple setup at home, so my requirements for a router OS were simple:\nDHCP leases and static mapping DNS Set internal domain name DNS forwarder Register DHCP leases and static mappings in DNS resolver Host overrides (e.g., CNAME records) Dynamic DNS updater Firewall 802.1Q VLANs Remote logging (to a remote server) I considered Untangle NG Firewall, Sophos UTM Home Edition, Sophos XG Firewall Home Edition, ZeroShell, IPFire, ClearOS Community Edition, Smoothwall Express, and Endian, but chose not to pursue them because they were either proprietary, had limited functionality, or were abandoned completely. In the end, I narrowed my search down to pfSense, OPNsense, and VyOS.\nSoftware Advantage Disadvantage Based on Comments pfSense Feature-rich firewall Supported by a real company (Netgate) with paid developers Very stable with good track record GUI runs as root The company behind pfSense (Netgate) did some shady shit to the OPNsense team FreeBSD Known to be a firewall with basic routing support OPNsense Feature-rich firewall Newer GUI than pfSense Some talk of poor code quality in HardenedBSD Considered to be \u0026#8220;run by amateurs\u0026#8221; FreeBSD (fork of pfSense) Based on HardenedBSD VyOS Feature-rich router (e.g., advanced routing protocols like BGP, OSPF, etc\u0026#8230;) Cisco/Juniper-style command-line interface Much better performance than anything based on BSD because Linux has better driver support and is multi-core aware Newest version of VyOS is based on an old version of Debian that is only supported until 2020 No GUI (not a huge issue since I\u0026#8217;m familiar with EdgeOS) Debian Known to be a router with basic firewall support Moved to RHEL-type subscription model, offering \u0026#8220;stable\u0026#8221; version to paid users, and \u0026#8220;rolling\u0026#8221; releases to free users (e.g., like RHEL vs CentOS) pfSense on the Netgate SG-1100 At first, I considered using the Shuttle DS77U with VyOS. However, VyOS is really made for advanced routing, which is not what I needed. Then, I thought about still using the DS77U, but with pfSense. However, I really wanted to support the pfSense project by purchasing from Netgate, and in my price range, my only option was the SG-1100. Even though x86 hardware arguably has more raw power than ARM hardware, the SG-1100 is no slouch. The ARM hardware is very specialized and can route at full gigabit (as seen by Lawrence Systems) and it has received some really great Reddit reviews.\nThe first ten minutes Having never used pfSense before, I spent the first few minutes poking around in the web interface. The web GUI is snappy, and the device doesn\u0026rsquo;t seem to run too hot.\nThe first 24 hours Before buying the SG-1100, I spent a good bit of time looking at my EdgeRouter configuration file and Googling how to duplicate it in pfSense. After going through the initial setup wizard,¬†I went through the following tasks to port my EdgeRouter configuration over to pfSense.\nSetup new user accounts Setup my DHCP server Setup DHCP static mappings Setup CNAME records (which pfSense calls \u0026ldquo;host overrides\u0026rdquo;) Setup port forwarding rules Setup firewall rules Setup dynamic DNS Setup remote logging Setup configuration backup I then shutdown all of my servers/devices, swapped out the routers, and powered up the SG-1100. To no one\u0026rsquo;s surprise, the SG-1100 booted up flawlessly and started handing out IP addresses.\npfSense vs EdgeOS Obviously pfSense is going to be different than EdgeOS, but in the first day or two, a few things stuck out immediately.\npfSense is based on FreeBSD, while EdgeOS is based on Debian Linux. I know nothing about how FreeBSD works under the hood, so my fear of the command-line is much greater on pfSense than on EdgeOS. That being said, pfSense has almost no command-line configuration. All of the configuration is done via the web interface, which has more options than I\u0026rsquo;ll ever use. Comparatively, EdgeOS had a relatively mediocre web interface, with all the advanced configuration being done via the command-line. The firewall setup on pfSense is very different from EdgeOS. I was used to a zone-based firewall with EdgeOS, but pfSense uses a more traditional interface-based firewall. pfSense has an implicit deny on the WAN inbound interface, and an implicit allow on the LAN outbound interface. EdgeOS only has this if you follow the setup wizard, whereas if you setup EdgeOS by hand, those rules are not there by default. Both pfSense and EdgeOS can route gigabit, and both are able to utilize my 400/400Mbps FiOS internet connection. Running the command below to download 500Mb test file, I\u0026rsquo;m able to max out my connection with both routers, so I have no complaints there.\nwget --report-speed=bits --output-document=/dev/null http://speedtest.wdc01.softlayer.com/downloads/test500.zip I\u0026rsquo;ll spend the next few days tweaking all my pfSense settings, and then working on getting logging setup to push pfSense firewall logs to Graylog. Until then, I\u0026rsquo;m a happy SG-1100 and pfSense user!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2019/06/migrating-away-from-the-ubiquiti-edgerouter-lite/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction For years, I\u0026rsquo;ve been using and loving my Ubiquiti EdgeRouter Lite.","title":"Migrating away from the Ubiquiti EdgeRouter Lite"},{"content":"TL;DR Skip to the bottom.\nIntroduction I receive a lot of email questions about my resume, specifically asking why I use LaTeX, and also asking for the source (which is at the very bottom). I thought I\u0026rsquo;d take a few minutes to discuss why I use LaTeX.\nFor the past 10 years, I\u0026rsquo;ve been writing my resume in Microsoft Word. Over time, it had become a burden to update. More often than not, I ended up fighting with the formatting, instead of focusing on the content. The slightest change to a column, graphic, or font would completely alter the formatting of the entire document. With this frustration in mind, I set out to find a new way to write my resume.\nI first switched to LibreOffice Writer, but that didn\u0026rsquo;t solve my formatting problem (although, I was happy to dump Word). I then looked into plain text, then Markdown, and finally HTML/CSS. However, each solution had its own advantages and disadvantages (shown below).\nSoftware Advantage Disadvantage Plain text Portable Will work on any system Zero formatting Considered ‚Äúugly‚Äù Markdown Some formatting Un-compiled text is still human readable Can use Pandoc to convert to multiple formats No easy way to change fonts All Markdown documents look the same (without some heavy customization) HTML/CSS Most customizable option Considered ‚Äúmodern‚Äù Option to print to PDF Most difficult to read and write Some employers will not accept a pure HTML/CSS resume However, after searching Reddit, HackerNews, and StackExchange, I kept seeing LaTeX being recommended, so I decided to give it a shot.\nDisclaimer Before I begin, I wanted to say a few things, because someone will call me out if I don\u0026rsquo;t:\nI\u0026rsquo;m not a writer (obviously) and I don\u0026rsquo;t write for a living (luckily for me). I\u0026rsquo;m not a LaTeX expert and I don\u0026rsquo;t claim to be (talk to the folks at TeX.SE). I\u0026rsquo;ve only been using LaTeX for my resume for about a year. I don\u0026rsquo;t write scientific papers or large documents using LaTeX. I\u0026rsquo;m not a typography nerd. Yes, Computer Modern is beautiful. Yes, LaTeX documents look great. That\u0026rsquo;s not why I use LaTeX. A (very) brief history of TeX and LaTeX TeX To understand LaTeX (pronounced like lay-tek), we first need to understand its predecessor, TeX (pronounced like tek). TeX was a typesetting system created by Donald Knuth in 1978 after he decided a book he was publishing looked awful (typographically), and he was determined to solve the problem himself. He created TeX with two goals in mind:\nAllow anyone to create beautiful, high-quality books Given an input, create the same output on any computer running TeX TeX was a huge success, due to a number of reasons:\nTeX was beautiful, mostly due to Knuth\u0026rsquo;s attention to typographic detail (e.g., font styles, spacing, kerning, ligatures, etc\u0026hellip;). TeX had its own programming language, which meant users could write small macros (i.e., custom commands) to speed up their workflow. TeX was open source, which also meant it was free. TeX was portable, which meant it would run on almost any system and still produce the same output. Knuth was more focused on stability and backwards compatibility than new features, and TeX was declared feature-complete in 1989 with version 3.0, with only minor bug fixes being applied since then (you can still download and use TeX today).\nThe main issue with TeX was that it focused mainly on the format of documents, which was great if you knew the TeX language really well. However, it was difficult for writers to get it working correctly, which made focusing on content difficult.\nLaTeX To solve this, Leslie Lamport created LaTeX in 1983. LaTeX is essentially a collection of helpful TeX macros that Lamport created himself. When you use LaTeX commands, you\u0026rsquo;re really just running a series of TeX commands. Because of these easy to use commands, LaTeX was simpler for writers to learn than TeX itself. In fact, the focus of LaTeX is more on the separation of format and content (whereas TeX focused on the format itself). In a way, you can think of a LaTeX document like HTML and CSS. One file holds the content, while the other file holds the formatting for that content.\nBecause LaTeX was even easier to use than TeX, its popularity soared. It gained a huge following in academia, and is still mainly used for writing books and scientific papers. It also excels in writing tasks that require mathematical expressions or non-Latin scripts, such as Chinese or Sanskrit.\nFor example, below is piece of LaTeX code (taken from Overleaf) with multiple mathematical expressions.\nSubscripts in math mode are written as $a_b$ and superscripts are written as $a^b$. These can be combined an nested to write expressions such as $$T^{i_1 i_2 \\dots i_p}_{j_1 j_2 \\dots j_q} = T(x^{i_1},\\dots,x^{i_p},e_{j_1},\\dots,e_{j_q})$$ We write integrals using $\\int$ and fractions using $\\frac{a}{b}$. Limits are placed on integrals using superscripts and subscripts: $$\\int_0^1 \\frac{1}{e^x} = \\frac{e-1}{e}$$ Lower case Greek letters are written as $\\omega$ $\\delta$ etc. while upper case Greek letters are written as $\\Omega$ $\\Delta$. Mathematical operators are prefixed with a backslash as $\\sin(\\beta)$, $\\cos(\\alpha)$, $\\log(x)$ etc. Below is the same piece of code (taken from Overleaf), but formatted via LaTeX. As I mentioned, one of the advantages of LaTeX is that the piece of code above will produce this exact output on any system running LaTeX.\nAs if that wasn\u0026rsquo;t enough, LaTeX also has the ability to load custom packages to add features/functionality. These packages include typical typesetting features, like:\nAdding custom fonts Customizing links Adding tables Adding image annotations Creating a table of contents However, some fun packages that have absolutely nothing to do with typesetting include:\nPlaying Reversi Creating sheet music Putting coffee stains on your documents Playing sudoku Creating knitting patterns Advantages of a LaTeX resume Now, onto the reason I\u0026rsquo;m writing this post. These are, in my opinion, the biggest advantages of using LaTeX to write your resume (in order).\nLess formatting, more content This is the entire reason I moved away from Word. I wrote a template (called a class in LaTeX) one time. Now, I know exactly how each piece of my resume will behave, because I\u0026rsquo;m using a template that is predictable.\nModularity Think of LaTeX as a programming language in that you write code, compile it, then execute it. When you write in LaTeX, you first write your plain text using any editor, let LaTeX compile the text, then output it to the screen or a file. My resume is modular because I can simply comment in/out a specific section, recompile, and I have a new resume that is tailored for a specific position.\nVersion control (Git) The source of a LaTeX resume is one or two text files which are easily tracked with Git. If you want to go back in time to see a specific thing, or simply undo something, having version control will help you.\nComplex formatting Have you seen some of the formatting LaTeX can offer for mathematical expressions or non-Latin scripts? It\u0026rsquo;s beautiful and consistent. Imagine trying to illustrate a quadratic equation in Microsoft Word.\nPackages There are literally thousands of packages available for LaTeX. In addition, there are many pre-created resume classes to choose from (some great options include Awesome CV, Fancy CV, moderncv, or any of these).\nStability LaTex is stable. LaTeX (written in the 80\u0026rsquo;s) still runs on top of the original TeX (written in the 70\u0026rsquo;s). How many times will Microsoft Word go through new file formats in the next 20 or 30 years? Will you be able to open the Word document you wrote in 2019 on Word 2050?\nOutput options You don\u0026rsquo;t want a recruiter editing your Word document, so you can output your resume to PDF. This also guarantees it will look great when printed (since you won\u0026rsquo;t be worrying about custom fonts). PDF not enough? Need HTML? Need plain text? Need Markdown? Need Word? Need almost any other text format? Check out Pandoc.\nOpen source I love things that are open source. I love things that are free. LaTeX is both.\nTypography Like I mentioned, I\u0026rsquo;m not a typography nerd. However, you have to admit, you can tell a LaTeX document when you see one, and they are always beautiful and professional. I\u0026rsquo;ve never looked at something and said \u0026ldquo;Was this written in Microsoft Word?!\u0026rdquo;.\nDisadvantages of a LaTeX resume These are, in my opinion, the biggest disadvantages of using LaTeX to write your resume (in order).\nLearning curve I\u0026rsquo;m going to admit, I had a hard time getting my class setup and working just right. All things equal, I could create the same resume in Word in a quarter of the time. In addition, finding the correct packages to get the formatting right was also difficult at first. And, don\u0026rsquo;t get me started on the syntax, it was not easy to master.\nLack of collaboration If you want to get advice on your resume, you can\u0026rsquo;t exactly send a .tex file to your friend to edit. Chances are, you\u0026rsquo;ll need to output a PDF, which your friend will have to take notes on using a separate program. With Word, your friend could put comments directly into the .docx file and send it back to you.\nInstall footprint LaTeX itself takes up a lot of space, and once you start downloading packages, it adds up quickly. In addition, if you\u0026rsquo;re using a GUI to edit your files, you need to account for that. Don\u0026rsquo;t be surprised if a full installation takes up 2GB.\nSource files resume.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Identification %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\documentclass{resume} \\geometry{letterpaper,portrait,margin=0.75in} \\begin{document} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Contact info %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\ContactName {First Last} % first and last name %\\ContactInfoPhysical %{123 Main Street} % house and street %{City, State ZIP} % city, state, zip %{USA} % country \\ContactInfoDigital {tel:+019876543210} % phone URL (with int\u0026#39;l code) {987-654-3210} % phone display text {mailto:email@domain.com} % email URL {email@domain.com} % email display text {https://domain.com} % web URL {domain.com} % web display text %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Work experience %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\section{{\\faBriefcase} Experience} \\PlaceAndLocation{Job Name}{City, State} \\\\ \\TitleAndYears{Title}{MM YYYY - MM YYYY} \\\\ Duties \\\\ \\begin{itemize} \\item Thing 1. \\item Thing 2. \\item Thing 3. \\end{itemize} Accomplishments \\\\ \\begin{itemize} \\item Thing 1. \\item Thing 2. \\item Thing 3. \\end{itemize} \\TitleAndYears{Title}{MM YYYY - MM YYYY} \\\\ \\TitleAndYears{Title}{MM YYYY - MM YYYY} \\\\ \\bigskip \\PlaceAndLocation{Job Name}{City, State} \\\\ \\TitleAndYears{Title}{MM YYYY - MM YYYY} \\\\ \\TitleAndYears{Title}{MM YYYY - MM YYYY} \\\\ %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Education %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\section{{\\faGraduationCap} Education} \\PlaceAndLocation{Job Name}{City, State} \\\\ \\TitleAndYears{Major}{MM YYYY - MM YYYY} \\\\ \\TitleAndYears{Minor}{GPA: 0.00/4.00} \\\\ %Accomplishments \\\\ \\begin{itemize} \\item Thing 1. \\item Thing 2. \\item Thing 3. \\end{itemize} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Skills %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\section{{\\faCheck} Skills} Put some text here. \\begin{itemize} \\item Thing 1. \\item Thing 2. \\item Thing 3. \\end{itemize} \\end{document} resume.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % This class (resume.cls) is to define the layout/structure of the template (resume.tex) % All content should go in the template file (resume.tex), not this file %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % OS Packages (Arch Linux) %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Arch packages % sudo pacman -S texmaker texlive-most %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Identification %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\ProvidesClass{resume} \\NeedsTeXFormat{LaTeX2e} \\LoadClass{article} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Settings %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\nofiles % Don\u0026#39;t create .aux files \\pagestyle{empty} % Don\u0026#39;t use page numbers %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Packages %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\RequirePackage{geometry} % To change page size/orientation/margins \\RequirePackage{fontawesome5} % To use FontAwesome5 \\RequirePackage[document]{ragged2e} % To left-align everything (using [document]) \\RequirePackage{enumitem} % To change spacing between lists \\setlist[itemize]{noitemsep,topsep=0pt} \\RequirePackage{titlesec} % To format the title \\RequirePackage{tabto} % To align text to a specific point \\newcommand*{\\rightsidetab}{.7\\linewidth}% Set the tab on the right side \\RequirePackage{color} % To define specific colors \\definecolor{darkblue}{RGB}{6,69,173} % Custom color for URLs \\RequirePackage{hyperref} % To make clickable URLs and set PDF options \\hypersetup{ colorlinks=true, linkcolor=darkblue, urlcolor=darkblue, pdftitle={Name}, pdfauthor={Name} } %%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Contact info %%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\newcommand{\\ContactName}[1]{ {\\Huge{#1}}\\\\ } \\newcommand{\\ContactInfoPhysical}[3]{ {\\faHome} {#1}, {#2} {#3}\\\\ } \\newcommand{\\ContactInfoDigital}[6]{ {\\faPhone} \\href{#1}{#2} | {\\faEnvelope} \\href{#3}{#4} | {\\faGlobeAmericas} \\href{#5}{#6}\\\\ } %%%%%%%%%%%%%%%%%%%%%%%%%%%%% % Sections %%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\titleformat{\\section} {\\Large} {}{0em} {} [\\titlerule] \\newcommand*{\\PlaceAndLocation}[2]{ {\\textbf{#1} \\tabto{\\rightsidetab}{\\faMapMarker*} {#2}} } \\newcommand*{\\TitleAndYears}[2]{ {\\textit{#1} \\tabto{\\rightsidetab} {#2}} } Anyways, I really like LaTeX and I hope you check it out! Even if you don\u0026rsquo;t stick with it, it\u0026rsquo;s still something to learn!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2019/03/why-i-write-my-resume-in-latex/","summary":"TL;DR Skip to the bottom.\nIntroduction I receive a lot of email questions about my resume, specifically asking why I use LaTeX, and also asking for the source (which is at the very bottom). I thought I\u0026rsquo;d take a few minutes to discuss why I use LaTeX.\nFor the past 10 years, I\u0026rsquo;ve been writing my resume in Microsoft Word. Over time, it had become a burden to update. More often than not, I ended up fighting with the formatting, instead of focusing on the content.","title":"Why I write my resume in LaTeX"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction What is a CNAME record? A canonical name (CNAME) record is a special type of DNS record that points one domain name to another.\nIt\u0026rsquo;s easier to explain with an example. Let\u0026rsquo;s say you own the website example.com, and you want to setup both www.example.com and example.com to go to the same place application (e.g., WordPress). You could maintain two separate A records, like this:\nwww.example.com --\u0026gt; 11.22.33.44 example.com --\u0026gt; 11.22.33.44 However, with a CNAME record, you can do this:\nwww.example.com --\u0026gt; example.com¬†\u0026lt;-- This is the CNAME record example.com --\u0026gt; 11.22.33.44 With this setup, if your server address changes, you only need to update one record (the record for example.com).\nCNAMEs as \u0026ldquo;shortcuts\u0026rdquo; The really cool part about CNAME records is that you can create DNS \u0026ldquo;shortcuts\u0026rdquo; with them.\nTime for another example. Let\u0026rsquo;s say you want to setup a backup server (with the hostname backup01) at your house and connect all your devices to it. This way, every device can backup to one central location.\ndevice01 --\\ device02 ---|--\u0026gt; backup01.localdomain device03 --/ However, eventually, the server named backup01 will need to be replaced with backup02, and when that happens, you\u0026rsquo;ll need to reconfigure every device in your house to point to the new server. But, what if you could setup a DNS name between each device and the backup server? This record is the CNAME record.\ndevice01 --\\ device02 ---|--\u0026gt; storage.localdomain --\u0026gt; backup01.localdomain device03 --/ With this setup, you can point every device to storage. Then, when backup01 eventually needs to be replaced with backup02, you can just update the CNAME record of storage. This is exactly what I\u0026rsquo;m using CNAME records for at home.\nSetting up CNAME records First, you\u0026rsquo;ll need to be using dnsmasq on your EdgeRouter instead of the default DHCP server (written by the ISC). If you don\u0026rsquo;t have dnsmasq running, I have a quick guide for that here, and Ubiquiti\u0026rsquo;s official guide is here.\nNext, you simply set your CNAME records with the command below. In this case, storage is the CNAME record, while backup01 is the actual server name.\nconfigure set service dns forwarding options cname=storage.localdomain,backup01.localdomain commit save Now, you can use the name storage on all your devices, and then update the CNAME record when you replace the server that\u0026rsquo;s behind the record.\nHope this helps!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2019/02/edgerouter-cname-records/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction What is a CNAME record?","title":"EdgeRouter CNAME records"},{"content":"Introduction WireGuard released their official iOS app today, and I wasted no time jumping on setting up a WireGuard server at home (based mostly on this guide). This is not going to be a tutorial, but instead, I\u0026rsquo;m going to talk about why WireGuard is a game-changer.\nOpenVPN drawbacks For years, I\u0026rsquo;ve used OpenVPN to connect back to my home network. Don\u0026rsquo;t get me wrong, OpenVPN is great, especially compared to dated, insecure alternatives like PPTP or L2TP/IPSec. But, for all its merits, OpenVPN has some drawbacks:\nOpenVPN is difficult to setup and maintain, especially considering configuration typically happens via command line scripts (however, there are web interfaces like OpenVPN Access Server and Pritunl). OpenVPN software isn\u0026rsquo;t built-in to devices (unlike PPTP and L2TP/IPSec). Clients are identified and authenticated via certificates, which expire at regular intervals, and need to be renewed. Certificates and client configuration files need to be distributed in a secure manner (e.g., probably not over email). OpenVPN is highly secure, but typically slow, because it uses AES encryption and offers many cipher options. OpenVPN is sensitive to changing networks (e.g., roaming from WiFi to cellular data). OpenVPN has a huge codebase, at over 600k lines of code, making it difficult to audit effectively (though, it has been audited). What is WireGuard? WireGuard is a next-generation VPN that promises to be almost everything that OpenVPN isn\u0026rsquo;t. It uses modern ideas and modern cryptography to solve modern problems.\nWhy you should use WireGuard Compared one-to-one with the drawbacks above, you can see where WireGuard succeeds.\nWireGuard is dead simple to setup, with configuration files being only a few lines long. WireGuard purposely does not have dozens of encryption and cipher options (think about choosing a cipher suite in OpenVPN). It\u0026rsquo;s designed to lack cryptographic agility, so you don\u0026rsquo;t waste time choosing poor ciphers or improperly configure encryption. Keep It Simple, Stupid. WireGuard is proposed to be included directly into the Linux kernel, with Linus himself calling the code a \u0026ldquo;work of art\u0026rdquo;. This makes WireGuard extremely fast (in most cases, near line-rate). This also greatly increases its possible user-base, as anything using Linux will have WireGuard available to it by default. Clients are authenticated with public/private keypairs, like SSH. No more expiring certificates, and no worrying about the key exchange problem. Configuration files are very small, and can be distributed as a flat file, or as a QR code (super convenient for mobile devices). WireGuard uses modern cryptography and ciphers that perform well on a wide range of devices (e.g., mobile devices), not just x86 and x64 hardware. WireGuard is designed to be available when moving networks WireGuard is only about 4k lines, making it easy to audit (though, it has not been audited yet) Some other advantages to WireGuard that didn\u0026rsquo;t fit into the categories above:\nWireGuard creates interfaces (e.g., wg0), which can be operated on like normal interfaces with tools like ip and ifconfig. It can also be managed by any network manager (e.g., systemd-networkd or NetworkManager). WireGuard is not a \u0026ldquo;chatty\u0026rdquo; protocol in that fact that it only transmits data when it needs to. When there is nothing to send, nothing is sent. This saves CPU, battery, data, etc\u0026hellip; If WireGuard is misconfigured, it will generally not work, rather than working insecurely. Wireguard doesn\u0026rsquo;t respond to unauthenticated packets, so there\u0026rsquo;s no way to \u0026ldquo;scan\u0026rdquo; for a WireGuard server, making it stealthy. WireGuard has built-in quantum cryptography resistance, with the ability to use a pre-shared key as well. Why you shouldn\u0026rsquo;t use WireGuard WireGuard is not a finished product, and should not be used in production yet. It also has not been formally audited. WireGuard is available for a variety of platforms (e.g., Linux, Mac, Android, iOS, BSDs), but not Windows (yet). Any other Windows clients are unofficial (as-of this writing). Give WireGuard a try!\n-Logan\n","permalink":"https://loganmarchione.github.io/2018/12/i-just-setup-wireguard-and-ill-never-go-back-to-openvpn/","summary":"Introduction WireGuard released their official iOS app today, and I wasted no time jumping on setting up a WireGuard server at home (based mostly on this guide). This is not going to be a tutorial, but instead, I\u0026rsquo;m going to talk about why WireGuard is a game-changer.\nOpenVPN drawbacks For years, I\u0026rsquo;ve used OpenVPN to connect back to my home network. Don\u0026rsquo;t get me wrong, OpenVPN is great, especially compared to dated, insecure alternatives like PPTP or L2TP/IPSec.","title":"I just setup WireGuard, and I'll never go back to OpenVPN"},{"content":"Introduction In March of 2018, Let\u0026rsquo;s Encrypt (the free Certificate Authority) announced they added support for wildcard certificates through the upgraded ACMEv2 protocol. I\u0026rsquo;ve been hosting most of my services on subdirectories (e.g., loganmarchione.com/rss) but have been wanting to move them to subdomains (e.g., rss.loganmarchione.com), and thought this was the perfect chance to do just that.\nWhat are wildcard certificates? Wildcard certificates cover any subdomain of a specific domain. For example, I own loganmarchione.com. Because of this, I can create services as subdomains of that domain. For example:\nwww.loganmarchione.com rss.loganmarchione.com mail.loganmarchione.com Using traditional certificates, I would need to request a certificate with one subject name and three subject alternative names. However, if I ever added another subdomain, I would need to re-request my certificate with the added domain.\nBy contrast, using wildcard certificates, I can request one certificate that is valid for loganmarchione.com and *.loganmarchione.com. Then, I can add any subdomain (e.g., testweb.loganmarchione.com or files.loganmarchione.com), and my single certificate will cover it.\nHow are wildcard certificates requested? This is going to very quickly go down a rabbit-hole, since there are a lot of moving parts to keep track of.\nACME First, we need to understand what ACME is and why it is important. The Automated Certificate Management Environment (ACME) protocol was created by the Internet Security Research Group (ISRG) back in 2016. In the past, when you wanted to create a SSL certificate for you website, you had to perform a long list of manual steps:\non the server, create a public/private keypair on the server, create a certificate signing request (CSR), including information like the domain name, business name, country/city/state, etc\u0026hellip; on the server, sign the CSR with your keys submit the CSR to the Certificate Authority (CA) the CA will sign the CSR and return a certificate (you typically paid at least $99 for this) move the certificate to the server on the server, update your webserver config file to point to the new certificate ACME automates almost 100% of this process. You simply need to download a client that is ACME-compatible, and run one command that will perform all of the functions above.\nLet\u0026rsquo;s Encrypt An automated protocol is pretty useless without a CA willing to provide certificates via that protocol. To parallel the launch of ACME, the ISRG, the Electronic Frontier Foundation (EFF), Mozilla, and other, created Let\u0026rsquo;s Encrypt. Let\u0026rsquo;s Encrypt is CA that issues free certificates using the ACME protocol. Not only are the certificates free, but Let\u0026rsquo;s Encrypt is a very transparent organization, and they try to use open source software wherever possible.\nAt the time of this writing, Let\u0026rsquo;s Encrypt has issued 50+ million active certificates, which means almost 75% of internet page loads are over HTTPS now (according to Firefox telemetry).\nACME clients Because ACME is an open protocol, anyone can write a client for ACME. The most popular, by far, is Certbot, which was created by the EFF. Certbot runs on the most platforms, and has the most features, including ACMEv2 support. Most guides will recommend using Certbot, which I do as well.\nDNS providers At the time of this writing, Certbot only supports a handful of DNS providers, listed here. I chose to use NS1.com. They offer a free tier with reasonably priced paid tiers, as well as a variety of record types. In the past, I\u0026rsquo;ve talked about Hurricane Electric and how much I like their service, but unfortunately, they don\u0026rsquo;t yet offer an API that Certbot can use.\nDNS setup Create DNS entries You can\u0026rsquo;t create a wildcard certificate if you don\u0026rsquo;t have a wildcard subdomain. I created the wildcard subdomain *.loganmarchione.com in NS1\u0026rsquo;s portal.\nCreate API key Next, I created an API key for NS1. This will allow Certbot to add/remove DNS entries without needing my NS1 username/password. I won\u0026rsquo;t cover that here, but it\u0026rsquo;s very simple if you follow their guide and give permissions to the API as shown below.\nInstall Certbot on Nginx I\u0026rsquo;m using Nginx, Certbot, and NS1.com, so I should be using the Certbot plugin called certbot-dns-nsone. However, that plugin isn\u0026rsquo;t available on my distribution (Ubuntu 16.04) yet. Because of this, I need to install pip, which is Python\u0026rsquo;s package manager, as well as Certbot for Nginx.\nsudo apt-get install python3-pip python-certbot-nginx Then, using pip, I can install the certbot-dns-nsone plugin.\npip install certbot_dns_nsone Finally, I need to create a file containing my NS1 API key.\n# NS1 API credentials used by Certbot dns_nsone_api_key = MDAwMDAwMDAwMDAwMDAw Requesting a certificate ACMEv1 (non-wildcard) ACMEv1 was the first implementation of ACME. It required you to create a directory called .well-known on your webserver (e.g., loganmarchione.com/well-known) where the ACME client would write temporary information. When running the ACMEv1 client to request a certificate, the following things would happen:\nthe ACME client would reach out to the Let\u0026rsquo;s Encrypt servers the Let\u0026rsquo;s Encrypt servers would give the ACME client a secret code to place in the .well-known directory the ACME client would place the code in the directory the Let\u0026rsquo;s Encrypt servers would check for the code if the codes matched, this proved the person running the command owned the domain name, and the certificate would be issued The only downside to this system was the fact that a directory needed to be opened up to the public internet, which was ok for internet-facing sites, but bad for internal networks (e.g., your home network).\nWith ACMEv1, I would need to request a certificate with one subject name and three subject alternative names, using the command below.\ncertbot certonly --webroot -w /var/www/wordpress/loganmarchione -d loganmarchione.com -d www.loganmarchione.com -d rss.loganmarchione.com -d mail.loganmarchione.com While there is nothing wrong with this, if I added a subdomain (e.g., analytics.loganmarchione.com), I would need to request a new certificate with the added subdomain.\nACMEv2 (wildcard) ACMEv2 still allows you to use the .well-known method, but added the ability to verify domains by allowing TXT records to be inserted into DNS. Now, when requesting a certificate, the following happens:\nthe ACME client would reach out to the Let\u0026rsquo;s Encrypt servers the Let\u0026rsquo;s Encrypt servers would give the ACME client a secret code to place into DNS the ACME client would place the code into DNS (using the API key to login) the Let\u0026rsquo;s Encrypt servers would check for the code if the codes matched, this proved the person running the command owned the domain name, and the certificate would be issued and the code removed from DNS This has the limitation of only supporting a small handful of DNS providers that offer an automated API, but it allows you to request certificates without needing to open your service to the public-facing internet (great for homelab use!).\nUsing ACMEv2 and wildcard certificates, I can request one certificate that is valid for loganmarchione.com and *.loganmarchione.com.\ncertbot certonly --dns-nsone --dns-nsone-credentials /path/to/credentials --agree-tos --non-interactive -m email@domain.com -d loganmarchione.com -d *.loganmarchione.com With wildcard, certificates, I can add any subdomain (e.g., testweb.loganmarchione.com, files.loganmarchione.com), and my single certificate will cover it.\nNginx config While Certbot can manage your Nginx config, I prefer to do it manually. To use the wildcard certificate, simply add the *.domain.com entry to your server_name declaration.\nserver { listen 80; listen [::]:80; server_name loganmarchione.com *.loganmarchione.com; return 301 https://$host$request_uri; } server { listen 443 ssl http2; listen [::]:443 ssl http2; server_name loganmarchione.com *.loganmarchione.com; #SSL/TLS settings ssl_certificate /etc/letsencrypt/live/loganmarchione.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/loganmarchione.com/privkey.pem; ssl_trusted_certificate /etc/letsencrypt/live/loganmarchione.com/chain.pem; root /var/www/wordpress/loganmarchione; autoindex off; index index.php index.html; ... ... } Anyways, I hope that helps!\n-Logan\n","permalink":"https://loganmarchione.github.io/2018/09/lets-encrypt-wildcard-certificates-with-certbot-on-nginx/","summary":"Introduction In March of 2018, Let\u0026rsquo;s Encrypt (the free Certificate Authority) announced they added support for wildcard certificates through the upgraded ACMEv2 protocol. I\u0026rsquo;ve been hosting most of my services on subdirectories (e.g., loganmarchione.com/rss) but have been wanting to move them to subdomains (e.g., rss.loganmarchione.com), and thought this was the perfect chance to do just that.\nWhat are wildcard certificates? Wildcard certificates cover any subdomain of a specific domain. For example, I own loganmarchione.","title":"Let's Encrypt wildcard certificates with Certbot on Nginx"},{"content":"Introduction In my last post, I talked about setting up an ODROID-HC2 as a NAS using OpenMediaVault. I have that up and running, and I\u0026rsquo;ve also written a few scripts to backup my data to a few of the SMB shares.\nNow, I need to get that data shipped offsite to an external location to cover my 3-2-1 backup strategy:\n3 backups 2 different types of media 1 backup offsite Software My cloud storage provider of choice is B2. I\u0026rsquo;ve written about them in the past and have generally had good luck with them, so I\u0026rsquo;d like to keep using them.\nI was looking for software to transfer my backups to an offsite location, but it had it fit a few requirements:\nwork with B2 by default - B2 is object storage, so I can\u0026rsquo;t just push files to it via SSH or SCP, I need a client that can speak in B2\u0026rsquo;s HTTP API language support encryption locally - because this data is going to be stored on devices not controlled by me, I wanted it to be encrypted locally before being sent to storage open source - since this program is going to be encrypting my data, I want it to be auditable and trustworthy While looking for backup programs, I compared the following:\nAttic BorgBackup Duplicity Duplicacy Duplicati git-annex rclone I ended up choosing rclone for this task, instead of Duplicity. Duplicity is great, but it requires a good bit of memory to run, and it writes temporary files to local storage while it encrypts and uploads them. Because the ODROID-HC2 has limited hardware, I didn\u0026rsquo;t want this to become a problem. As far as I can tell, rclone doesn\u0026rsquo;t have these problems or limitations. In addition, this backup is really a backup of a backup, so I\u0026rsquo;m just interested in pushing large amounts of data offsite as quickly as possible, which rclone seems to be suited for.\nSetup rclone Install rclone Rclone is available in the default Debian/Ubuntu repositories. However, the version is pretty out of date. On Ubuntu, you can add a PPA to get a newer version, but on Debian you can\u0026rsquo;t. Because of this, I recommend downloading the .deb directly from the rclone website.\nsudo curl -sLO https://downloads.rclone.org/rclone-current-linux-arm.deb \u0026amp;\u0026amp; sudo dpkg -i rclone-current-linux-arm.deb Then, verify rclone is installed.\nrclone -V Configure rclone remote Rclone uses a concept called remotes. Remotes are just remote storage locations, and you can nest remotes inside of other remotes.\nFirst, configure rclone. It\u0026rsquo;s important to do this as the user that will be running rclone, so keep that in mind if you want to use a service account (more about this later).\nrclone config Press n to create a new remote.\nn Name the remote (I\u0026rsquo;m using backup01).\nbackup01 Press 3 to select B2 from the menu.\n3 Enter your B2 account ID (you get this from B2\u0026rsquo;s control panel).\nxxxxxxxxxxxx Enter your B2 application ID (you get this from B2\u0026rsquo;s control panel).\nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Leave the endpoint blank.\nPress y to to save your configuration.\ny Configure rclone encrypted remote Now, we\u0026rsquo;re going to created an encrypted remote inside of our first remote. Anything that goes into this encrypted remote will be encrypted automatically.\nPress n to create a new remote.\nn Name the remote (I\u0026rsquo;m using backup01_crypt).\nbackup01_crypt Press 5 to select crypt from the menu.\n5 Enter the name of your rclone remote (e.g., backup01), followed by your B2 bucket name.\nbackup01:bucket01 Press 2 to encrypt the file names.\n2 Choose to create or generate a passphrase (I\u0026rsquo;m going to generate one).\nChoose to create or generate a salt (I\u0026rsquo;m going to generate one).\nPress y to to save your configuration.\ny Run backup When you want to backup a file or directory, use the command below.\nrclone sync /home/local/directory remote:bucket In my case, the remote is backup01_crypt, and the bucket name is bucket01.\nrclone sync /home/local/directory backup01_crypt:bucket01 Once the files are synced, you can list the files on the remote using the command below.\nrclone lsf remote:bucket In my case, the remote is backup01_crypt, and the bucket name is bucket01.\nrclone lsf backup01_crypt:bucket01 ODROID performance Overall, it look a little under 24 hours to do the initial transfer of around 580GB. During that time, my ODROID was hovering about 65-70¬∞C.\nCPU temp: 68¬∞C Also during this time, the ODROID-HC2 was using about 1GB RAM out of the available 2GB.\ntotal used free shared buff/cache available Mem: 1993 965 209 51 818 921 Swap: 996 91 905 CPU usage hovered around 60% total capacity.\nLoad average: 0.59 0.56 0.71 A note about bandwidth By default, rclone will transfer four files at the same time. If you want to change this number, you can use the --transfers flag. Obviously, if you have the hardware to support it, you can increase this number, which will decrease the amount of time it takes to complete your transfers, at the cost of CPU, memory, and bandwidth.\nrclone --transfers=6 sync /home/local/directory backup01_crypt:bucket01 My internet connection is Verizon FiOS 100/100Mbps. I found that when using the default of four transfers at once, my bandwidth usage was about 60-80Mbps. However, when I kicked the transfers up to six, my bandwidth was 100% utilized at 100Mbps. This does decrease transfer time, but the internet in my house was almost unusable because the connection was saturated. Just something to keep in mind.\nBackup your config file! By default, rclone stores all of your B2 account information, your password, salt, and settings in the ~/.rclone.conf file of the account you used to configure rclone. If you lose this file, you lose access to all of your backups. Obviously, backup this file, but don\u0026rsquo;t save the backup on your encrypted storage.\nHelpful commands I\u0026rsquo;ve tried to gather some of the most useful commands from rclone\u0026rsquo;s website.\nCommand Description rclone listremotes List all remotes rclone config show remote Show config for a remote rclone size remote:bucket Show total size and number of objects on remote rclone ls remote:bucket List objects on remote rclone lsd remote:bucket List directories on remote rclone ncdu remote:bucket Like NCDU, but for your remote. Useful for seeing what is taking up disk space rclone mount --read-only remote: /path/to/local/directory Mount your remote in a read-only state on a local directory rclone tree remote:bucket Like tree Caveat - if filenames are encrypted, it will show them as encrypted rclone serve http remote:bucket --addr :8080 Start a HTTP server to browse the remote, listen on all IPs on port 8080. Caveat - if filenames are encrypted, it will show them as encrypted rclone sync /home/local/directory remote:bucket Copy source to destination, but do delete files in the destination if they were deleted from source (like the --delete flag in rsync) rclone copy /home/local/directory remote:bucket Copy source to destination, but do not delete files in the destination if they were deleted from source rclone cleanup remote:bucket Delete old versions of files stored on the remote Hope this helps!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2018/06/rclone-on-odroid-hc2/","summary":"Introduction In my last post, I talked about setting up an ODROID-HC2 as a NAS using OpenMediaVault. I have that up and running, and I\u0026rsquo;ve also written a few scripts to backup my data to a few of the SMB shares.\nNow, I need to get that data shipped offsite to an external location to cover my 3-2-1 backup strategy:\n3 backups 2 different types of media 1 backup offsite Software My cloud storage provider of choice is B2.","title":"Rclone on ODROID-HC2"},{"content":"Introduction I\u0026rsquo;ve been doing some work on my homelab that I haven\u0026rsquo;t documented here.\nI recently decommissioned my Raspberry Pi 3 that was running my Unifi controller, Dokuwiki, and Network UPS Tools (NUT). I replaced the RPi3 with an Intel i3 NUC with 12GB RAM and a Crucial 2.5\u0026quot; SSD. I chose to use Proxmox as the hypervisor on the NUC because it is open source, has a well-proven record, and has a low learning curve. At the time of this writing, I\u0026rsquo;m running five KVM virtual machines:\nmgmt01 - Jump server and Ansible master unifi01 - Unifi controller nginx01 - LEMP stack, running Dokuwiki and NUT vpn01 - Pritunl log01 - Graylog However, the one thing I\u0026rsquo;m missing is a backup server.\n3-2-1 backup The golden rule is to follow the 3-2-1 method for backups:\n3 backups 2 different types of media 1 backup offsite Currently, I\u0026rsquo;m following the 3-2-1 backup method, except the central location is my desktop PC. This is both inconvenient and a waste of space on my desktop. Ideally, I\u0026rsquo;d like have all the backups go to a NAS-type device, and have that device push the backups to a cloud provider (I already use Backblaze B2).\nDevices I looked at quite a few options, from single-board devices to full NAS devices, but ruled most of them out.\nSoftware Advantage Disadvantage Raspberry Pi 3 Model B+ Cheap Small form-factor Large community and great aftermarket support CPU/memory is limited Fastest storage connection is USB2.0 Gigabit ethernet, but bound to USB bus, so max throughput is 300Mbps Any Raspberry Pi clone (e.g., BananaPi, OrangePi, NanoPi, etc‚Ä¶) Cheap Small form-factor Typically isn‚Äôt in mainline kernel Any x86 single-board device (e.g., Udoo, UP board, Minnowboard, etc‚Ä¶) Small form-factor SATA3 and USB3.0 x86 architecture Small community and limited aftermarket support Expensive for what the devices offer ODROID C2 Cheap Small form-factor Gigabit ethernet Fastest storage connection is USB2.0 ODROID XU4 Cheap Small form-factor Gigabit ethernet USB3.0 No SATA ports ESPRESSObin Cheap Small form-factor Gigabit ethernet SATA3 and USB3.0 Relatively new Small community and limited aftermarket support Helios4 NAS form-factor Gigabit ethernet SATA3 and USB3.0 Relatively new Small community and limited aftermarket support For the same price, I could get a NAS from Synology or QNAP GnuBee PC2 NAS form-factor Gigabit ethernet SATA3 and USB3.0 CPU/memory is limited Relatively new Small community and limited aftermarket support For the same price, I could get a NAS from Synology or QNAP An actual 2-bay NAS (e.g., Synology, QNAP, etc‚Ä¶) NAS form-factor Gigabit ethernet SATA3 and USB3.0 Official support and updates CPU/memory is limited Expensive In the end, I decided on the ODROID-HC2. The HC2 is the larger version of the HC1 (the HC1 holds 2.5\u0026quot; drives, while the HC2 holds 3.5\u0026quot; drives).\nBoth the HC2 and HC1 are based on the XU4, but lack the XU4\u0026rsquo;s HDMI port, USB 3.0 ports, eMMC slot, and GPIO connectors. The HC2 features:\nSamsung Exynos 5422 eight-core CPU 2GB DDR3 RAM USB3.0-based SATA3 port Gigabit ethernet (Realtek chipset) USB2.0 port MicroSD slot UART for serial console Stackable aluminum frame that acts as a heatsink and drive cage I purchased the HC2 from ameriDroid, along with a power cable and clear top cover. I also picked up a WD Red 4TB 5400 RPM hard drive. The Red drives are WD\u0026rsquo;s NAS drives, and the 5400 RPM speed will keep the unit quiet.\nI chose the HC2, which is only a single-drive device, because I\u0026rsquo;m not looking for a 2-bay NAS with RAID support. The primary purpose of this device will be to backup all my other devices, then ship those backups offsite. If the drive dies, I\u0026rsquo;ll put a new drive in and the only thing I\u0026rsquo;ll have lost is old backups (locally, anyways).\nSoftware The HC2 has wide support for Linux, including an Ubuntu image from ODROID, Armbian, Arch Linux Arm, and OpenMediaVault. From these, I decided to go with OpenMediaVault (OMV). OMV is a NAS solution based on (at the time of this writing) Debian 9 (Stretch). It runs services like SSH, FTP, SFTP, SMB/CIFS, NFS, rsync and many more. It also features a nice web interface, S.M.A.R.T. monitoring, and a plugin system to enhance functionality (e.g., LDAP, iSCSI, etc\u0026hellip;).\nCurrently, OMV3 is being retired, to be replaced with OMV4. However, OMV4 is still being tested for ARM boards. Because of this, you can install OMV4 one of three ways:\nInstall Armbian first, then install OMV on top of Armbian Install OMV3, then upgrade to OMV4 Install the current OMV4 test image For this install, I chose to use the OMV4 test image.\nInstallation The installation of OMV4 was pretty straight-forward, and there are plenty of guides for the XU4 that apply to the HC1 and HC2 (e.g., here, here, and here). You can also use any guide for OMV (e.g., here, here, and here) and take just the parts you need. I\u0026rsquo;m going to document what worked for me and what I enabled, but you can enable/disable whatever services you like.\nWriting the MicroSD card First, download the newest OMV4 image for the XU4/HC1/HC2 from here. You\u0026rsquo;ll need to extract the .img file from the .xz file, then pipe that through dd to write to your MicroSD card (I\u0026rsquo;m assuming you\u0026rsquo;re running Linux here).\nsudo unxz OMV_4_Odroid_XU4_HC1_HC2.img.xz sudo dd status=progress bs=4M if=OMV_4_Odroid_XU4_HC1_HC2.img of=/dev/sdX sudo sync First boot When you boot the HC2 for the very first time, expect it to take 30 minutes or so. Since this server is headless (i.e., it has no graphics output), you won\u0026rsquo;t have the option to watch a screen to verify its state. Wait for the server to ping, then head to the web interface. By default, the web interface username/password is admin/openmediavault.\nDate and time settings Navigate to System, then Date \u0026amp; Time, set your timezone, and enable NTP.\nUpdate packages Navigate to System, then Update Management. Click Check at the top of the page to check for available updates.\nCheck the box next to each package, then click Upgrade at the top of the page to update the package(s).\nOnce completed, reboot the HC2 from the menu at the top-right of the page.\nEnable HTTPS Navigate to System, then Certificates, then select the SSL tab, click Add, then click Create. Fill in the information as necessary.\nNavigate to System, then General Settings. In the Secure connection section, enable SSL/TLS and select the certificate you created. You will need to open a new tab using HTTPS instead of HTTP.\nChange default web admin password Navigate to System, then General Settings, then select the Web Administrator Password tab to update the password.\nEnable SSH I do most of my updating and management through Ansible, which requires SSH access.\nNavigate to Services, then SSH, and enable the SSH service. Also, enable Permit root login.\nChange default root password By default, the root username/password is root/openmediavault.\nNow that SSH is enabled, you can SSH to the server as root. Upon login, you should be prompted to change root\u0026rsquo;s password\nssh root@IP_goes_here Once you\u0026rsquo;ve changed the password, logout.\nexit Disable SSH for root Navigate to Services, then SSH, and disable Permit root login.\nAdd a secondary user Navigate to Access Rights Management, then User. Click Add, name your user, and set a password.\nEnable S.M.A.R.T Navigate to Storage, then S.M.A.R.T., then select the Settings tab, and enable S.M.A.R.T. monitoring.\nNavigate to the Devices tab, select your device and click Edit at the top of the page, then enable S.M.A.R.T. monitoring.\nDrive setup Physical setup Navigate to Storage, then Disks. Select your hard drive (e.g., /dev/sda) and click Wipe at the top of the page.\nSetup LVM - SKIP THIS STEP I tried to setup LVM so that I could have one encrypted partition, and one unencrypted partition. I was able to get it working, however, every reboot would break the setup. Specifically, under Filesystems, the filesystem would be marked Missing after a reboot. Checking dmesg, I would see the drive was offline with the error Medium access timeout failure. Offlining disk!.\nroot@backup01:~# dmesg | grep sda [ 14.588107] sd 0:0:0:0: [sda] 7814037168 512-byte logical blocks: (4.00 TB/3.64 TiB) [ 14.588119] sd 0:0:0:0: [sda] 4096-byte physical blocks [ 14.589011] sd 0:0:0:0: [sda] Write Protect is off [ 14.589025] sd 0:0:0:0: [sda] Mode Sense: 53 00 00 08 [ 14.589455] sd 0:0:0:0: [sda] Disabling FUA [ 14.589466] sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn\u0026#39;t support DPO or FUA [ 14.603406] sd 0:0:0:0: [sda] Attached SCSI disk [ 14.868930] device-mapper: table: 254:0: adding target device sda caused an alignment inconsistency: physical_block_size=4096, logical_block_size=512, alignment_offset=0, start=33553920 [ 14.868939] device-mapper: table: 254:0: adding target device sda caused an alignment inconsistency: physical_block_size=4096, logical_block_size=512, alignment_offset=0, start=33553920 [ 14.870900] device-mapper: table: 254:1: adding target device sda caused an alignment inconsistency: physical_block_size=4096, logical_block_size=512, alignment_offset=0, start=2194476629504 [ 14.870908] device-mapper: table: 254:1: adding target device sda caused an alignment inconsistency: physical_block_size=4096, logical_block_size=512, alignment_offset=0, start=2194476629504 [ 30.572176] sd 0:0:0:0: [sda] tag#0 uas_eh_abort_handler 0 uas-tag 1 inflight: CMD IN [ 30.572231] sd 0:0:0:0: [sda] tag#0 CDB: opcode=0x85 85 08 0e 00 00 00 01 00 00 00 00 00 00 40 ec 00 [ 45.597301] sd 0:0:0:0: [sda] tag#1 uas_eh_abort_handler 0 uas-tag 2 inflight: CMD IN [ 45.597352] sd 0:0:0:0: [sda] tag#1 CDB: opcode=0x88 88 00 00 00 00 00 ff 78 7f 7f 00 00 00 08 00 00 [ 61.612177] sd 0:0:0:0: [sda] tag#1 uas_eh_abort_handler 0 uas-tag 2 inflight: CMD IN [ 61.612228] sd 0:0:0:0: [sda] tag#1 CDB: opcode=0x85 85 08 0e 00 00 00 01 00 00 00 00 00 00 40 a1 00 [ 76.637308] sd 0:0:0:0: [sda] tag#0 uas_eh_abort_handler 0 uas-tag 1 inflight: CMD IN [ 76.637361] sd 0:0:0:0: [sda] tag#0 CDB: opcode=0x88 88 00 00 00 00 00 ff 78 7f 7f 00 00 00 08 00 00 [ 76.786240] sd 0:0:0:0: [sda] tag#0 Medium access timeout failure. Offlining disk! [ 76.786522] sd 0:0:0:0: [sda] killing request [ 76.786690] sd 0:0:0:0: [sda] UNKNOWN(0x2003) Result: hostbyte=0x01 driverbyte=0x00 [ 76.786787] sd 0:0:0:0: [sda] CDB: opcode=0x88 88 00 00 00 00 00 ff 78 7f 7f 00 00 00 08 00 00 [ 76.786834] blk_update_request: I/O error, dev sda, sector 4286087039 [ 76.859645] blk_update_request: I/O error, dev sda, sector 0 [ 1462.638016] blk_update_request: I/O error, dev sda, sector 0 [ 1462.640632] blk_update_request: I/O error, dev sda, sector 0 [ 1462.655726] blk_update_request: I/O error, dev sda, sector 0 [ 1462.674249] blk_update_request: I/O error, dev sda, sector 0 [ 1462.678512] blk_update_request: I/O error, dev sda, sector 0 [ 1462.697718] blk_update_request: I/O error, dev sda, sector 0 [ 2675.814067] blk_update_request: I/O error, dev sda, sector 0 [ 2698.300818] blk_update_request: I/O error, dev sda, sector 0 I could verify this by checking the file below.\ncat /sys/block/sda/device/state The only way to bring the device back online was to echo running to that file. In fact, this is the official \u0026ldquo;fix\u0026rdquo; according to RedHat.\necho running \u0026gt; /sys/block/sda/device/state Upon reboot, the device would go offline again. Because of this, I recommend skipping the LVM setup and moving straight onto creating one large filesystem.\nInstead of having shares that are at a fixed size, I\u0026rsquo;m going to use Logical Volume Manager (LVM) to create smaller volumes that I can extend/shrink as needed. If you want to skip this setup, you can move on to Format and mount volumes.\nNavigate to System, then Plugins. From the search box, search for lvm. Select openmediavault-lvm2 and click Install at the top of the page.\nFor LVM to work, we need to create three types of groups\na physical volume a volume group one or more logical volumes Navigate to Storage, then Logical Volume Management.\nNavigate to the Physical volumes tab, click Add, and select your primary drive.\nNavigate to the Volume groups tab, click Add, name your volume group, and select the physical volume you just created.\nNavigate to the Logical volumes tab, click Add, name your logical volume, select the volume group you just created, and choose a partition size.\nFormat and mount volumes Navigate to Storage, then File System, then click Create. Select the logical volume you just created, then choose a name and filesystem type (I\u0026rsquo;m using XFS).\nOnce the filesystem is created, select your new filesystem and click Mount at the top of the page.\nCreate shared folder Navigate to Access Rights Management, then Shared Folders. Click Add, name your folder, and select the filesystem we created earlier.\nEnable SMB/CIFS I have Windows, Linux, and Mac clients on my network. Because of this, I\u0026rsquo;m choosing to use Server Message Block (SMB) to share files.\nNavigate to Services, then SMB/CIFS. On the Settings tab, enable the SMB service.\nNavigate to the Shares tab, click Add, then enable the share and select the shared folder we created earlier.\nGrant privileges Navigate to Access Rights Management, then Shared Folders, select your shared folder, and click Privileges. Here, grant Read/Write privileges to the user you created earlier.\nClient setup I won\u0026rsquo;t cover how to setup every single type of client. In this case, Google \u0026ldquo;how to connect to smb from YOUR DEVICE HERE\u0026rdquo;.\nPerformance As you can see below, the performance is close to 1Gbps, which means the HC2 is able to almost saturate the network connection. Because of this, I don\u0026rsquo;t believe any of the tweaks suggested here or here apply. Specifically, the CPU governor is set to ondemand by default¬†(shown in the command below) and since we\u0026rsquo;re using XFS, the NTFS tweaks don\u0026rsquo;t apply.\nsudo grep GOVERNOR /etc/default/openmediavault Write performance Here, I\u0026rsquo;m copying a 1GB file from a Windows 10 laptop to OMV4 over wired ethernet.\nHere is the same test, but with a 10GB file.\nRead performance Here, I\u0026rsquo;m copying a 1GB file from a OMV4 to aWindows 10 laptop over wired ethernet.\nHere is the same test, but with a 10GB file.\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2018/06/odroid-hc2-as-an-entry-level-nas/","summary":"Introduction I\u0026rsquo;ve been doing some work on my homelab that I haven\u0026rsquo;t documented here.\nI recently decommissioned my Raspberry Pi 3 that was running my Unifi controller, Dokuwiki, and Network UPS Tools (NUT). I replaced the RPi3 with an Intel i3 NUC with 12GB RAM and a Crucial 2.5\u0026quot; SSD. I chose to use Proxmox as the hypervisor on the NUC because it is open source, has a well-proven record, and has a low learning curve.","title":"ODROID-HC2 as an entry-level NAS"},{"content":"Winners An update:\nComments are locked as-of 12:05pm Eastern time.\nI received 363 comments, but 4 were mine, so 359 comments gives you a 1-in-359 chance of winning (.27%).\nCongrats to the two winners, Dan and Michael! I\u0026rsquo;ll be emailing you shortly!\n-Logan\nIntroduction Since 2014, I\u0026rsquo;ve been blogging about security, open source, Linux, and routers. Since then, I\u0026rsquo;ve hit the 1000 comment mark (although technically, some comments are my own replies to your comments). To thank my readers, I\u0026rsquo;m giving away two Raspberry Pi 3 Complete Starter Kit (32 GB Edition) by CanaKit.\nI have a very similar kit, and it\u0026rsquo;s a great way to get introduced to Linux, or build something new. With a Raspberry Pi 3, you can:\ncreate a HTPC media streaming server turn a \u0026ldquo;dumb\u0026rdquo; TV into a \u0026ldquo;smart\u0026rdquo; TV setup a NAS setup a print server create an old-school game emulator (using RetroPie) learn programming replace your (really) old desktop play Minecraft build robots extend your home network setup your own cloud (using NextCloud) host a website block ads on your network (Pi-hole is great for this) build your own smart assistant run a crytocurrency node (e.g., Bitcoin, Ethereum, Monero, etc\u0026hellip;) run your own VPN server Because I spend a lot of time on reddit, and have received so much help on reddit over the years, I\u0026rsquo;ll be advertising on the following subreddits that have helped along the way (sorry, I don\u0026rsquo;t like Facebook, Instagram, Twitter, etc\u0026hellip;).\nr/homelab - messaged mods, didn\u0026rsquo;t hear back r/linux - mods OKed r/selfhosted - mods OKed r/Ubiquiti - messaged mods, didn\u0026rsquo;t hear back r/CryptoCurrency - mods OKed r/MiniPCs - messaged mods, didn\u0026rsquo;t hear back r/linux_devices - messaged mods, didn\u0026rsquo;t hear back r/linuxmasterrace - messaged mods, didn\u0026rsquo;t hear back Eligibility requirements You must be age 18 or older (sorry, kids), and reside in the United States of America (sorry, Canada). You must reside at an address that Amazon.com will deliver to, in the United States of America. You must comment between 12/5 at noon (Eastern time) and 12/8 at noon (Eastern time). How to enter Leave one comment on this post - anything will do (duplicate comments won\u0026rsquo;t be counted). When leaving your comment, use a working email address so I can reply to you if you are chosen (i.e., don\u0026rsquo;t use a temporary email). I\u0026rsquo;ll be using the Pick Giveaway Winner plugin (WordPress link, GitHub link) to choose two winners at random (duplicate comments won\u0026rsquo;t be counted). Once a winner is chosen, I\u0026rsquo;ll email you via the email you provided to request your name and mailing address to ship you the item. You\u0026rsquo;ll have 24 hours to respond. If you do not respond within 24 hours, I will choose another winner (who will then have 24 hours to respond). If you do respond within 24 hours, I\u0026rsquo;ll purchase the item from Amazon.com and it will ship directly to you. After the item is purchased and shipped, I\u0026rsquo;ll post your first name and the link to your comment at the top of this post. Your last name and email address will not be published. Some legal stuff You must be age 18 or older (sorry, kids), and reside in the United States of America (sorry, Canada). You must reside at an address that Amazon.com will deliver to, in the United States of America. You must comment between 12/5 at noon (Eastern time) and 12/8 at noon (Eastern time). No purchase is necessary for entry. You are not required to like or subscribe to this blog for entry. The number of eligible entries received determine the odds of winning. This is technically a sweepstakes (because winners are chosen randomly). This is not: a contest, because no merit or skill is involved a lottery, because no tickets are sold (plus, I\u0026rsquo;m not a government) a raffle, because no tickets are sold The winner will not pay for the item, taxes, or shipping. I will store your name and mailing address for the purpose of delivering the item. Void where prohibited by law. By submitting a comment, you are agreeing to the terms on this page, as well as my Privacy Policy. Good luck!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2017/12/celebrating-1000-comments-by-giving-away-a-raspberry-pi-3/","summary":"Winners An update:\nComments are locked as-of 12:05pm Eastern time.\nI received 363 comments, but 4 were mine, so 359 comments gives you a 1-in-359 chance of winning (.27%).\nCongrats to the two winners, Dan and Michael! I\u0026rsquo;ll be emailing you shortly!\n-Logan\nIntroduction Since 2014, I\u0026rsquo;ve been blogging about security, open source, Linux, and routers. Since then, I\u0026rsquo;ve hit the 1000 comment mark (although technically, some comments are my own replies to your comments).","title":"Celebrating 1000 comments by giving away a Raspberry Pi 3!"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction In the past, I\u0026rsquo;ve posted about my DuckDNS dynamic DNS settings, and mentioned I use Dyn as well. My Dyn setup is documented below.\nI should mention, however, that Dyn no longer offers free dynamic DNS (it was discontinued in 2014). They now charge $40/year for 30 hostnames.\nDyn setup Web setup Head over to the Dyn website and setup an account. Create a new hostname, choosing the TLD from the available options. For this setup, just click Your current location\u0026rsquo;s IP address to continue through to this process.\nGo to your Account Settings page and make note of the Updater Client Key. If you don\u0026rsquo;t have one, generate one.\nRouter setup EdgeOS only supports a handful of pre-configured DNS service providers by default (shown below).\nubnt@erl# set service dns dynamic interface eth0 service afraid dslreports easydns noip zoneedit dnspark dyndns namecheap sitelutions Luckily, Dyn is one of the providers.\nset service dns dynamic interface eth0 service dyndns set service dns dynamic interface eth0 service dyndns host-name loganmarchione.dyndns.org set service dns dynamic interface eth0 service dyndns login username set service dns dynamic interface eth0 service dyndns password updater-client-key set service dns dynamic interface eth0 service dyndns protocol dyndns2 set service dns dynamic interface eth0 service dyndns server members.dyndns.org commit save exit A couple notes on the options:\nthe hostname is the entire domain (e.g., loganmarchione.dyndns.org) the username is your account name the password is your updater client key (that long string of numbers/letters) Verify setup Trigger a manual update.¬†EdgeOS will only update the dynamic DNS provider when your IP address actually changes.\nupdate dns dynamic interface eth0 You can show the status with the command below.\nshow dns dynamic status Here, you can see the successful update.\ninterface : eth0 ip address : XX.XX.XX.XX host-name : loganmarchione.dyndns.org last update : Tue Apr 25 22:13:09 2017 update-status: good SSL settings Also, just so you know, EdgeOS uses ddclient for the dynamic DNS updates. The configuration file is located at /etc/ddclient.conf, but there is a directory at /etc/ddclient with a configuration file for each interface. By default, ddclient is setup to use SSL, as shown below.\nroot@erl:~# grep ssl /etc/ddclient/ddclient_eth*.conf ssl=yes Hope this helps!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2017/10/dyn-ddns-on-edgerouter/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction In the past, I\u0026rsquo;ve posted about my DuckDNS dynamic DNS settings, and mentioned I use Dyn as well.","title":"Dyn DDNS on EdgeRouter"},{"content":"Introduction While creating CAA records, I found myself needing a new DNS provider. During that process, I thought it would be a good idea to document what it take to host a website and how the internet works (in a very limited sense). To host a website on the public internet, you need three things:\ndomain name DNS record(s) web host Typically, most domain registrars offer basic DNS support. In addition, most web hosts also offer basic DNS support. However, you can (and probably should) have these three services hosted at three separate companies (you don\u0026rsquo;t want all your eggs in one basket).\nDomain name A domain name is a a string of characters that represents a specific space on the internet. It consists of a top-level domain (TLD), as well as a domain name. Optionally, it can contain one or more subdomains (e.g., www, ftp, etc\u0026hellip;).\nAll TLDs are maintained by The Internet Assigned Numbers Authority (IANA), a private nonprofit organization that oversees global IP address allocation. The IANA, is in turn, overseen by The Internet Corporation for Assigned Names and Numbers (ICANN), another private nonprofit organization.\nThe IANA delegates IP address assignment to five major Regional Internet Registries (RIRs), who in turn, allocate IP addresses to companies/individuals/organizations in their specific region.\nAFRINIC - African Network Information Center (Africa) ARIN - American Registry for Internet Numbers (North America and Antarctica) APNIC - Asia-Pacific Network Information Center (Asia, Australia, and New Zealand) LACNIC - Latin America and Caribbean Network Information Centre (South America and the Caribbean) RIPE NCC - The Reseaux IP Europeens Network Coordination Centre (Europe, Russia, the Middle East, and Central Asia) In fact, because of the limits of IPv4, ARIN has already used all of its allocated IP addresses. The transition to IPv6 will solve this problem, but the change is expected to take a very long time.\nWhen you purchase a domain name (e.g., loganmarchione.com), you are purchasing it through a registrar approved by the ICANN (e.g., Namecheap, GoDaddy, Hover, etc\u0026hellip;). For a small fee, the registrar registers your domain with the ICANN so that no one else can have that same domain.\nThere are other less-centralized domain registration projects, such as the .bit TLD, but they have yet to see widespread adoption.\nDNS record(s) The Domain Name System (DNS) is the \u0026ldquo;phonebook\u0026rdquo; for the internet. When you type loganmarchione.com into your browser, your computer requests the IP address associated with loganmarchione.com from special servers, called nameservers. Once your computer has this IP address from the nameserver, it can load the page in your browser. This is a simplified explanation. In reality, your computer may have to query multiple nameservers, each of which may have to query other nameservers.\nThe first query your computer sends is to one of the 13 root nameservers managed by the IANA.\na.root-servers.net b.root-servers.net c.root-servers.net d.root-servers.net e.root-servers.net f.root-servers.net g.root-servers.net h.root-servers.net i.root-servers.net j.root-servers.net k.root-servers.net l.root-servers.net m.root-servers.net These 13 servers are used by every other nameserver on the planet to start the DNS lookup process. As such, they are very important to the function of the internet and are sometimes the target of attacks.\nIt\u0026rsquo;s important to note that many types of DNS records exist, but below are some of the most common:\nA record - Returns an IPv4 address (like the example above) AAAA record - Returns an IPv6 address CAA record - Returns a Certificate Authority Authorization CNAME record - Returns an alias of one name to another MX record - Returns of list of mailservers NS record - Returns a nameserver TXT record - Returns a text record When you create a DNS record (through your registrar or a dedicated DNS provider like Hurricane Electric), you are putting an entry into one of these root nameservers, which then propagates out to every other nameserver on the planet.\nWeb host At the most basic level, a web host consists of a computer running a webserver (e.g., Nginx, Apache, etc\u0026hellip;) that sends HTML documents to computers that request them (like the example above). Obviously, there are many more configurations that can take place and the setup can become much more complicated.\nOne of the biggest decisions you can make about a web host it whether to host your pages locally (at home or work) or in the cloud (at someone else\u0026rsquo;s home or work). However, I would recommend hosting data that isn\u0026rsquo;t private (e.g., this website) in the cloud. I\u0026rsquo;m a big fan of DigitalOcean for this task.\nHope this was a good introduction to get you started!\n-Logan\n","permalink":"https://loganmarchione.github.io/2017/09/how-to-host-a-website/","summary":"Introduction While creating CAA records, I found myself needing a new DNS provider. During that process, I thought it would be a good idea to document what it take to host a website and how the internet works (in a very limited sense). To host a website on the public internet, you need three things:\ndomain name DNS record(s) web host Typically, most domain registrars offer basic DNS support. In addition, most web hosts also offer basic DNS support.","title":"How to host a website"},{"content":"Introduction Certification Authority Authorization (CAA) is a new DNS record specifying which Certificate Authorities (CAs) are allowed to issue certificates for a domain. Introduced by RFC 6844, CAA protects websites by only allowing certificates to be issued by specific CAs. If an attacker were to take over a website, they would only be able to obtain a certificate from a CA specified in DNS CAA records, limiting the damage they could do. While CAA records aren\u0026rsquo;t going to completely stop certificate misuse, they are easy to implement and are part of a larger security plan.\nIt\u0026rsquo;s important to note that creating CAA records for your domain is optional. However, as of September 8, 2017, all CAs will be required to check CAA records and comply with them, but only if they exist. If a CAA record is in place, only the specified CA can issue a certificate to the domain. If no CAA record is in place, any CA can issue a certificate to the domain.\nIn addition, Qualys SSL Labs is now testing for the presence of CAA records.\nCAA format A CAA record is made up of the following elements:\nflag - a number between 0-255, but right now only 0 (non-critical) and 1 (critical) are used tag - a string consisting of one of the three elements below: issue - allows a CA to issue regular certificates issuewild - allows a CA to issue wildcard certificates iodef - the URL where the CA can report issues or violations value - a string to represent the value of the tag In DNS, the CAA format will look like this:\nexample.com CAA \u0026lt;flags\u0026gt; \u0026lt;tag\u0026gt; \u0026lt;value\u0026gt; For example, my CAA records only allow Let\u0026rsquo;s Encrypt to issue regular certificates, denies any CA from issuing wildcard certificates, and also lists a contact address in case of any violation.\nloganmarchione.com. CAA 0 issue \u0026#34;letsencrypt.org\u0026#34; loganmarchione.com. CAA 0 issuewild \u0026#34;;\u0026#34; loganmarchione.com. CAA 0 iodef \u0026#34;mailto:email@domain.com\u0026#34; CAA generation You don\u0026rsquo;t need to be an expert to create CAA records. SSLMate has created an open source tool to generate CAA records for you. All you need to do is copy/paste them into your DNS page.\nDNS provider migration It seems that because CAA is a relatively new standard, not all DNS providers support it yet. In that case, you might need to switch DNS providers. For example, my DNS provider, Hover, does not support CAA records. I also have a Dyn account, but I would need to pay $60/year for each domain.\nHurricane Electric While looking for a dedicated DNS host, I kept seeing Hurricane Electric (HE) popup on various subreddits and forums. They are a global ISP that offers carrier-level services, as well as free services such a DNS and dynamic DNS. While their website is lacking in the visual and documentation departments, they more than make up for it in the services they offer. However, there is a bit of a learning curve and you need to know a little about DNS in order to make changes.\nFirst, create an account at dns.he.net. I\u0026rsquo;d also recommend enabling two-factor authentication. Once you\u0026rsquo;re set, login to¬†dns.he.net again.\nThen, from the menu on the left, click Add a new domain. In the prompt, enter your domain name (even if you didn\u0026rsquo;t purchase the name from HE).\nThen, click the pencil icon to edit the domain.\nHere, you\u0026rsquo;ll see a scary looking message saying that your domain is not delegated to HE\u0026rsquo;s nameservers. That\u0026rsquo;s because you need to go into your registrar\u0026rsquo;s page (in my case, Hover) and edit the nameservers to point to HE\u0026rsquo;s servers.\nUpdate your nameservers to use HE\u0026rsquo;s nameservers. I had to remove the Transfer Lock on my domain in order for the delegation to take place. That setting shouldn\u0026rsquo;t affect DNS servers, but the changes wouldn\u0026rsquo;t take effect while the domain was locked.\nWhile that\u0026rsquo;s processing, add your DNS records in HE\u0026rsquo;s control panel. In my case, I first had to duplicate all the records that were already in Hover\u0026rsquo;s DNS (A, AAAA, MX, etc\u0026hellip;). Once they\u0026rsquo;re added in HE\u0026rsquo;s control panel, delete them from Hover\u0026rsquo;s control panel.\nNext, I added the new CAA records.\nKeep in mind, it may take up to 24 hours for DNS changes to propagate throughout the internet. In my case, it took about 3-4 hours, during which time, my website and email were inaccessible. Verify the changes are in place by doing a WHOIS lookup and looking for HE\u0026rsquo;s nameservers. If the nameservers are listed, click Check Delegation in HE\u0026rsquo;s control panel to verify HE has delegation over your domain.\nYou can see SSL Labs is now testing OK for CAA records.\nHope this helps!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2017/09/creating-caa-records/","summary":"Introduction Certification Authority Authorization (CAA) is a new DNS record specifying which Certificate Authorities (CAs) are allowed to issue certificates for a domain. Introduced by RFC 6844, CAA protects websites by only allowing certificates to be issued by specific CAs. If an attacker were to take over a website, they would only be able to obtain a certificate from a CA specified in DNS CAA records, limiting the damage they could do.","title":"Creating CAA records"},{"content":"Introduction Recently, I\u0026rsquo;ve been thinking more and more about backups for my small (but growing) homelab. The golden rule is to follow the 3-2-1 method for backups:\n3 backups 2 different types of media 1 backup offsite Current setup Currently, I keep an encrypted external HDD at home and another at work. Every couple weeks, I perform a backup to both and rotate the drives (this covers a 2-1-1 backup).\nPlanned setup I\u0026rsquo;d like to add cloud storage for a full 3-2-1 backup. My idea is to centralize all my backups to one location, then send the backups offsite to a cloud storage provider. The setup below is my final goal and will fulfill my 3-2-1 requirement.\nStorage providers For this, I was looking for a raw storage endpoint with some sort of API or command line interface. I was not interested in a file syncing service (e.g., Google Drive or Dropbox) or a cloud backup solution (e.g., Crashplan or Carbonite). While looking for cloud storage providers, I compared the following:\nAmazon Cloud Drive Amazon S3 Amazon Glacier Backblaze B2 Google Nearline Tarsnap I ended up choosing Backblaze B2 storage. They seemed to be the cheapest, had the most straight-forward pricing, and were the easiest to setup with the backup program I was using.\nFull disclosure, I was already a Backblaze fanboy. I was already subscribed to their great blog where they post yearly stats on their hard drives. But, if that\u0026rsquo;s not enough, they offer free restores via USB flash drive or external HDD if your data is too big to download. And if you need to upload up to 40TB of data, you can request a Fireball (not free, but still cool).\nBackup programs While looking for backup programs, I compared the following:\nAttic BorgBackup Duplicity Duplicacy Duplicati git-annex rclone I ended up choosing Duplicity. It seemed to be the most popular program, it supports incremental backups and B2 storage, and supports encryption with GPG.\nSetup B2 Sign up and install B2 Sign up for a B2 account if you don\u0026rsquo;t have one already. You can download the official B2 command line tool from these instructions, but I\u0026rsquo;m installing the package from the AUR using pacaur. Note - You can create a bucket from the website if you don\u0026rsquo;t want to install the B2 command line tool.\npacaur -S backblaze-b2 Setup a bucket Start by authorizing your account (substitute your account ID as needed). You will be prompted for your Application Key, which you can get in the B2 control panel.\nbackblaze-b2 authorize_account xxxxxxxxxxx Now, create a bucket (make sure it is allPrivate). The bucket name must be globally unique to all of Backblaze, not just your account. You can have up to 100 buckets per account.\nbackblaze-b2 create_bucket server-backups allPrivate Finally, list your available buckets.\nbackblaze-b2 list_buckets Setup GPG I highly recommend you encrypt your backups using GPG. It\u0026rsquo;s integrated into Duplicity and will protect your files from prying eyes. I won\u0026rsquo;t be covering it here, but check out my other guide on how to create a GPG key. For this setup, I will be using a separate key for encryption and signing.\nDisclaimer - Don\u0026rsquo;t lose the keys or the passphrases to the keys. For example, don\u0026rsquo;t backup the GPG keys using Duplicity, then have your hard drive crash, which would require the GPG keys to unlock Duplicity. Store the keys on a separate backup by themselves.\nSetup Duplicity First, install Duplicity.\nsudo pacman -S duplicity Duplicity basics The basic syntax for Duplicity is below.\nduplicity [SOURCE] [DESTINATION] To backup directly to a server via SFTP, use a command similar to the one below.\nduplicity ~/backups sftp://username@server/directory/ To backup a folder to your B2 bucket, use a command similar to the one below. Substitute your account ID, application key, and bucket name as needed.\nduplicity ~/backups b2://[account_id]:[application_key]@[bucket_name]/[directory] Duplicity also handles rotating backups. Here, I\u0026rsquo;m remove backups older than 3 months.\nduplicity remove-older-than 3M b2://[account_id]:[application_key]@[bucket_name]/[directory] Duplicity script Because Duplicity has so many command line options, it\u0026rsquo;s easier to setup a script and run it via cron.\n#!/bin/sh # Backblaze B2 configuration variables B2_ACCOUNT=\u0026#34;AAA\u0026#34; B2_KEY=\u0026#34;BBB\u0026#34; B2_BUCKET=\u0026#34;CCC\u0026#34; B2_DIR=\u0026#34;backups\u0026#34; # Local directory to backup LOCAL_DIR=\u0026#34;/home/DDD/backups\u0026#34; # GPG key (last 8 characters) ENC_KEY=\u0026#34;EEEEEEEE\u0026#34; SGN_KEY=\u0026#34;FFFFFFFF\u0026#34; export PASSPHRASE=\u0026#34;GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG\u0026#34; export SIGN_PASSPHRASE=\u0026#34;HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH\u0026#34; # Remove files older than 90 days duplicity \\ --sign-key $SGN_KEY --encrypt-key $ENC_KEY \\ remove-older-than 90D --force \\ b2://${B2_ACCOUNT}:${B2_KEY}@${B2_BUCKET}/${B2_DIR} # Perform the backup, make a full backup if it\u0026#39;s been over 30 days duplicity \\ --sign-key $SGN_KEY --encrypt-key $ENC_KEY \\ --full-if-older-than 30D \\ ${LOCAL_DIR} b2://${B2_ACCOUNT}:${B2_KEY}@${B2_BUCKET}/${B2_DIR} # Cleanup failures duplicity \\ cleanup --force \\ --sign-key $SGN_KEY --encrypt-key $ENC_KEY \\ b2://${B2_ACCOUNT}:${B2_KEY}@${B2_BUCKET}/${B2_DIR} # Show collection-status duplicity collection-status \\ --sign-key $SGN_KEY --encrypt-key $ENC_KEY \\ b2://${B2_ACCOUNT}:${B2_KEY}@${B2_BUCKET}/${B2_DIR} # Unset variables unset B2_ACCOUNT unset B2_KEY unset B2_BUCKET unset B2_DIR unset LOCAL_DIR unset ENC_KEY unset SGN_KEY unset PASSPHRASE unset SIGN_PASSPHRASE Hope this helps!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2017/07/backblaze-b2-backup-setup/","summary":"Introduction Recently, I\u0026rsquo;ve been thinking more and more about backups for my small (but growing) homelab. The golden rule is to follow the 3-2-1 method for backups:\n3 backups 2 different types of media 1 backup offsite Current setup Currently, I keep an encrypted external HDD at home and another at work. Every couple weeks, I perform a backup to both and rotate the drives (this covers a 2-1-1 backup).","title":"Backblaze B2 backup setup"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction I\u0026rsquo;ve been using Dyn for my dynamic DNS for years. However, after the 2016 Dyn DDoS, I\u0026rsquo;ve decided to add a second dynamic DNS service provider, in case Dyn goes down again.\nChoosing a provider Some dynamic DNS service providers might offer more update methods or tutorials, but that\u0026rsquo;s where the differences end. Unless you\u0026rsquo;re a large client or have a very custom setup, the largest factor between providers is price. Dyn starts at $7/month, but I\u0026rsquo;m grandfathered into a $40/year plan.\nFor my second provider, I\u0026rsquo;ve chosen DuckDNS. DuckDNS was started by a redditor, they are pretty transparent, and best of all, the service is free. I\u0026rsquo;d still donate to them because I\u0026rsquo;d prefer to pay a couple of guys running a good service, rather than a corporation.\nDuckDNS setup Web setup Head over to the DuckDNS website and setup an account. Interestingly, DuckDNS only offers oAuth logins (e.g., through Google, Facebook, Reddit, etc\u0026hellip;). This is so they don\u0026rsquo;t have to worry about storing usernames/passwords themselves and can leave it to the professionals.\nNext, enter your domain in the box and click Add domain. If the domain is available, it will be registered to your account. While you\u0026rsquo;re on this same screen, make note of your account token.\nRouter setup EdgeOS only supports a handful of pre-configured DNS service providers by default (shown below).\nubnt@erl# set service dns dynamic interface eth0 service afraid dslreports easydns noip zoneedit dnspark dyndns namecheap sitelutions To use DuckDNS, we need to setup a custom service provider. Substitute your interface, hostname, and password as needed.\nset service dns dynamic interface eth0 service custom-duckdns set service dns dynamic interface eth0 service custom-duckdns host-name loganmarchione set service dns dynamic interface eth0 service custom-duckdns login nouser set service dns dynamic interface eth0 service custom-duckdns password your-token-here set service dns dynamic interface eth0 service custom-duckdns protocol dyndns2 set service dns dynamic interface eth0 service custom-duckdns server www.duckdns.org commit save exit A couple notes on the options:\nthe hostname is the prefix to your domain (e.g., loganmarchione.duckdns.org) the username is nouser (don\u0026rsquo;t use your account name) the password is your account token (that long string of numbers/letters) Verify setup Trigger a manual update.¬†EdgeOS will only update the dynamic DNS provider when your IP address actually changes.\nupdate dns dynamic interface eth0 You can show the status with the command below.\nshow dns dynamic status Here, you can see the successful update.\ninterface¬†: eth0 ip address¬†: XX.XX.XX.XX host-name¬†: loganmarchione last update¬†: Tue Apr 25 22:13:09 2017 update-status: good SSL settings Also, just so you know, EdgeOS uses ddclient for the dynamic DNS updates. The configuration file is located at /etc/ddclient.conf, but there is a directory at /etc/ddclient with a configuration file for each interface. By default, ddclient is setup to use SSL, as shown below.\nroot@erl:~# grep ssl /etc/ddclient/ddclient_eth*.conf ssl=yes Hope this helps!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2017/04/duckdns-on-edgerouter/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction I\u0026rsquo;ve been using Dyn for my dynamic DNS for years.","title":"DuckDNS on EdgeRouter"},{"content":"Introduction With the winter weather, we\u0026rsquo;ve been having brownouts and power losses more frequently. I wanted to purchase a UPS to protect my equipment from this, but I also wanted to receive alerts when the power goes out, and possibly shutdown equipment. For this, I need an Uninterruptible Power Supply (UPS) and a computer to monitor it with.\nHardware As you guessed by now, I\u0026rsquo;m going to be using my Raspberry Pi to monitor the UPS. I\u0026rsquo;m using the Raspberry Pi because it is a low power device, it is always on (hosting a webserver, Unifi controller, and a few other things), and can be run off the UPS it is monitoring.\nThe UPS I\u0026rsquo;m using is a CyberPower CP1500PFCLCD, specifically, this one. A crucial factor in choosing a UPS is whether you need¬†Pure Sine Wave or Simulated Sine Wave. This decision is based off of the type of power supply in the equipment you\u0026rsquo;re protecting. Power supplies that use Active Power Factor Correction (Active PFC) typically require Pure Sine Wave, which is shown on the left. Simulated Sine Wave, shown on the right, mimics Pure Sine Wave and is typically cheaper. However, during a switchover to battery power, Simulated Sine Wave has a momentary gap in power (shown in the red circle). During this time, no power is being sent, and Active PFC power supplies may shutdown (which defeats the purpose of the UPS in the first place). In my case, I was happy to be safe instead of sorry, and went for the Pure Sine Wave UPS.\nDisclaimer - I am not an electrical engineer ;-)\nSoftware I need some way to monitor the status of the UPS and act on it if a certain threshold is reached. CyberPower provides software called PowerPanel Personal that runs on Windows, Mac, and Linux. However, it has its limits and cannot be used with anything other than CyberPower devices. Instead, I\u0026rsquo;m going to be using the Network UPS Tools (NUT) suite. NUT has many advantages over vendor-specific software:\nOpen source, all available on GitHub Supports serial, USB, and network monitoring Supports Windows, Mac, Linux, Unix, BSD, etc\u0026hellip; Implements a client/server architecture Configuration The NUT suite consists of three components:\ndriver - connects to and communicates with the UPS server - monitors the UPS status client¬†- sends/receives information from the server The NUT suite offers a variety of configurations. In my case, I\u0026rsquo;m using the \u0026ldquo;simple\u0026rdquo; configuration, also known as standalone. It consists of one UPS and one computer which runs the driver, server, and client. This is the minimum setup needed.\nHowever, you can setup a more advanced configuration consisting of a \u0026ldquo;master\u0026rdquo; computer that runs the driver, server, and client, but also have clients running on one or more separate \u0026ldquo;slave\u0026rdquo; computers. With this configuration, the master shuts down last, giving the slaves time to shutdown first.\nDriver setup First, connect your UPS to your Raspberry Pi via the included USB cable. Verify you can see it with lsusb.\n--\u0026gt; lsusb Bus 001 Device 005: ID 0764:0501 Cyber Power System, Inc. CP1500 AVR UPS Next, we need to install the NUT suite. Just a warning, the systemd service will fail to start until we make a configuration file.\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install nut nut-client nut-server Over on NUT\u0026rsquo;s compatibility database, you can see which driver to use for the CP1500PFCLCD (in my case, it was usbhid-ups). Edit the configuration file at /etc/nut/ups.conf¬†and add the following information at the bottom. The friendly name (e.g., cyberpower1) must be one word, no spaces.\n[cyberpower1] driver = usbhid-ups port = auto desc = \u0026#34;CyberPower CP1500PFCLCD\u0026#34; Now, start the driver service (this is the same as running upsdrvctl start) and check the status. If it doesn\u0026rsquo;t start (mine didn\u0026rsquo;t), a quick reboot will solve the problem.\nsudo systemctl start nut-driver sudo systemctl status nut-driver You should see something like this when checking the status.\nFeb 09 22:05:00 rpi01 upsdrvctl[962]: Using subdriver: CyberPower HID 0.3 Feb 09 22:05:00 rpi01 upsdrvctl[962]: Network UPS Tools - Generic HID driver 0.38 (2.7.2) Feb 09 22:05:00 rpi01 upsdrvctl[962]: USB communication driver 0.32 Feb 09 22:05:01 rpi01 upsdrvctl[962]: Network UPS Tools - UPS driver controller 2.7.2 Feb 09 22:05:01 rpi01 usbhid-ups[964]: Startup successful Server setup Next, we\u0026rsquo;ll setup the server. Edit the configuration file at /etc/nut/upsd.conf and add a LISTEN directive.\nLISTEN 127.0.0.1 3493 Now, we need to add users to access the server. Edit the configuration file at¬†/etc/nut/upsd.users. Here, I\u0026rsquo;m adding an admin user and a master user.\n[admin] password = admin1 actions = SET instcmds = ALL [upsmon_local] password = local1 upsmon master Next, we need to set the server to run. Edit the configuration file at /etc/nut/nut.conf to set the mode.\nMODE=standalone Finally, start the server service (this is the same as running upsd) and check the status.\nsudo systemctl start nut-server sudo systemctl status nut-server You can test the connection via localhost (replace cyberpower1 with the friendly name of your UPS).\nsudo upsc cyberpower1@localhost If it worked, you should see something like this.\nInit SSL without certificate database battery.charge: 100 battery.charge.low: 10 battery.charge.warning: 20 battery.mfr.date: CPSlocalhost battery.runtime: 9450 battery.runtime.low: 300 battery.type: PbAcid battery.voltage: 16.0 battery.voltage.nominal: 24 device.mfr: CPS device.model: CP1500PFCLCD device.serial: 000000000000 device.type: ups driver.name: usbhid-ups driver.parameter.pollfreq: 30 driver.parameter.pollinterval: 2 driver.parameter.port: auto driver.version: 2.7.2 driver.version.data: CyberPower HID 0.3 driver.version.internal: 0.38 input.transfer.high: 139 input.transfer.low: 88 input.voltage: 119.0 input.voltage.nominal: 120 output.voltage: 136.0 ups.beeper.status: disabled ups.delay.shutdown: 20 ups.delay.start: 30 ups.load: 2 ups.mfr: CPS ups.model: CP1500PFCLCD ups.productid: 0501 ups.realpower.nominal: 900 ups.serial: 000000000000 ups.status: OL ups.test.result: No test initiated ups.timer.shutdown: -60 ups.timer.start: -60 ups.vendorid: 0764 Client setup Since I\u0026rsquo;m using the standalone setup, I can make all my connections on localhost. Edit the configuration file at /etc/nut/upsmon.conf and add the connection string, using the master user you created earlier.\nMONITOR cyberpower1@localhost 1 upsmon_local local1 master Ensure your ownership and permissions are correct.\nsudo chown root:nut /etc/nut/* sudo chmod 640 /etc/nut/* Then, start the client service (this is the same as running upsmon) and check the status.\nsudo systemctl start nut-monitor sudo systemctl status nut-monitor You can test the connection via localhost (replace cyberpower1 with the friendly name of your UPS).\nsudo upsc cyberpower1@localhost Web monitoring (Nginx) Assuming you have Nginx installed, you can monitor NUT from the master client via a browser. It\u0026rsquo;s easier to do this with Apache, but I prefer Nginx. However, unlike Apache, Nginx doesn\u0026rsquo;t have built in support for executing CGI scripts, so a helper application is needed to handle dynamic content. In this case, that package is fcgiwrap.\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install nut-cgi fcgiwrap Edit the configuration file at /etc/nut/hosts.conf and add the following line (replace cyberpower1 with the friendly name of your UPS).\nMONITOR cyberpower1@localhost \u0026#34;CyberPower CP1500PFCLCD\u0026#34; Then, add the necessary location to your Nginx configuration file (this will obviously vary a bit for everyone).\nserver { ... location /nut { alias /usr/share/nut/www/; try_files $uri $uri/ /index.html; } location /cgi-bin/ { gzip off; root /usr/lib; include fastcgi_params; fastcgi_pass unix:/var/run/fcgiwrap.socket; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; } ... } Change ownership of the CGI files and start/restart the necessary services.\nsudo chmod 644 /etc/nut/hosts.conf sudo chmod 644 /etc/nut/*.html sudo chown www-data:www-data /usr/lib/cgi-bin/nut/*.cgi sudo systemctl restart fcgiwrap.service sudo systemctl restart fcgiwrap.socket sudo systemctl restart nginx Then, visit your stats page at http://\u0026lt;your_IP\u0026gt;/nut\nIf you want to visit the settings/admin page, you will need to edit the configuration file at /etc/nut/upsset.conf and uncomment the line below. You can then login with the admin username/password we set earlier.\n###I_HAVE_SECURED_MY_CGI_DIRECTORY Email alerting Email setup Because most ISPs block port 25 (SMTP), we need an external STMP server that we can use to route messages through. Luckily, Google provides one for free if you have a Gmail account. Google\u0026rsquo;s SMTP settings are here, we\u0026rsquo;ll¬†need them later. A few protips for this:\nObviously, I would advise against using your primary Gmail account for this. Setting up a dedicated Gmail account just for this application only takes a few minutes and is worth it, in my opinion. If you use 2FA, use an app password instead of your Gmail password. You will also need to Allow less secure apps in your Settings. Start by installing msmtp, a send-only SMTP server that will relay email through Gmail. I chose msmtp over sSMTP because msmtp has sendmail compatibility and sSMTP hasn\u0026rsquo;t been updated since 2011.\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install msmtp Next, we\u0026rsquo;re going to edit the configuration file at /etc/msmtprc to include our information. Substitute your new Gmail username and password below.\n# Accounts will inherit settings from this section defaults auth on tls on tls_certcheck on tls_trust_file /etc/ssl/certs/ca-certificates.crt account default host smtp.gmail.com protocol smtp port 587 from your_email@gmail.com user your_email@gmail.com password your_app_password Send a test email to yourself to make sure it works.\nprintf \u0026#34;Subject: Test Mail\\n\\nThis is a test mail\u0026#34; | msmtp email@domain.com Alerting setup Edit the configuration file at /etc/nut/upsmon.conf and add the following information. Adjust your alerts accordingly.\nNOTIFYCMD /etc/nut/notifycmd.sh NOTIFYFLAG ONLINE SYSLOG+WALL+EXEC NOTIFYFLAG ONBATT SYSLOG+WALL+EXEC NOTIFYFLAG LOWBATT SYSLOG+WALL+EXEC NOTIFYFLAG FSD SYSLOG+WALL+EXEC NOTIFYFLAG COMMOK SYSLOG+WALL+EXEC NOTIFYFLAG COMMBAD SYSLOG+WALL+EXEC NOTIFYFLAG SHUTDOWN SYSLOG+WALL+EXEC NOTIFYFLAG REPLBATT SYSLOG+WALL+EXEC NOTIFYFLAG NOCOMM SYSLOG+WALL+EXEC NOTIFYFLAG NOPARENT SYSLOG+WALL Next, create the script at /etc/nut/notifycmd.sh.\nsudo touch /etc/nut/notifycmd.sh sudo chown root:nut /etc/nut/* sudo chmod 755 /etc/nut/notifycmd.sh Then, edit it as necessary.\n#!/bin/bash EMAIL=\u0026#39;email@domain.com\u0026#39; printf \u0026#34;Subject: NUT ALERT: $NOTIFYTYPE\\n\\nUPS: $UPSNAME\\r\\nAlert type: $NOTIFYTYPE\u0026#34; | msmtp $EMAIL Finally, cycle the services.\nsudo systemctl restart nut-driver sudo systemctl restart nut-server sudo systemctl restart nut-monitor Testing Test your email alerts by unplugging the USB cable from the Raspberry Pi and plugging it back in. This action will trigger the COMMBAD and COMMOK flags, which we\u0026rsquo;ve set to write to the syslog, wall, and execute our script.\nYou can check the syslog, as shown below.\ngrep ups /var/log/syslog You should get a message on any SSH sessions you have open, since we specified to use a wall message.\nBroadcast message from nut@rpi01 (somewhere) (Fri Feb 24 21:59:16 2017): Communications with UPS cyberpower1@localhost lost Broadcast message from nut@rpi01 (somewhere) (Fri Feb 24 21:59:21 2017): Communications with UPS cyberpower1@localhost established You should also get an email for each action.\nCaveat In our setup, upsmon calls our script directly, every time an event takes place.\n----------¬†------------------------ | upsmon | ----\u0026gt; | calls your CMDSCRIPT | ----------¬†------------------------ The main caveat with this setup is that you may get a notification storm. If the weather is bad and the power goes in and out repeatedly, you\u0026rsquo;ll get a notification for each event. To mitigate this, NUT has another program called upssched that can call our script, after a specific interval has passed.\n----------¬†------------------¬†------------------------ | upsmon | ----\u0026gt; | calls upssched | ----\u0026gt; | calls your CMDSCRIPT | ----------¬†------------------¬†------------------------ Using upssched, we can call our script after the UPS has been on battery for 30 seconds, instead of right away. Then, if the power goes back on in 20 seconds, you can cancel the timer. I haven\u0026rsquo;t set this up yet, but I\u0026rsquo;m working on it.\nTweaks After a few days, I noticed I was receiving constant storms of COMMBAD/NOCOMM/COMMOK, even though the power wasn\u0026rsquo;t going out. After some Google-ing, I stumbled across this article with a solution (copied out below).\nEdit the configuration file at /etc/nut/ups.conf¬†and add a poll interval.\n[cyberpower1] driver = usbhid-ups port = auto desc = \u0026#34;CyberPower CP1500PFCLCD\u0026#34; pollinterval = 15 Edit the configuration file at /etc/nut/upsmon.conf and add DEADTIME.\nDEADTIME 25 Edit the configuration file at /etc/nut/upsd.conf and add MAXAGE.\nMAXAGE 25 Finally, cycle the services.\nsudo systemctl restart nut-driver sudo systemctl restart nut-server sudo systemctl restart nut-monitor Apache Because I didn\u0026rsquo;t have Apache instructions, someone was nice enough to email me an Apache configuration for this. Thanks Kara!\n\u0026lt;VirtualHost *:80\u0026gt; Alias /nut /usr/share/nut/www ScriptAlias /cgi-bin /usr/lib/cgi-bin \u0026lt;Directory \u0026#34;/usr/lib/cgi-bin\u0026#34;\u0026gt; AddHandler cgi-script .py AllowOverride None Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch Order allow,deny Allow from all \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; Let me know how this works for you!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2017/02/raspberry-pi-ups-monitor-with-nginx-web-monitoring/","summary":"Introduction With the winter weather, we\u0026rsquo;ve been having brownouts and power losses more frequently. I wanted to purchase a UPS to protect my equipment from this, but I also wanted to receive alerts when the power goes out, and possibly shutdown equipment. For this, I need an Uninterruptible Power Supply (UPS) and a computer to monitor it with.\nHardware As you guessed by now, I\u0026rsquo;m going to be using my Raspberry Pi to monitor the UPS.","title":"Raspberry Pi UPS monitor (with Nginx web monitoring)"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction I\u0026rsquo;m planning on upgrading my EdgeRouter Lite (ERL) to the newly-released v1.9.1 (I\u0026rsquo;m following my upgrade guide). This time, I\u0026rsquo;m using a serial cable to connect to my ERL. This is the first time I\u0026rsquo;ve used serial, so I\u0026rsquo;m going to document the process.\nWhy serial? Serial connectors (standard RS-232) are often included on networking and enterprise equipment. Serial comes in a number of different physical connectors, called D-subminiature, including DB25 and DB9.\nSerial is a very old technology, so why is it still around? Serial is slow, doesn\u0026rsquo;t transmit power, and isn\u0026rsquo;t good for runs longer than a few meters. However, serial is a very basic connection, which means is it reliable, simple, and is almost universal. In the case of the ERL, it is easy to break the configuration in a way that locks you out. You can assign the wrong firewall rule to the wrong port, disable password authentication and then delete your SSH keys, etc\u0026hellip; Serial is an always-on, dead-simple, reliable connection to your ERL. The only downside is that you need to physically be connected to the ERL.\nSerial connection The ERL uses a standard ethernet serial port, so you\u0026rsquo;ll need a RJ45 (ethernet) to DB9 (serial) adapter. If your computer doesn\u0026rsquo;t have a DB9 serial port, you\u0026rsquo;ll also need a DB9 to USB adapter. If you only want to use one cable, you can use an all-in-one serial-to-usb cable, like this one from Amazon. If you\u0026rsquo;ve ever used Cisco products, any teal Cisco serial cable will work (Ubiquiti did that on purpose).\nThe serial settings for Ubiquiti products are listed on the Ubiquiti website, and shown below.\nBaud rate: 115200 Data bits: 8 Parity: NONE Stop bits: 1 Flow control: NONE Those same settings are sometimes abbreviated in the format shown below.\n115200 8N1 OFF Windows First, check Device Manager for your COM port. In my case, it was COM3.\nNext, connect to the ERL with the serial console of your choice. I\u0026rsquo;m using PuTTY on Windows. The settings you need are under Connection \u0026ndash;\u0026gt; Serial, shown below.\nIf you get a blank screen (shown below), just press Enter once to get the prompt to login.\nLinux Typically, you\u0026rsquo;ll need to add your user to a group to use the serial console. In Arch Linux, the group is uucp, but it may be different depending on your distribution.\nsudo gpasswd -a username uucp Start by plugging in your serial cable to identify which port it is connected to. My device was at /dev/ttyUSB0.\ndmesg | grep -iE \u0026#39;serial|tty\u0026#39; Next, you\u0026rsquo;ll need to install a program to use the serial console. I\u0026rsquo;m using picocom, but you can also use minicom, screen, etc\u0026hellip;\nsudo picocom -b 115200 -d 8 -f n -p 1 -y n /dev/ttyUSB0 Again, if you get a blank screen, just press Enter once to get the prompt to login.\nHope this helps!\n-Logan\n","permalink":"https://loganmarchione.github.io/2017/01/ubiquiti-edgerouter-serial-console-settings/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction I\u0026rsquo;m planning on upgrading my EdgeRouter Lite (ERL) to the newly-released v1.","title":"Ubiquiti EdgeRouter serial console settings"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction As you know, I love my Ubiquiti EdgeRouter Lite. Since I bought it, I\u0026rsquo;ve been wanting to purchase one of the UniFi wireless APs ever since I saw the Ars Technica review of them. I ended up picking up the UniFi AC Pro on a Black Friday deal on Jet.com.\nThe UniFi AP itself does not have a web interface (however, you can SSH to it). To manage the APs, you need to use the UniFi controller software. The software is only needed for the initial setup, and can then be turned off afterwards (which means you can do the setup on your laptop, then disable the software after the initial setup). However, if you want to enable statistic gathering or guest portal, the controller software needs to be running at all times. The controller software is available for Windows, Mac, Linux, which means it\u0026rsquo;s perfect to run on a small Linux server (like a Raspberry Pi 3).\nController setup Installation I\u0026rsquo;m going to assume you\u0026rsquo;re running this on a Raspberry Pi 3, running Raspbian. However, any Debian-based distribution should follow the same instructions.\nFirst, we need to add the repository to apt.\necho \u0026#34;deb http://www.ubnt.com/downloads/unifi/debian stable ubiquiti\u0026#34; | sudo tee /etc/apt/sources.list.d/100-ubnt.list Note - You can also specify the version of UniFi to use, as commenter battlechop did, since the stable repository is still on v4. Thanks for submitting this!\nThen, add the GPG key.\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv C0A52C50 Next, update your repositories and install Unifi.\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install unifi Now, start Unifi.\nsudo systemctl enable unifi sudo systemctl start unifi Finally, we need to disable MongoDB, since UniFi will run its own instance.\nsudo systemctl stop mongodb sudo systemctl disable mongodb Package hold If you read around r/Ubiquiti and the UniFi forums, you\u0026rsquo;ll learn that the controller releases (and AP firmware) can be hit-or-miss. Because we\u0026rsquo;ve added the UniFi repository, every time we do a sudo apt-get update \u0026amp;\u0026amp; sudo apt-get upgrade, we might update the UniFi controller software, even if we don\u0026rsquo;t want it updated. To get around this, we\u0026rsquo;ll hold back the unifi package from being updated automatically.\nsudo apt-mark hold unifi To verify it is held back, use dpkg.\nsudo dpkg -l | grep ^h Here, you can see the results.\nhi¬†unifi¬†4.8.20-8422¬†all¬†Ubiquiti UniFi server The h as the first character means the package is held, and the i as the second character means the package is currently installed.\nIf you ever need to remove the hold, use the command below.\nsudo apt-mark unhold unifi Manually update To check for a new release of the unifi package in the repository, use the command below.\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-cache policy unifi If there is a newer version, update to it manually.\nsudo apt-get install --only-upgrade unifi Oracle Java 8 (optional) Oracle changed the Java licensing model (as-of January 2019) to start charging for Oracle Java. Instead, you should stick with OpenJDK as it is open-source.\nOpenJDK has been known to have performance issues on the Pi, so I\u0026rsquo;m running Oracle\u0026rsquo;s Java 8 instead. You can find your current Java packages with the command below.\nsudo dpkg --get-selections |grep -e \u0026#34;java\\|jdk\\|jre\u0026#34; If you try to find your Java version, you\u0026rsquo;ll probably be using OpenJDK.\n--\u0026gt; java -version java version \u0026#34;1.7.0_111\u0026#34; OpenJDK Runtime Environment (IcedTea 2.6.7) (7u111-2.6.7-2~deb8u1+rpi1) OpenJDK Zero VM (build 24.111-b01, interpreted mode) Start by installing Oracle Java 8.\nsudo apt-get install oracle-java8-jdk -y Next, update your environment to use the new Java.\nsudo update-alternatives --config java Check your Java version again to make sure you\u0026rsquo;re on Java 8.\n--\u0026gt; java -version java version \u0026#34;1.8.0_65\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_65-b17) Java HotSpot(TM) Client VM (build 25.65-b01, mixed mode) Now, copy the systemd service file so we can edit it, then update it to point at the new Java location.\nsudo cp -p /lib/systemd/system/unifi.service /etc/systemd/system sudo sed -i \u0026#39;/^\\[Service\\]$/a Environment=JAVA_HOME=/usr/lib/jvm/jdk-8-oracle-arm32-vfp-hflt\u0026#39; /etc/systemd/system/unifi.service Now, restart systemd and UniFi.\nsudo systemctl daemon-reload sudo systemctl restart unifi.service Log rotation (optional) Because I\u0026rsquo;m running the controller on a Raspberry Pi 3, I have limited space on the SD card. To make sure the log files don\u0026rsquo;t fill the card, I\u0026rsquo;m going to rotate them using logrotate. Credit to¬†Kevin Burdett for this idea.\nFirst, install logrotate.\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install logrotate Then, create the configuration file to rotate your UniFi and MongoDB logs.\nsudo bash -c \u0026#39;cat \u0026gt;\u0026gt; /etc/logrotate.d/unifi \u0026lt;\u0026lt; EOF /var/log/unifi/*.log { rotate 5 daily missingok notifempty compress delaycompress copytruncate } EOF\u0026#39; The logrotate options are explained below:\nRotate any files ending in /var/log/unifi ending in .log Save 5 log files before deleting older files Rotate the log files daily If the log is missing, go onto the next one without error Do not rotate the log if it is empty Compress the log files (into gzip format) Delay compression until the log file is rotated (so processes won\u0026rsquo;t be trying to log to a compressed file) Truncate the original log file in place after creating a copy, instead of moving the old log file and optionally creating a new one Access controller You can now access the controller by going to the IP of your device, over port 8443.\nhttps://\u0026lt;device_IP_here\u0026gt;:8443 If everything is working, you should see the setup wizard. Since there are many different ways to do the setup, I won\u0026rsquo;t be covering that here.\nController alternatives There are a few alternatives to running the controller software on the Raspberry Pi on your local network:\nAs mentioned earlier, run the controller software on your PC (Windows/Mac/Linux) for initial setup. You can either turn it off after the setup, or leave it running to gather statistics. Download the UniFi app (iOS or Android) to setup the AP. The app provides limited setup functionality, with more advanced options requiring the controller. Purchase the Unifi Cloud Key ($80). This device sits on your network and runs the controller software locally, but is accessible from anywhere at https://unifi.ubnt.com. Instructions are here. Run the controller in a VPS or AWS instance. See instructions here for installation and adoption. Comparison Here, you can see my signal strength on the old access point (TP-Link Archer C7 running OpenWrt Chaos Calmer) on the 2.4GHz and 5GHz networks, respectively.\nThen, the same measurements with the new UniFi access point. Again, on the 2.4GHz and 5GHz networks, respectively.\nHope this helps!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2016/11/ubiquiti-unifi-controller-setup-on-raspberry-pi-3/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction As you know, I love my Ubiquiti EdgeRouter Lite.","title":"Ubiquiti UniFi controller setup on Raspberry Pi 3"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction One of my only¬†complaints about the EdgeRouter Lite is the usage of the¬†Internet Systems Consortium (ISC) DHCP¬†server. My main issue is that the DHCP server does not integrate with the DNS server. Because of this, DHCP names/leases are not automatically added to DNS. This topic has been addressed a few times before (here, here,¬†here, here, and¬†here).\nHowever, with the release of the v1.9.0 EdgeMax software¬†(you can use my software upgrade guide), Ubiquiti offers the use of dnsmasq. Based on a script by the forum user¬†final, the dnsmasq script has been incorporated into v.1.9.0, but only at the command-line, no GUI usage is setup yet. With dnsmasq, when you give a specific host a static lease, the host will be added to DNS, by name, automatically.\nISC vs dnsmasq With both ISC and dnsmasq, you would need to specify a static lease for each device.\nset service dhcp-server shared-network-name LAN subnet 10.10.2.1/24 static-mapping device1 ip-address 10.10.2.32 set service dhcp-server shared-network-name LAN subnet 10.10.2.1/24 static-mapping device1 mac-address \u0026#39;XX:XX:XX:XX:XX:XX\u0026#39; However, ISC does not add the above entries to DNS (which dnsmasq does). Because of this, you\u0026rsquo;ll need to add each device to DNS (if you\u0026rsquo;re using ISC).\nset system static-host-mapping host-name device1.\u0026lt;yourdomain\u0026gt; inet 10.10.2.32 set system static-host-mapping host-name device1.\u0026lt;yourdomain\u0026gt; alias device1 If you want to use ISC, but don\u0026rsquo;t want to set the static-host-mapping entry for each device, you can set the /etc/hosts file to automatically update with DNS entries. However, that\u0026rsquo;s a lot of adding/subtracting from the hosts file, and there have been reports that expired leases aren\u0026rsquo;t deleted from the hosts file.\nset service dhcp-server hostfile-update enable Instead, I\u0026rsquo;m going to switch to dnsmasq. I\u0026rsquo;ve used it on OpenWrt, DD-WRT, and Linux, so I prefer it. The caveats of dnsmasq (in Ubiquiti\u0026rsquo;s current implementation) are outlined below.\nOne of the advantages of using dnsmasq is that, if DNS forwarding is also configured, the \u0026ldquo;name resolution for local hosts\u0026rdquo; function is integrated, and the \u0026ldquo;hostfile-update\u0026rdquo; setting for the ISC DHCP implementation is not needed (it is ignored when use-dnsmasq is enabled). When use-dnsmasq is enabled, DHCP server will serve the \u0026ldquo;listen-on\u0026rdquo; interfaces configured under \u0026ldquo;service dns forwarding\u0026rdquo;, or all interfaces if that is not configured. Since some of the existing DHCP server config settings are specific to the ISC DHCP implementation (e.g., the failover settings, the \u0026ldquo;free-form\u0026rdquo; parameters settings), those will be ignored when use-dnsmasq is enabled. If \u0026ldquo;free-form\u0026rdquo; parameters for dnsmasq are needed, they can be entered under DNS forwarding config, e.g., \u0026ldquo;set service dns forwarding options \u0026hellip;\u0026rdquo;. When use-dnsmasq is enabled, the \u0026ldquo;authoritative\u0026rdquo; setting is not \u0026ldquo;per-shared-network\u0026rdquo;, i.e., \u0026ldquo;authoritative\u0026rdquo; will be enabled if it is set under any shared-network. When use-dnsmasq is enabled, the entries configured under \u0026ldquo;static-mapping\u0026rdquo; will be translated to statically assigned A records in dnsmasq (using the dnsmasq host-record directive). If a client with a static-mapping entry sends a DHCP request with a different client-name, that client-name will be ignored. Currently use-dnsmasq only handles \u0026ldquo;configuration\u0026rdquo;, and status reporting (including show commands in the CLI and the leases display in the Web UI for example) is not supported yet. Enable dnsmasq For dnsmasq to be setup properly, you need to have DNS setup to listen on certain interfaces, otherwise it will listen on all interfaces. You should also set the nameserver to the localhost (so dnsmasq is used first), then forward queries to external DNS servers. This setup is described in my initial setup, and also shown below.\nconfigure set service dhcp-server shared-network-name LAN subnet 10.10.2.1/24 dns-server 10.10.2.1 set service dns forwarding listen-on eth1 set service dns forwarding cache-size 400 set system name-server 127.0.0.1 set service dns forwarding name-server 50.116.40.226 set service dns forwarding name-server 107.170.95.180 Next, you need to set a local domain name, as shown below.\nset system domain-name home.lan Then, enable dnsmasq.\nset service dhcp-server use-dnsmasq enable commit save Test At this point (you may need a reboot), you should be able to ping your devices by hostname (as configured in the static-mapping section, above).\n/home/ubnt ubnt@erl --\u0026gt; ping rpi01_lan PING rpi01_lan.home.lan (10.10.2.32) 56(84) bytes of data. 64 bytes from rpi01 (10.10.2.32): icmp_req=1 ttl=64 time=0.404 ms 64 bytes from rpi01 (10.10.2.32): icmp_req=2 ttl=64 time=0.373 ms 64 bytes from rpi01 (10.10.2.32): icmp_req=3 ttl=64 time=0.310 ms You should also be able to access any device via its name, instead of IP.\nHope this helps!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2016/08/edgerouter-lite-dnsmasq-setup/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction One of my only¬†complaints about the EdgeRouter Lite is the usage of the¬†Internet Systems Consortium (ISC) DHCP¬†server.","title":"EdgeRouter Lite Dnsmasq setup"},{"content":"Hey! Listen! This post is part of a series on using your own router with Verizon FiOS. Check them all out!\nDate URL Part 2016-08-22 Verizon FiOS Router Maintenance Charge Maintenance Charges 2015-07-11 Use your own router with Verizon FiOS Initial Post Introduction If you\u0026rsquo;ve read my other post, you already know how to use your own router with Verizon FiOS. Interestingly enough, that post is my most popular, but¬†I was surprised to see my pageviews double¬†one day in July. I checked the referring links and was surprised to find I had been link to by ArsTechnica (thanks Ars!).¬†The article that Ars posted was about Verizon charging a $2.80/month \u0026ldquo;Router Maintenance Charge\u0026rdquo; to continue supporting the older Actiontec routers. This was the first I\u0026rsquo;d heard of this. The information first went public via email (below), and then started popping up on DSLReports.\nThank you for being a Verizon Fios¬Æ customer. We‚Äôre committed to providing you with the best internet experience possible, backed by the latest technology.\nOur records indicate that you have an older model router that is being discontinued. If you do plan to keep using your current router, we will begin billing, on 9.29.16, a monthly Router Maintenance Charge of $2.80 (plus taxes), to ensure we deliver the best support.\nYou also have the option to upgrade to a certified, pre-owned Fios Advanced Wi-Fi Router. It‚Äôs a one-time purchase of $59.99 (plus taxes) with free shipping and handling for a limited time. This is a great opportunity to enhance your Fios experience with faster Wi-Fi speeds.\nRouters being discontinued After doing some research, it seemed that Verizon was phasing out only a few¬†models of routers.¬†I came across a very helpful post by (someone who¬†appears to be) a Verizon employee in the Verizon forums.\nTalking to a Verizon representative also yielded the following information.\nXXXXXXXXX(21:21:48): The router that I show on your account is the newer actiontec router, which wouldn\u0026rsquo;t have a charge. That is the router with the red ring around it. The solid black or black and gray routers are the ones we are discontinuing.\nSo, the TL;DR of this whole thing is the routers below¬†are¬†being phased out. If your router looks like any of the models below, it\u0026rsquo;s probably best to call Verizon and confirm.\nActiontec BHR1 -¬†MI424WR Rev A, C, and D Actiontec BHR2 -¬†MI424WR Rev E¬†and¬†Rev F Westell 9100EM Rev A and Rev C What you can do about it You have three basic options:\nBuy a refurbished Actiontec (from Verizon, eBay, or Amazon), but¬†make sure you get the Rev G or newer (Rev H or Rev I). Buy the newer Quantum Gateway ($199 or $10/month from Verizon) Pay the $2.80/month fee Personally, I don\u0026rsquo;t see why you should keep¬†using one of the discontinued routers (and paying money to do it). They are technological dinosaurs that are only 10/100Mbps and run 802.11g. In addition, they won\u0026rsquo;t be receiving updates, so they\u0026rsquo;re probably security nightmares.\nDSLReports has a forum, called Verizon Direct, that is monitored by real Verizon employees. I posted there¬†and received a reply within the hour. The technician¬†I worked with was pretty technical (which I wasn\u0026rsquo;t expecting for Level 1 support), and they took care of¬†me right away. There were reports of users posting there and receiving free replacement routers, but I didn\u0026rsquo;t go that route (I just requested a return kit for my FiOS router).\nUse your own router Again, if you\u0026rsquo;re an internet-only customer, you can use your own router with Verizon FiOS. This is what I did, and it works flawlessly.\nHopefully this clears up some of the confusion surrounding the new fees and router models.\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2016/08/verizon-fios-router-maintenance-charge/","summary":"Hey! Listen! This post is part of a series on using your own router with Verizon FiOS. Check them all out!\nDate URL Part 2016-08-22 Verizon FiOS Router Maintenance Charge Maintenance Charges 2015-07-11 Use your own router with Verizon FiOS Initial Post Introduction If you\u0026rsquo;ve read my other post, you already know how to use your own router with Verizon FiOS. Interestingly enough, that post is my most popular, but¬†I was surprised to see my pageviews double¬†one day in July.","title":"Verizon FiOS Router Maintenance Charge"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction Ubiquiti just released the new v1.8.5 software for their EdgeMax devices, including the EdgeRouter Lite (ERL). I\u0026rsquo;ll be showing you how to install the new software via the CLI, which only takes a few minutes.\nThe software downloads are normally here, but since v1.8.5 was just released, it\u0026rsquo;s currently only available on the forums, here.\nIf you haven\u0026rsquo;t already, you can subscribe to the EdgeMax updates blog, located here. Ubiquiti will post all major updates here, so subscribing to the RSS feed is a good way to stay in the loop.\nBackup¬†configuration It goes without saying that you need to backup your current configuration before you upgrade. The upgrade process is supposed to preserve your configuration, but I wouldn\u0026rsquo;t rely too much on that.\nCLI I prefer to use the CLI to backup my ERL. I use a similar script on¬†all my devices, though slightly customized for each. On the ERL, it is saved under /config/scripts (since this directory is preserved during an upgrade). Essentially, it is just making a tar.gz file out of the /config directory.\n#!/bin/bash #Set variables, update as needed BACKUP_FOLDER=/backup/backup HOSTNAME=`uname -n` #Make backup directory if it doesn\u0026#39;t exist mkdir -p ${BACKUP_FOLDER} #Backup /config tar -czf ${BACKUP_FOLDER}/${HOSTNAME}_$(date +%Y%m%d_%H%M)_config.tar.gz /config \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 #Remove backups older than 7 days find ${BACKUP_FOLDER} -name \u0026#34;*.gz\u0026#34; -type f -mtime +7 -exec rm {} \\; exit This script runs on a weekly basis using the built-in scheduler (below), but you can run it manually to generate a backup.\ntask backup_script { crontab-spec \u0026#34;0 5 * * 0\u0026#34; executable { path /config/scripts/generate_backups.sh } } GUI You can backup the configuration through the GUI as well as the CLI. Login to the web GUI, then click on¬†the System tab at the bottom. Scroll down to¬†Configuration Management \u0026amp; Device Maintenance, then under¬†Back Up Config, download the configuration¬†file.\nInstall new image I recommend viewing the current version of the firmware first. This is also a good chance to double-check which hardware model you have, if you\u0026rsquo;re not 100% sure.\nshow version You can also view all the images you have saved.\nshow system image Since the ERL can only store two images at once, you\u0026rsquo;ll need to delete the old image (if you have one).\ndelete system image Download the new system image.\nadd system image https://dl.ubnt.com/firmwares/edgemax/v1.8.5/ER-e100.v1.8.5.4884695.tar Then, use the command below to show both installed images.\nshow system image Reboot to load the new image.\nreboot Finally, verify you\u0026rsquo;re on the new version.\nshow version Roll back (optional) If something goes wrong, you can easily roll back the image to the older one.\nset system image default-boot Reboot to make it take effect.\nreboot Finally, verify you\u0026rsquo;re on the old¬†version.\nshow version GUI updates The v1.8.5 software has a changelog that you should read.¬†Below are the changes I made.\nFirst, I used the new option to disable all old ciphers for the web GUI.\nconfigure set service gui older-ciphers disable commit save Next, I took advantage of the SHA256 hash suite in the v1.8.5 software to generate a new web GUI certificate. This is especially important if you allow GUI access from the WAN. The old certificate was SHA1.\nStart by backing up the old certificate.\nmv /etc/lighttpd/server.pem /etc/lighttpd/server.pem_old Generate a new certificate.\ntouch /etc/lighttpd/server.pem openssl req -new -x509 -newkey rsa:2048 -keyout /etc/lighttpd/server.pem -out /etc/lighttpd/server.pem -sha256 -days 3650 -nodes -passout pass:\u0026#39;\u0026#39; -subj \u0026#34;/C=US/CN=UBNT Router UI/O=Ubiquiti Networks/ST=CA/L=San Jose\u0026#34; \u0026gt;\u0026amp;/dev/null chown root:root /etc/lighttpd/server.pem chmod 400 /etc/lighttpd/server.pem Then, restart the web server.\npgrep lighttpd | xargs kill /usr/sbin/lighttpd -f /etc/lighttpd/lighttpd.conf As it was pointed out to me, all you need to do is remove the old certificate and reboot.\nsudo su -¬†rm /etc/lighttpd/server.pem reboot Verify your certificate is SHA256.\n-Logan\n","permalink":"https://loganmarchione.github.io/2016/06/edgerouter-lite-software-upgrade/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction Ubiquiti just released the new v1.","title":"EdgeRouter Lite software upgrade"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction In my last post, I setup the Ubiquiti EdgeRouter Lite (ERL) as a basic router and firewall. Is this post, I\u0026rsquo;ll be going over the setup of an OpenVPN server. In the past, I used an Archer C7 running OpenWrt to host OpenVPN, so I\u0026rsquo;ll be applying most of those principles again here.\nVPN types If you need a refresher on the different types of VPNs, see below.\nSoftware Advantage Disadvantage PPTP Available in most operating systems by default Uses IP protocol 47 (GRE) and UDP port 1723, making it easily detectable and blockable by a firewall Encryption is not strong First on NSA's \"to-hack\" list L2TP/IPSec Available in most operating systems by default More secure than PPTP No known security flaws Uses UDP ports 50, 500, 1701, and 4500, making it easily detectable and blockable by a firewall Slightly more overhead than OpenVPN, since traffic is passing through the tunnel and encryption in two separate steps OpenVPN Very configurable Uses open source software More secure than PPTP No known security flaws Can use any port, setting to TCP 443 makes it almost indistinguishable from HTTPS traffic Not available in most operating systems by default, requires a third-party application Split-tunnel vs full-tunnel When setting up a VPN, you\u0026rsquo;ll have to choose whether to use split-tunnel or full-tunnel for the clients.\nSplit-tunnel - Allows your local client to access resources on the remote server network (e.g., network shares, file servers, email servers, etc\u0026hellip;). Regular internet traffic does not flow through¬†the tunnel and is not encrypted. Full-tunnel - Allows your local client to access resources on the remote server network (e.g., network shares, file servers, email servers, etc\u0026hellip;). Regular internet traffic does¬†flow through¬†the tunnel and is encrypted. However, this might cut your client off from local resources. Typically, clients will have to connect/disconnect based on which group of resources they want to access (local or remote). I usually choose to go full-tunnel, since I\u0026rsquo;m usually trying to get access to resources at home and I\u0026rsquo;m not concerned about local resources. This is easy enough to change on each client by adding or removing one option.\nHardware acceleration A big advantage of the ERL is that it allows you to offload some functions to hardware. One of these is the IPSec VPN, which greatly improves the throughput. Expect to get about 10Mbps (with one CPU at 100%) while using OpenVPN, and expect up to¬†150Mbps while using IPSec/L2TP with hardware offload enabled.\nI\u0026rsquo;m choosing to use OpenVPN because it\u0026rsquo;s what I\u0026rsquo;m more familiar with. If the performance is really bad, I\u0026rsquo;ll switch to IPSec/L2TP.\nOpenVPN security By default, OpenVPN developers tend to favor compatibility and speed over security. That\u0026rsquo;s not necessarily a bad thing, but in this case, I\u0026rsquo;m going to be changing a few default options. OpenVPN defaults to the following:\ncipher - Blowfish in Cipher Block Chaining mode (BF-CBC) authentication digest - SHA1 OpenVPN themselves recommend AES-256 for more security. In addition, SHA1 is outdated, and shouldn\u0026rsquo;t be used if SHA2 is available. I\u0026rsquo;m going to be using the following:\ncipher - AES-256-CBC authentication digest - SHA256 For more security reading, check out the resources here, here, and here.\nOpenVPN setup We\u0026rsquo;re basically going to create our own Certificate Authority (CA) on the router and use it to sign certificates for authentication. This isn\u0026rsquo;t best-practice, since the CA should be on its own machine, but it will do for this situation.\nCreate CA First, you\u0026rsquo;ll need to become root.\nsudo su - Next, move into the necessary directory and create a new CA certificate.\ncd /usr/lib/ssl/misc/ ./CA.sh -newca Once this completes, you\u0026rsquo;ll have a new directory called demoCA. The two most important files in here are as follows:\nprivate/cakey.pem - This is the private key for your CA (keep this secret) cacert.pem - This the public key for your CA (you\u0026rsquo;ll be giving this out to your clients) Create server certificate Next, we\u0026rsquo;ll generate a public/private key for the server. The Common Name (CN) of your server certificate should be something unique (I used my dynamic DNS name).\n./CA.sh -newreq Once this completes, you\u0026rsquo;ll have two new files,¬†as follows:\nnewkey.pem -¬†This is the private key for your server (keep this secret) newreq.pem -¬†This is the unsigned public key of the server (this needs to be signed by your CA) Now, sign the request.\n./CA.sh -sign You\u0026rsquo;ll have one more file, shown below.\nnewcert.pem -¬†This is the public¬†key for your server Move files I recommend moving the important files to a directory where they won\u0026rsquo;t be wiped out during a firmware upgrade. In addition to moving the files, we\u0026rsquo;re also renaming them.\ncp /usr/lib/ssl/misc/demoCA/cacert.pem /config/auth/ cp /usr/lib/ssl/misc/demoCA/private/cakey.pem /config/auth/ mv /usr/lib/ssl/misc/newcert.pem /config/auth/host.pem mv /usr/lib/ssl/misc/newkey.pem /config/auth/host.key DH parameters Next, generate Diffie-Hellman (DH) parameters to ensure Perfect Forward Secrecy (PFS). Expect this to take 5-10 minutes with one CPU at 100%.\nopenssl dhparam -out /config/auth/dh2048.pem -2 2048 A good explanation of DH parameters and why you need them is located here.\nCreate user certificate(s) Next, generate a request and sign it for a new user certificate. The Common Name (CN) of your user certificate¬†should be something unique (I used my¬†client\u0026rsquo;s host¬†name).\n./CA.sh -newreq ./CA.sh -sign Move the new files into your preserved directory while renaming them.\nmv newcert.pem /config/auth/client1.pem mv newkey.pem /config/auth/client1.key Repeat this as necessary for each client.\nDecrypt keys You\u0026rsquo;ll need¬†to remove the password from the host and client(s) keys so that OpenVPN can run in interactive mode.\nopenssl rsa -in /config/auth/host.key -out /config/auth/host-decrypted.key openssl rsa -in /config/auth/client1.key -out /config/auth/client1-decrypted.key Repeat this as necessary for each client(s).\nEdgeRouter setup First, I would recommend exiting back to the normal ubnt user.\nexit whoami The following steps were pretty straight-forward, since I\u0026rsquo;ve already setup an OpenVPN server on my Archer C7.\nCreate interface Now, we\u0026rsquo;ll need to create a new interface for the VPN and set a few settings.\nconfigure set interfaces openvpn vtun0 set interfaces openvpn vtun0 description \u0026#34;OpenVPN server\u0026#34; set interfaces openvpn vtun0 mode server set interfaces openvpn vtun0 encryption aes256 set interfaces openvpn vtun0 hash sha256 set interfaces openvpn vtun0 server subnet 10.10.10.0/24 set interfaces openvpn vtun0 server push-route 10.10.2.0/24 set interfaces openvpn vtun0 server name-server 10.10.2.1 set interfaces openvpn vtun0 tls ca-cert-file /config/auth/cacert.pem set interfaces openvpn vtun0 tls cert-file /config/auth/host.pem set interfaces openvpn vtun0 tls key-file /config/auth/host-decrypted.key set interfaces openvpn vtun0 tls dh-file /config/auth/dh2048.pem set interfaces openvpn vtun0 openvpn-option \u0026#34;--port 1194\u0026#34; set interfaces openvpn vtun0 openvpn-option --tls-server set interfaces openvpn vtun0 openvpn-option \u0026#34;--comp-lzo yes\u0026#34; set interfaces openvpn vtun0 openvpn-option --persist-key set interfaces openvpn vtun0 openvpn-option --persist-tun set interfaces openvpn vtun0 openvpn-option \u0026#34;--keepalive 10 120\u0026#34; set interfaces openvpn vtun0 openvpn-option \u0026#34;--user nobody\u0026#34; set interfaces openvpn vtun0 openvpn-option \u0026#34;--group nogroup\u0026#34; commit save A few notes on these settings:\nThe VPN subnet can\u0026rsquo;t be the same as your LAN subnet. In my case, my VPN subnet is 10.10.10.0/24 and my LAN subnet is 10.10.2.0/24. You\u0026rsquo;ll need to push a route from the VPN subnet to your LAN subnet. You\u0026rsquo;ll need to set a name server for the VPN subnet (I\u0026rsquo;m using my router, but you can use a public DNS server). The standard OpenVPN port is 1194, but setting it to 443 would make it almost¬†indistinguishable from HTTPS traffic ;-) The rest of the settings are explained in the OpenVPN manuals. Setup firewall We\u0026rsquo;ll need to open a port in the firewall for OpenVPN. If you\u0026rsquo;re not using the standard port (1194), change it appropriately.\nconfigure set firewall name WAN_LOCAL rule 50 action accept set firewall name WAN_LOCAL rule 50 description \u0026#34;OpenVPN\u0026#34; set firewall name WAN_LOCAL rule 50 destination port 1194 set firewall name WAN_LOCAL rule 50 log enable set firewall name WAN_LOCAL rule 50 protocol udp commit save Set DNS Tell DNS to listen for requests on the new vtun0 interface.\nconfigure set service dns forwarding listen-on vtun0 commit save Setup client configuration The client configuration will vary from client-to-client, but the configuration below should work for Android phones or Linux clients. If you\u0026rsquo;re using Windows, you\u0026rsquo;re going to have a tougher time, because it needs some extra options.\necho \u0026#34;client\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;dev tun\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;proto udp\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;remote yourhostname.dyndns.com¬†1194\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;cipher AES-256-CBC\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;auth SHA256\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;resolv-retry infinite\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;redirect-gateway def1\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;nobind\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;comp-lzo yes\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;persist-key\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;persist-tun\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;user nobody\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;group nogroup\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;verb 3\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;ca cacert.pem\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;cert client1.pem\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn echo \u0026#34;key client1-decrypted.key\u0026#34; \u0026gt;\u0026gt; /config/auth/client1.ovpn A few notes on these settings:\nObviously, subsititue your dynamic DNS hostname and port as needed. To use full-tunnel, include the option¬†redirect-gateway def1. To use split tunnel, leave it out. The rest of the settings are explained in the OpenVPN manuals. Distribute keys You‚Äôll need to move the following files from the router, to your client(s). All four files should be saved in the same folder/location on your client.\ncacert.pem (CA certificate) client1.pem (client1 certificate) client1-decrypted.key (client1 key) client1.ovpn (client1 configuration) You should¬†use SFTP, SSH, or SCP to move the files to your client(s). DO NOT EMAIL THESE FILES TO YOURSELF!\nClient setup Android In this case, I\u0026rsquo;m going to be using the official OpenVPN Android app.\nOnce installed, tap on the Option button, then tap on Import, then tap on Import Profile from SD Card.\nBrowse to the client1.ovpn file and import it into the OpenVPN Connect app.\nThe profile should be imported successfully, and you should be able to see your server\u0026rsquo;s name. Click Connect to establish a connection.\nVerify your connection on the next screen.\niOS In this case, I\u0026rsquo;m going to be using the official OpenVPN iOS app.\nYou should use iTunes to move the files to your iOS device, since emailing them is not secure. An example of how to transfer files with iTunes is shown here.\nWindows 10 If you\u0026rsquo;re using a Windows client, check out Randy\u0026rsquo;s .ovpn file in the comments!\nCommenter Chris was nice enough to email me a configuration for Windows 10, shown below. For certificate/key generation he used this guide instead of the built-in scripts.\nServer ‚Äãxxxxx@‚Äãxxxxx# show interfaces openvpn vtun0 description \u0026#34;OpenVPN Server\u0026#34; encryption aes256 hash sha256 mode server openvpn-option \u0026#34;--port ‚Äãxxxx\u0026#34; openvpn-option --tls-server openvpn-option \u0026#34;--comp-lzo yes\u0026#34; openvpn-option --persist-key openvpn-option --persist-tun openvpn-option \u0026#34;--keepalive 10 120\u0026#34; openvpn-option \u0026#34;--user nobody\u0026#34; openvpn-option \u0026#34;--group nogroup\u0026#34; openvpn-option \u0026#34;--tls-auth /config/auth/ta.key 0\u0026#34; openvpn-option \u0026#34;--tls-cipher TLS-DHE-RSA-WITH-AES-256-CBC-SHA\u0026#34; server { name-server 10.10.0.1 push-route 10.10.0.0/24 push-route 0.0.0.0/0 subnet 10.10.10.0/24 } tls { ca-cert-file /config/auth/ca-chain.cert.pem cert-file /config/auth/openvpn.host.cert.pem dh-file /config/auth/dh2048.pem key-file /config/auth/openvpn.host.key.pem }‚Äã Client (Win10) pull tls-client dev tun proto udp remote ‚Äãxxx.xxx.xxx.xxx ‚Äãxxxx cipher AES-256-CBC tls-cipher TLS-DHE-RSA-WITH-AES-256-CBC-SHA auth SHA256 resolv-retry infinite redirect-gateway def1 nobind comp-lzo yes persist-key persist-tun verb 3 ca ca-chain.cert.pem cert openvpn.client01.cert.pem key openvpn.client01.key.pem tls-auth ta.key 1‚Äã Verify connection Try to browse a public site (e.g., www.google.com), then try to browse to your router\u0026rsquo;s IP (e.g., 10.10.2.1). If everything is setup correctly, both should load. You can also check your IP with an external tool, such as WhatIsMyIP, and you should see your router\u0026rsquo;s public IP. I\u0026rsquo;d also advise to check for DNS leaks (your DNS should be set to the DNS servers we set on the router).\nSpeedtest On a Nexus 5 on AT\u0026amp;T LTE, I get 25.61Mbps down, and 23.37Mbps up.\nWhen connected to the VPN while on the same LTE, I get 11.52Mbps down and 5.35Mbps up. Not great, but certainly not bad.\nBackup CA Thanks to commenter Axel for pointing this out. You should backup the entire /usr/lib/ssl/misc directory because it is wiped on a firmware upgrade, and you won\u0026rsquo;t be able to create any new certificates without creating a new CA from scratch.\ncp -r /usr/lib/ssl/misc /config/ Then, after an upgrade, you can restore the misc directory from /config back to /usr/lib/ssl.\nLet me know how you setup OpenVPN!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2016/05/edgerouter-lite-openvpn-setup/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction In my last post, I setup the Ubiquiti EdgeRouter Lite (ERL) as a basic router and firewall.","title":"EdgeRouter Lite OpenVPN setup"},{"content":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction As much as I love my C7 running OpenWrt, I\u0026rsquo;ve been hearing a lot of good things about Ubiquiti devices. In particular, the¬†EdgeRouter Lite, which is touted as being the world\u0026rsquo;s first router under $100 capable of passing one million packets per second (1Mpps). In contrast, I\u0026rsquo;ve read that the TP-Link WDR-3600 can pass about 25Kpps. This is partly due to the hardware in the WDR-3600, and partly due to the software (OpenWrt). I wanted to try out the EdgeRouter Lite (ERL) and see how it performed.\nCurrently, my setup looks like the diagram below.\nI plan on putting the ERL in front of the C7, and using the C7 as a switch and AP only (as shown below). Eventually, I\u0026rsquo;ll replace the C7 with a proper switch and AP.\nAlso, I\u0026rsquo;m not a network engineer.¬†Do this at your own risk, I\u0026rsquo;m not responsible for anything you break. üôÉ\nHardware The ERL packs a dual-core 500MHz MIPS64 processor, 512MB DDR2 RAM, and 2GB of flash storage. In addition, it also supports¬†hardware offload for the functions below.¬†This means that the CPU can offload these tasks to a special chip, freeing up the CPU and greatly improving throughput.\nIPSec IPv4 forwarding IPv4 vlan IPv4 PPPoE IPv4 GRE IPv4 export IPv4 DPI IPv6 forwarding IPv6 vlan IPv6 PPPoE For this guide, I am configuring the ERL through the ethX ports over SSH, not via the console port. Because of this, I end up doing a good bit of connecting/disconnecting from my ERL. If you\u0026rsquo;d like to avoid this problem, pickup a console cable and adapter (or this combo cable).\nMy setup is going to use eth0 to connect to my WAN, and eth1 for my LAN.¬†You could use eth2 for another LAN if needed. However, do not bridge the two LANs, as that will disable the hardware offload (see here and here). If you need more ports, you\u0026rsquo;ll need a separate switch.\nNote -¬†The original ERL (with angled corners) had storage issues and was¬†prone¬†to failure, the newer¬†ERL (with square corners) does not suffer from this issue.\nSoftware EdgeOS is based on Vyatta Core 6.3, which is itself based on Debian.¬†As a side-note, VyOS is also a fork of Vyatta, so most principles from VyOS will apply to EdgeOS as well. The EdgeOS command line (CLI) can be accessed one of three ways: SSH via an ethX port, a console port, or through the web interface. The CLI has two modes: operational¬†mode and configuration mode (similar to vi\u0026rsquo;s normal and insert modes). By default, you are loaded into operational mode, used to show system settings. Operational mode is indicated by a dollar-sign prompt ($).\nubnt@ubnt:~$ Use the configure command to enter configuration mode, which is used to make configuration changes to the ERL. Configuration mode is indicated by a number sign prompt (#) and the word edit.\nubnt@ubnt:~$ configure [edit] ubnt@ubnt# The CLI¬†has context-sensitive tab completion only for commands, not for browsing around the filesystem. In addition, context-sensitive help is available with the ? command, with detailed help available with the ?? command.\nWhen making changes, they are not active until committed. To see what changes you\u0026rsquo;ve made, but not commited, use the compare command.\ncompare To undo uncommitted changes, use the discard command.\ndiscard To commit changes,¬†use the commit command.\ncommit Committed¬†changes are not persistent across reboots. Use the save command to write the changes to the plain-text configuration file, which is available at¬†/config/config.boot. Note - using ?¬†reveals that save can also save the configuration to a SCP, FTP, or TFTP location.\nsave To get back to operational mode, use exit.\nexit As far documentation is concerned,¬†Ubiquiti\u0026rsquo;s documentation is pretty poor, but their forums and Reddit are the best places to get help. The old Vyatta Core 6.3 documents are very helpful as well. In addition, two important primers to have¬†on-hand are the ERL quick-start guide and the EdgeOS user guide.\nInitial setup Firmware update Before we connect to the router for the first time and start making changes, I recommend you download¬†the latest firmware.¬†Go to Ubiquiti\u0026rsquo;s download page¬†for the ERL and download the latest firmware (v1.8.0 at the time of this writing).\nNext, connect your PC to eth0¬†of the ERL with an ethernet cable, then give your PC a static IP address in the 192.168.1.x range (e.g., 192.168.1.2). The web GUI¬†is available at https://192.168.1.1, but I\u0026rsquo;ll be trying to do most of my work through the CLI.\nFirst, transfer the firmware file to the ERL¬†(the default credentials are ubnt/ubnt).\nscp ER-e100.v1.8.0.4853089.tar ubnt@192.168.1.1:~ Next, SSH into the ERL.\nssh ubnt@192.168.1.1 I recommend viewing the current version of the firmware (my ERL shipped with v1.2.0).\nshow version Upload the system image.\nadd system image ~/ER-e100.v1.8.0.4853089.tar Use the command below to show all the installed images.\nshow system image You\u0026rsquo;ll then need to reboot to make the new image take effect.\nreboot Once you\u0026rsquo;re back up, use the command below to show the installed images (EdgeOS can store two images, should you need to revert). At this point, you should be booted into the latest image.\nshow system image Just to be sure, verify the version you\u0026rsquo;re running.\nshow version Optional - If you\u0026rsquo;re running low on space, you can use the two commands below to view image storage and delete the unused image.\nshow system image storage delete system image Set the hostname Now that our firmware is updated, we can start making changes. I\u0026rsquo;m starting by changing the hostname.\nconfigure set system host-name \u0026lt;name\u0026gt; commit save Note - Notice that I\u0026rsquo;m using configure to enter configuration mode, making my changes, then running commit and save. After that, you\u0026rsquo;ll need to type exit¬†if you want to get back to operational¬†mode.\nChange timezone The list of available time zones is available by navigating the files and directories under /usr/share/zoneinfo, should you need to update it.\nconfigure set system time-zone US/Eastern commit save NTP The ERL does not have a hardware clock, so it depends on NTP to synchronize time. You can verify the NTP settings below.\nconfigure show system ntp The ERL will use a pool¬†of Ubiquiti NTP servers¬†by default.\nSetup interfaces First, configure the WAN interface on eth0. My provider (Verizon FiOS) distributes addresses via DHCP (as I imagine most fiber/cable providers in the US do), so my WAN interface will use DHCP.\nconfigure delete interfaces ethernet eth0 address 192.168.1.1/24 set interfaces ethernet eth0 address dhcp set interfaces ethernet eth0 description \u0026#34;WAN\u0026#34; set interfaces ethernet eth0 duplex auto set interfaces ethernet eth0 speed auto Next, configure the LAN interface on eth1. I\u0026rsquo;m using the 10.10.2.x IP range, specified in CIDR notation. I\u0026rsquo;m not a network engineer, so use a calculator to determine what you need (hint - /24 will provide 254 usable IP addresses).\nset interfaces ethernet eth1 address 10.10.2.1/24 set interfaces ethernet eth1 description \u0026#34;LAN\u0026#34; set interfaces ethernet eth1 duplex auto set interfaces ethernet eth1 speed auto commit At this point, when you type commit, your SSH session will hang, since we just set eth0 to be a DHCP client. Change your PC\u0026rsquo;s static IP address to something in the 10.10.2.x range (e.g., 10.10.2.2), then move your ethernet cable over to eth1. SSH back into the ERL, and make sure you commit and save the changes you just made. This is where that console cable would come in handy\u0026hellip;\nconfigure commit save Now, we need to setup a DHCP server on¬†eth1. Pick a start and stop range, specify the router IP, DNS server, and lease time.\nconfigure set service dhcp-server disabled false set service dhcp-server shared-network-name LAN authoritative enable set service dhcp-server shared-network-name LAN subnet 10.10.2.0/24¬†start 10.10.2.100 stop¬†10.10.2.199 set service dhcp-server shared-network-name LAN subnet 10.10.2.0/24¬†default-router¬†10.10.2.1 set service dhcp-server shared-network-name LAN subnet 10.10.2.0/24¬†dns-server¬†10.10.2.1 set service dhcp-server shared-network-name LAN subnet 10.10.2.0/24¬†lease 86400 Here, we\u0026rsquo;ll tell DNS which interface to listen on and set a cache size. Then, we\u0026rsquo;ll tell¬†DNSMasq to use the router itself (127.0.0.1) for DNS, and then forward DNS requests to my specified DNS servers (I\u0026rsquo;m using OpenNIC DNS servers). The options I\u0026rsquo;m using are standard DNSMasq options.\nset service dns forwarding listen-on eth1 set service dns forwarding cache-size 400 set system name-server 127.0.0.1 set service dns forwarding name-server 50.116.40.226 set service dns forwarding name-server 107.170.95.180 set service dns forwarding options domain-needed set service dns forwarding options bogus-priv set service dns forwarding options all-servers I\u0026rsquo;m¬†also telling eth0 not to request DNS servers via DHCP, as per this post, because I want to use only OpenNIC servers.\nset interfaces ethernet eth0 dhcp-options name-server no-update commit save Now, change your PC\u0026rsquo;s static IP back to DHCP, disconnect from eth1, and reconnect to it. You should be getting an IP in the range you specified above. You can test your DNS servers here.\nSetup firewall At this point, our ERL can route, but we don\u0026rsquo;t have a firewall. To setup these rules, think of this from the router\u0026rsquo;s perspective. At a minimum, you need two sets of firewall rules: one for traffic coming from the internet destined for the LAN, and one for traffic coming from the internet destined for the ERL itself. If you\u0026rsquo;re more of a visual person, this is a great way to visualize these firewall rules.\nWe\u0026rsquo;ll start by setting some global options.\nconfigure set firewall all-ping enable set firewall broadcast-ping disable set firewall receive-redirects disable set firewall ipv6-receive-redirects disable set firewall ip-src-route disable set firewall ipv6-src-route disable set firewall log-martians enable Now, create a firewall to protect the¬†LAN. We\u0026rsquo;re saying the default action is to drop anything coming into our LAN, with the exception of already established sessions. In addition, we drop anything with an invalid state.\nset firewall name WAN_IN default-action drop set firewall name WAN_IN description \u0026#34;WAN to internal\u0026#34; set firewall name WAN_IN enable-default-log set firewall name WAN_IN rule 10 action accept set firewall name WAN_IN rule 10 description \u0026#34;Allow established/related\u0026#34; set firewall name WAN_IN rule 10 state established enable set firewall name WAN_IN rule 10 state related enable set firewall name WAN_IN rule 20 action drop set firewall name WAN_IN rule 20 description \u0026#34;Drop invalid state\u0026#34; set firewall name WAN_IN rule 20 state invalid enable set firewall name WAN_IN rule 20 log enable Then, a firewall to protect the ERL¬†itself. Again,¬†We\u0026rsquo;re saying the default action is to drop anything coming into our ERL, with the exception of already established sessions. We drop anything with an invalid state, and we also limit pings.\nset firewall name WAN_LOCAL default-action drop set firewall name WAN_LOCAL description \u0026#34;WAN to router\u0026#34; set firewall name WAN_LOCAL enable-default-log set firewall name WAN_LOCAL rule 10 action accept set firewall name WAN_LOCAL rule 10 description \u0026#34;Allow established/related\u0026#34; set firewall name WAN_LOCAL rule 10 state established enable set firewall name WAN_LOCAL rule 10 state related enable set firewall name WAN_LOCAL rule 20 action drop set firewall name WAN_LOCAL rule 20 description \u0026#34;Drop invalid state\u0026#34; set firewall name WAN_LOCAL rule 20 state invalid enable set firewall name WAN_LOCAL rule 20 log enable set firewall name WAN_LOCAL rule 30 action accept set firewall name WAN_LOCAL rule 30 description \u0026#34;Limit pings\u0026#34; set firewall name WAN_LOCAL rule 30 limit burst 1 set firewall name WAN_LOCAL rule 30 limit rate 50/minute set firewall name WAN_LOCAL rule 30 log enable set firewall name WAN_LOCAL rule 30 protocol icmp Now, enable the firewall by applying it to our eth0 interface.\nset interfaces ethernet eth0 firewall in name WAN_IN set interfaces ethernet eth0 firewall local name WAN_LOCAL commit save Setup NAT Because of NAT, one external IP can map to many internal IPs. This allowed the extension of the use of IPv4, even though we were quickly running out of addresses. The rule below will change (masquerade) all traffic going out of eth0 to have its source address changed to the public address of eth0 (instead of staying at 10.10.2.x, where it would never get a return).\nconfigure set service nat rule 5000 description \u0026#34;Masquerade for WAN\u0026#34; set service nat rule 5000 outbound-interface eth0 set service nat rule 5000 type masquerade commit save That\u0026rsquo;s it! Technically, you should be able to get online with this configuration and be pretty safe!\nOptional setup Verify hardware offload Verify hardware offload is working for the services you need.\nshow ubnt offload Change password I highly recommend changing the password of the default ubnt user (even if you disable password authentication via SSH).\nconfigure set system login user ubnt¬†authentication plaintext-password \u0026lt;password_here\u0026gt; commit save Ubiquiti also recommends creating a new user and removing the default¬†ubnt user. I\u0026rsquo;m not going to cover that, but see this document for more details.\nSetup SSH keys I also highly recommend setting up SSH keys so you don\u0026rsquo;t need to use password authentication.¬†Start by copying the key from your PC to the ERL.\nscp ~/.ssh/id_rsa.pub ubnt@10.10.2.1:~/id_rsa.pub Then, load the key and turn off password authentication.\nconfigure loadkey ubnt¬†~/id_rsa.pub set service ssh disable-password-authentication commit save Note - If you receive the error below when trying to load a key, make sure there are no spaces in the comment section of the key.\nNot a valid key file format (see man sshd) at /opt/vyatta/sbin/vyatta-load-user-key.pl line 96, \u0026lt;$in\u0026gt; line 1. Custom SSH banners If you\u0026rsquo;d like, you can setup a SSH banner for pre-login and post-login.\nconfigure set system login banner pre-login \u0026#39;\\n\\n\\n\\tUNAUTHORIZED USE OF THIS SYSTEM\\n\\tIS STRICTLY PROHIBITED!\\n\\n\\tPlease contact Logan Marchione for access\\n\\n\\n\\n\u0026#39; set system login banner post-login \u0026#39;\\n\\n\\n\\tWelcome to EdgeRouter Lite\\n\\n\\n\\n\u0026#39; commit save Note - The string \\n is a newline, and \\t is an indent.\nChange SSH port You can argue about security through obscurity, but I\u0026rsquo;m going to change the port SSH listens on. At the very least, it\u0026rsquo;ll help protect from scanners and bots.\nconfigure set service ssh port 1234 commit save Change GUI port Again, changing this port is more security through obscurity.\nconfigure set service gui https-port 8443 commit save Change MAC I\u0026rsquo;ve been using¬†my own router with Verizon FiOS for a while, but for some reason, I can\u0026rsquo;t pull an IP from the ONT unless I\u0026rsquo;m cloning the MAC of the original Actiontec router. Until I get the time (i.e., willpower) to call Verizon, I\u0026rsquo;m going to choose to clone the MAC.\nconfigure set interfaces ethernet eth0 mac 00:00:00:00:00:00 commit save Dynamic DNS I like to connect remotely via SSH and/or VPN to my router, so I use Dyn for my dynamic DNS service.\nconfigure set service dns dynamic interface eth0 service dyndns host-name \u0026lt;hostname.dyn.com\u0026gt; set service dns dynamic interface eth0 service dyndns login \u0026lt;username\u0026gt; set service dns dynamic interface eth0 service dyndns password¬†\u0026lt;password_here\u0026gt; commit save Then, trigger a manual update.¬†EdgeOS will only update the dynamic service when your IP address actually changes.\nupdate dns dynamic interface eth0 You can show the status with the command below.\nshow dns dynamic status Remote SSH access I like to connect back to my home via SSH, and will eventually setup a VPN. To allow SSH, I\u0026rsquo;ll need to open a port¬†for SSH in the firewall.\nconfigure set firewall name WAN_LOCAL rule 40 action accept set firewall name WAN_LOCAL rule 40 description \u0026#34;Allow SSH to router\u0026#34; set firewall name WAN_LOCAL rule 40 destination port 1234 set firewall name WAN_LOCAL rule 40 log enable set firewall name WAN_LOCAL rule 40 protocol tcp commit save Remote GUI access In my case, I want remote access to SSH, but I don\u0026rsquo;t want the GUI to be open to world. This will make it so it only listens for requests from the LAN, not the WAN.\nconfigure set service gui listen-address¬†10.10.2.1 commit save Static DHCP leases I prefer to set static DHCP leases on the router, rather than configuring all my devices with a static IP. Use the syntax below to setup a static lease.\nconfigure set service dhcp-server shared-network-name LAN subnet 10.10.2.0/24 static-mapping client01 ip-address 10.10.2.10 set service dhcp-server shared-network-name LAN subnet 10.10.2.0/24 static-mapping client01 mac-address 00:00:00:00:00:00 commit save Note - It\u0026rsquo;s best practice to not use addresses inside the DHCP pool (mine is¬†10.10.2.100 -¬†10.10.2.199).\nHope this was helpful! I plan on configuring a VPN on this router in the near future.\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2016/04/ubiquiti-edgerouter-lite-setup/","summary":"Hey! Listen! This post is part of a series on the Ubiquiti EdgeRouter Lite. Check them all out!\nDate URL Part 2019-06-28 Migrating away from the Ubiquiti EdgeRouter Lite Migrated to a Netgate SG-1100 2019-02-03 EdgeRouter CNAME records Setup CNAME records 2017-10-03 Dyn DDNS on EdgeRouter Setup DynDNS 2017-04-25 DuckDNS on EdgeRouter Setup DuckDNS 2017-01-08 Ubiquiti EdgeRouter serial console settings Serial console settings 2016-11-29 Ubiquiti UniFi controller setup on Raspberry Pi 3 Install UniFi Controller 2016-08-30 EdgeRouter Lite Dnsmasq setup Setup dnsmasq 2016-06-13 EdgeRouter Lite software upgrade Firmware upgrade 2016-05-12 EdgeRouter Lite OpenVPN setup OpenVPN server setup 2016-04-29 Ubiquiti EdgeRouter Lite setup Initial setup Introduction As much as I love my C7 running OpenWrt, I\u0026rsquo;ve been hearing a lot of good things about Ubiquiti devices.","title":"Ubiquiti EdgeRouter Lite setup"},{"content":"Hey! Listen! This post is part of a series on using OpenWrt. Check them all out!\nDate URL Part 2016-04-28 OpenWrt upgrade process OpenWrt upgrade 2015-08-26 OpenWrt with OpenVPN server on TP-Link Archer C7 Initial post 2015-02-15 OpenWrt with OpenVPN client on TP-Link TL-MR3020 Initial post Introduction Typically, when a new version of OpenWrt is released, I completely wipe the router and start over. However, with the recent release of 15.05.1, I wanted to perform an in-place upgrade while preserving all of my data.\nBefore we begin, it\u0026rsquo;s important to understand how the OpenWrt upgrade process works. It\u0026rsquo;s best to quote the wiki on this one:\nBoth the LuCI and sysupgrade upgrade procedures work by saving specified configuration files, wiping the entire file system, installing the new version of OpenWrt and then restoring back the saved configuration files. This means that any parts of the file system that are not specifically saved will be lost.\nIn particular, any manually installed software packages you may have installed after the initial OpenWrt installation have to be reinstalled after an OpenWrt upgrade. That way everything will match, e.g. the updated Linux kernel and any installed kernel modules.\nAny configuration files or data files placed in locations not specifically listed as being preserved below will also be lost in an OpenWrt upgrade. Be sure to check any files you have added or customized from a default OpenWrt install to back up these items before an upgrade.\nThis is important to note because OpenWrt doesn\u0026rsquo;t automatically preserve¬†everything by default. You\u0026rsquo;ll need to tell OpenWrt which files and directories to preserve in a configuration file.\nPreparation Check your release Start by viewing the /etc/openwrt_release file to double-check the version you\u0026rsquo;re running. Here, you can see I\u0026rsquo;m on 15.05.\nDISTRIB_ID=\u0026#39;OpenWrt\u0026#39; DISTRIB_RELEASE=\u0026#39;15.05\u0026#39; DISTRIB_REVISION=\u0026#39;r46767\u0026#39; DISTRIB_CODENAME=\u0026#39;chaos_calmer\u0026#39; DISTRIB_TARGET=\u0026#39;ar71xx/generic\u0026#39; DISTRIB_DESCRIPTION=\u0026#39;OpenWrt Chaos Calmer 15.05\u0026#39; DISTRIB_TAINTS=\u0026#39;\u0026#39; Backup I would highly recommend you make a backup of any necessary configuration files. Also, it\u0026rsquo;s important to test your backups before you need them! üôÉ\nPreservation Next, you\u0026rsquo;ll need to determine what files will be preserved through the upgrade by using the command below.\nopkg list-changed-conffiles If a file or directory is not in this list, it will not be preserved through the upgrade.\nOpenWrt will preserve any files or directories listed in¬†/lib/upgrade/keep.d/ (e.g.,¬†/lib/upgrade/keep.d/keep.me) or¬†/etc/sysupgrade.conf.¬†The easiest thing to do is list your needed files or directories in¬†/etc/sysupgrade.conf. My file is shown below.\n## This file contains files and directories that should ## be preserved during an upgrade. /etc/config/ /etc/crontabs/ /etc/uhttpd.crt /etc/uhttpd.key /etc/rc.local You can see that I\u0026rsquo;m choosing to preserve the entire /etc/config directory, as well as all my crontabs, the certificate and key for LuCI, and my startup file.\nUpgrade I recommend using the sysupgrade utility, since it\u0026rsquo;s tailor-made for this process.\nStart by downloading the new firmware. For upgrades, always use the firmware that ends in¬†sysupgrade.bin, not the factory.bin firmware. In my case, I\u0026rsquo;m using a TP-Link Archer C7 v2¬†going from 15.05 to 15.05.1, so I\u0026rsquo;ll be using this file.¬†Keep in mind, you\u0026rsquo;ll need enough space in RAM¬†to download the files.\ncd /tmp wget https://downloads.openwrt.org/chaos_calmer/15.05.1/ar71xx/generic/openwrt-15.05.1-ar71xx-generic-archer-c7-v2-squashfs-sysupgrade.bin Next, I highly recommend checking the MD5 sum to make sure the file isn\u0026rsquo;t corrupt.\ncd /tmp wget¬†https://downloads.openwrt.org/chaos_calmer/15.05.1/ar71xx/generic/md5sums md5sum -c md5sums 2\u0026gt; /dev/null | grep OK If the MD5 sum returns OK, you can proceed with the upgrade (the -v flag tells sysupgrade to be verbose.).\nsysupgrade -v /tmp/openwrt-15.05.1-ar71xx-generic-archer-c7-v2-squashfs-sysupgrade.bin Expect the upgrade to take a few minutes. The router should reboot when completed.\nVerification Verify you can SSH into your router (assuming you chose to preserve the correct configuration files), then view the /etc/openwrt_release file to check the new version you\u0026rsquo;re running.\nDISTRIB_ID=\u0026#39;OpenWrt\u0026#39; DISTRIB_RELEASE=\u0026#39;15.05.1\u0026#39; DISTRIB_REVISION=\u0026#39;r48532\u0026#39; DISTRIB_CODENAME=\u0026#39;chaos_calmer\u0026#39; DISTRIB_TARGET=\u0026#39;ar71xx/generic\u0026#39; DISTRIB_DESCRIPTION=\u0026#39;OpenWrt Chaos Calmer 15.05.1\u0026#39; DISTRIB_TAINTS=\u0026#39;\u0026#39; Now, you\u0026rsquo;ll need to re-download all your previously installed packages (this is where that backup list comes in handy).\nopkg update opkg list-upgradable opkg install package1 package2 package3 I had to re-enable LuCI, you probably will too.\n/etc/init.d/uhttpd start /etc/init.d/uhttpd enable In addition, you\u0026rsquo;ll need to disable any unneeded services again.\n/etc/init.d/telnet stop /etc/init.d/telnet disable Let me know how your upgrade went!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2016/04/openwrt-upgrade-process/","summary":"Hey! Listen! This post is part of a series on using OpenWrt. Check them all out!\nDate URL Part 2016-04-28 OpenWrt upgrade process OpenWrt upgrade 2015-08-26 OpenWrt with OpenVPN server on TP-Link Archer C7 Initial post 2015-02-15 OpenWrt with OpenVPN client on TP-Link TL-MR3020 Initial post Introduction Typically, when a new version of OpenWrt is released, I completely wipe the router and start over. However, with the recent release of 15.","title":"OpenWrt upgrade process"},{"content":"Introduction Put on your tinfoil hats, boys and girls! Today, we\u0026rsquo;re talking about security, encryption, and GPG!\nPGP vs OpenPGP vs GPG PGP Pretty Good Privacy (PGP) was a program created to encrypt/decrypt data in 1991 by Phil Zimmermann. Zimmermann formed PGP Incorporated, which was acquired serveral times and is now owned by Symantec.\nFun fact - in 1993 the US government charged Zimmerman with¬†\u0026ldquo;munitions export without a license\u0026rdquo;. At the time, cryptography systems with keys over 40 bits were considered a weapon, and since PGP used 128 bit keys, Zimmerman was in violation of the law. However, Zimmerman was able to circumvent this by publishing the entire source code of PGP in a physical book (that could be scanned with OCR and recompiled into source code), since the export of books was protected by the First Amendment. Today, PGP is no longer considered a weapon, but still cannot be exported to a specific list of individuals/countries.\nOpenPGP Because of PGP\u0026rsquo;s importance, Zimmermann decided that an open standard needed to be created so that others could write/use code that would interact with PGP. In 1997, Zimmermann proposed to the Internet Engineering Task Force (IEFT) the standard called OpenPGP. The current standard is RFC 4880. Today, any programs that use the OpenPGP standard (like PGP and GPG) will be cross-compatible.\nGPG GNU Privacy Guard (GnuPG or GPG), now part the GNU Project, was created by Werner Koch in 1997. It was designed to be an open source, OpenPGP compatible version of PGP. GPG became the de facto standard encryption software, powering almost all of the underlying encryption software that world and web depended on. However, since its creation, it has been maintained almost single-handedly by Koch, who relied only on donations and limited funding from the German government. In fact, Koch only earned an average of about $25k per year working full time on GPG, all while supporting a wife and daughter. In February 2015, ProPublica published an article outlining Koch\u0026rsquo;s labor of love with GPG. After the article went viral, Koch received over $137k in donations from users, $60k from the Linux Foundation, and recurring donations of $50k per year from both Facebook and Stripe. With the money, Koch was able to hire a full-time developer and continue work on GPG.\nPublic vs private keys This is a very quick lesson in public key cryptography, which is used by PGP and GPG. You first generate a public and private key using a program on your computer. These keys are mathematically related, but you cannot derive one from the other. You should make your public key public (anyone can see it), but keep your private key private (only you can see it).\nYou can encrypt a message¬†with either key, then decrypt it with the other.¬†The choice of which to use depends on the scenario, as seen below.\nEncryption If you want to send an encrypted message¬†to someone, you would encrypt it using their public key. When they receive the message, it can only be decrypted by their private key.\nIn the example below, you can see that in order for Alice to receive a message from Bob, Bob must encrypt it using Alice\u0026rsquo;s public key. Then, only Alice can decrypt it, since she is the only one with access to her private key.\nVerification/digital signature If someone wants to verify a message is coming from you, and hasn\u0026rsquo;t been tampered with, encrypt a message with your private key.\nWhen they receive the message, it can only be decrypted by your public key. This proves you are who you say you are and that the message hasn\u0026rsquo;t been tampered with.\nNote - In the image above, the outcome of \u0026ldquo;Exact Match?\u0026rdquo; for \u0026ldquo;Yes\u0026rdquo; should not read invalid. Thanks to commenter XiaoKe for pointing that out!\nInstall GPG There are three main branches of GPG:\nClassic - Currently on version 1.4. It is usually built on older Unix systems, has almost no dependencies, but is very limited in features. Stable - Currently on version 2.0. It is modular, and supports OpenPGP, S/MIME, and SSH. Modern - Currently on version 2.1. It is the newest version, supports elliptic-curve cryptography, and will eventually replace the Stable branch. In Arch Linux, you can install GPG with the command below.\nsudo pacman -S gnupg The gnupg package will also install pinentry, a collection of simple PIN or passphrase entry dialog boxes which GPG uses.\nNote - In Arch Linux, the executable can be called from the command line with¬†gpg, but some distributions will require you to use gpg2 instead.\nImportant! You can replace your-key-id in this document with your short key ID, long key ID, fingerprint, or email address. GPG is pretty flexible in allowing this, and I usually use my email for this option.\nYou may also see --armor¬†in various GPG commands. Normally, GPG output is binary and can be corrupted by other programs (e.g., email clients, word processors, etc..). To circumvent this, you can use --armor to create¬†ASCII-armor encrypted output that can be safely used by other programs.\nGenerate a key pair Using GPG, generate a key using the command below.\ngpg --gen-key Alternately, you can use the extended version of --gen-key, which uses a wizard to guide you through the process, offering non-standard options. This is the option I\u0026rsquo;ll be using.\ngpg --full-gen-key First, select what type of key you want. Typically, you\u0026rsquo;ll want option 1 (RSA and RSA).\nSecond, specify the key size. The default is 2048 bits, but I\u0026rsquo;m going to specify 4096 bits. There is some discussion about whether¬†anything larger than 2048 bits is more secure.\nThird, choose an expiration date. I\u0026rsquo;m going to choose a key that does not expire.\nNow, GPG will construct your identity. Enter your full name, email address, and a comment (optional). Verify your information, then create a password to protect your keys. It goes without saying, but PROTECT THIS PASSWORD AND KEYFILES!\nGenerate a revocation certificate I highly recommend you generate an revocation certificate. This is used in the event that your key is lost, stolen, or somehow compromised. This should¬†be done in advance, do not wait until after your key has been compromised.\ngpg --gen-revoke --output=RevocationCertificate.asc your-key-id This key should be protected as well as your GPG keys, since anyone who has access to key can essentially render your key obsolete (then impersonate you with a new key). Some users recommend printing this key as a backup fail-safe, since it is relatively short, and can be manually retyped if needed.\nGenerating a key fingerprint A key fingerprint is a 40 character, SHA-1 hashed version of your key. This is used to quickly verify a key, since it\u0026rsquo;s quicker than checking the entire key (which could be thousands of characters long). You can find your¬†key fingerprint with the command below.\ngpg --fingerprint your-key-id Using a key fingerprint Having a key fingerprint doesn\u0026rsquo;t mean anything by itself, but it does help to identify yourself. For example,¬†I can publish my public key and fingerprint on this blog, but how can you trust that its really my key? You may know me personally, you may have watched me publish it, but what if you don\u0026rsquo;t?\nTake the following scenario as an example. You¬†could import my public key¬†(from a keyserver or a file), generate a fingerprint of that key, then either call/email/IM/meet me and have me read back my¬†fingerprint, generated from my private key. If the fingerprint you generated is the same as the fingerprint I\u0026rsquo;m¬†reading you, then you can at least assume I have¬†control of the key (whether or not I¬†acquired it genuinely is yet to be determined).\nExport¬†your public key A public key is no good if no one knows about it. You should try to publish your public key and fingerprint anywhere possible, including a domain/site you control (blog, Facebook, Twitter etc\u0026hellip;).\nManually Use the command below to export your public key.\ngpg --armor --export your-key-id When published, your key should look something like this (below is my public key). The --BEGIN-- and --END-- stanzas are part of the key, do not forget them!\n-----BEGIN PGP PUBLIC KEY BLOCK----- Version: GnuPG v2 mQINBFaDTpoBEACsRFbwH6qQGfpScwGjf5K5pK6Wbp4w+lK0GZBfWDc3jN4DqhhE pPUITT7zv5qazJEqZL17QM5ZgYxwuC5DYqrdOxUrM8H0n01OqaxP60ajE8DPjt5r dSS9o8M7WyEWn7hW28+POkPKY4+R/8A1DiH8dHYeHvx6S7LlETNDgyi0UmRA8gCL Dsbywd9cCX3wNTNBH2/dlUuHL33TlQZ5EQdER6rb8o1QtBaHieApFbcsGBQpNJ2x 7tDhheLCO0ybW2HrllW9oqvSU9EiiAlaEQG3NvVo31fEWyT9Rj4Lucdsp8yWinJj j3RiWxCRtXITE5DkBPNd8MbPaAmF2x3nOsTNjaCHuajfC5p6XfX+9fhyqLmihwpt B8cGh3Et8QQov7mfG44rp2jf9i1Ba0Ghgc6yRrCx2+0fRiajD1kUVt0LcrEVIHL1 5/IJuVs3L6VfjWOtkEcBUNEvTN4X9migPsmymggPDQ0PTbs2ne8S5T/lZxtNHC+z qF5xjK3AULS2jIGzwML2BfiLZy2UvJQ4qYEwEJAc7N8PtXaspomGjTAPoh+QSDmR ZtesX53sUwHncA2KZbkqxUAFXlrZ4nJK3a3pKasv5FirvPTng4bV4gd6EjZXpgRi zO0ap/+g+9Ebs+ecH2gZaKk6se3XuAxRCD8Yu/KwYZNCJmjWEFFriiAEkQARAQAB tCpMb2dhbiBNYXJjaGlvbmUgPGxvZ2FuQGxvZ2FubWFyY2hpb25lLmNvbT6JAjcE EwEIACEFAlaDTpoCGwMFCwkIBwIGFQgJCgsCBBYCAwECHgECF4AACgkQt62lSxyM SycrLg//VVDsGiwwTBmwGTQU5ciJQjeUtjusJvjIga4H9VLOrLRiSljWG02queoE cihx1Dtvo3bR/tyXFMt6LCqlpbP+iBLnIyOzMwJfsWQvyqQOVRI/2mX+VVOxfbO2 6RvNQuK+GFayLXtV2QNeyOLKbASjAJ7PUB3q5sh3uhwy8Cs5haLu5G99vXIWoVDV mtluW97bamK8udA6TMlqVb4+r9wE9cMxeiQeH6lhnuvRospTUI4D4+zAf1kPvOWS RAe85waCuLiqqkmIVaoOkcSw3Ml76mRT9LkxtSQKDr3rPV70kS1pmovxrn2uXRt2 ok1iN2R4duRs3K/fhlTIXS+sU8Qa2PdQq4Rq9+G2y2xG3TiPYQwKpnD6/H/4fboB yWLyYT8agBxyEPAtk6+hgSbivSPUuhyAncYKdJrDjKsjB0dNHBegAqSv5vdyhWxx q39+QC0WiRWfYZQ2h9UYq9nfui+bjlX9gPXs2GpRE71BBImG4Mq2/GzNhwVeqflj TBQShblWoI/1MLQHF7Ek+n6UuxXp5QY077VVV4ioy1T949zBOxf2l9Bf+RERf5VU RkDxSfJBBLECDf3SA4zrat2HxDRBv1ZSFLmPKBlBN5ehLRJWL21OKO/4EYfHBwYS hUDv2XKmTohZ+WP/4y5BXdrkaXsCguSKIjRl8wohpBJjFwxbhMS5Ag0EVoNOmgEQ AKrDlvQi6pugG2WmtMe2QJmL1yAcsUiexVFYcgUd3uFsWCHNQGOSp/XgH2Pqx4ae XjwozdlosT2t2WHzbyH7iAb4YW2mx212NEVQOi4b38MXlnDK8ZuGXVKSDq+Tflss VXkeNtAVK4dqLKxAqWymq23Ug7NObwLOmfwwnuJuad8QtFVTKS1PamrWWtYUlCNx 6GFNFDSei0nqYQJYtkymu33+jB3CDnfp4eOJczlNCQr9qyjRPx0wz/wFrEvYBD4r iO9nK8PEvoMOCIjrdvroucC63BuIG/11BJHb6hTxHQXCh8BFmSX0qpXVXsALNoH8 jcrUtM8NBi1kagpT8dhXRdjlmLR6Zkr+pB7sTFFGjMFPiAYZNt+mtyhIdxB/+VAe r3zOJqow+amQpsNGyOrDR/bcFDWZn6xOdxIlsR+RzJnEdNRToTBzcp4AqtA4ZMRO otr1ztJMdHiQrnJRsZn2j7qlbYtVhlAua1DKQwiZRJH7s4FRujCZvrQ2a6i+i51v ASZOlQ2wahCex+vAosRLJSdQNTFm2mmDNmQ5PoB1Lbor0ZwE9Dh0CmCIEqnTQmw5 941OkdW0ZUmjetfEzG4QoVYiaNiOZXxzFxlR9BLM2Wl+cg6fFJDWaybQ3vy5y3qJ 7YR8X86qNqdkphQ7uMC9TQ5F8iouFZX+284bYFwRsaVrABEBAAGJAh8EGAEIAAkF AlaDTpoCGwwACgkQt62lSxyMSycc/w//X4adPpGg1odzc7qDiAVPqJv2lh/11Hir LLMHubRGhSEtLrXpBY0uWgm3mRRHwYR8cWmdQRF2GQuBKn8SSDWfwRgplrlFsXuY xQ3xFWQ3h5USY1Y+6yMcc0VZ5l7jRiW8gw6sspACloSDpzQk/nLKC7+A3b7AGZGv N4MIadphedrjGjsIZtQJ6DC/sZjEhBZUgqxcI5qaBUtrnlA3QCUYsa1JYGSFu8oq sPBruqgr02X8oYsWGvz4iM8cgyEl49PxXMLAGgJ4HghlSCRHdIOGQ4/kUACjtC+b oReZ3dKwT2iqv6saMer5I2Pl4qf0+Y5w/SMPYvWV0tCz3vwr+IdWcWEOfzCwhxEe AP6bLL1wBol3x5bzilZ/ORN5wsVV67PR+asjWFZGdb2S6kedJ4e3kvPrgJa/JEI3 YYupeId3puY2ByCUzRDG0+57rR87LbxeS6fsbvTyDmlvOEHxujW7YeEHib6YeG12 tStAAPg2ql6IK7PKDjDoK1YqKN+IW4w+UDJFh89urEokmkuZKMX4RBgPSb37XEw0 ufbIngA6+BlNugzpQnfxcWMz31gZSjmwjDZjtVKTuM9mPZvgP7XB0gU4WzjffpsI HhCOLGsimhprq2DqnjzxKMTcDu5tOOBvjtCtaTDxhPF7O6UboWQXvogzcb9iYaWL CiNrh1avYNQ= =ujqp -----END PGP PUBLIC KEY BLOCK----- To a keyserver Start by finding the 8 character hexadecimal ID of your key, using the command below. The hex-id¬†will be the same as the last 8 characters of your key fingerprint as well.\ngpg --list-keys your-key-id Now, upload your key to a keyserver. You\u0026rsquo;ll need to use your hex-id, not your your-key-id, as we\u0026rsquo;ve been using in this guide.\ngpg --send-keys --keyserver pgp.mit.edu hex-id Note - The major keyservers mirror one another, so once you upload to one, they\u0026rsquo;ll eventually all be in sync.\nImport a key To trust other users, you\u0026rsquo;ll need to import their keys.\nManually Use the command below to import a key from a file.\ngpg --import filename From a keyserver Before we being, keep in mind that importing a key from a keyserver does not guarantee the key belongs to the user (e.g., look at all the entries for Richard Stallman).\nFirst, start by searching for a key on a keyserver.\ngpg --search-keys --keyserver pgp.mit.edu their-key-id Then, import the key using the command below.\ngpg --recv-keys --keyserver pgp.mit.edu their-key-id A note on¬†short key IDs When publishing your GPG information, you typically publish the entire public key, as well as the fingerprint, long key ID, and short key ID.\nIt is highly¬†recommended to NOT¬†use the short key ID or long key ID when importing/exporting/publishing your GPG information. Instead, use the full 40 character fingerprint. Using a GPU, anyone can generate a key with a duplicate short key ID. More resources are available here, here,¬†here, and a guide to publishing your information effectively¬†is here.\nSigning keys Web of trust Before we discuss signing keys, we need to understand the¬†web of trust¬†(WOT). The WOT is a concept used to establish the authenticity of a public key with an individual owner. It is the decentralized version of the centralized public key infrastructure (PKI) commonly used by certificate authorities when creating SSL certificates.\nSigning Signing a key is your way of telling the world that you believe the key belongs to the name and email contained inside it.\nFirst, you\u0026rsquo;ll have¬†to¬†import¬†the key of the other user (either manually or from a keyserver).¬†Next, you\u0026rsquo;ll need to sign their key.\ngpg --sign-key their-key-id After you\u0026rsquo;ve signed their key, you should export it.\ngpg --export --armor their-key-id Send them the output, and have them import it into GPG on their machine. They can then publish their updated key on a keyserver to show the world that you trust their key.\nThis is how the web is created and expands.¬†If someone trusts you, and they see you\u0026rsquo;ve trusted this user, they will be more likely to trust that user as well. The more users that trust each other\u0026rsquo;s keys, the more of a \u0026ldquo;web of trust\u0026rdquo; that is created.\nKey signing party The WOT wouldn\u0026rsquo;t be very useful, however, if the web wasn\u0026rsquo;t large.¬†Imagine you have a key pair, but don\u0026rsquo;t know anyone else who uses GPG. Who would sign your keys?¬†Fortunately, events called key signing parties exist where users gather to verify each other\u0026rsquo;s identities and exchange fingerprints of public keys printed on paper (users are often warned not to bring a computer). After the party, users sign the keys they received, upload them to keyservers, then download their newly signed public key as well. A few resources on¬†the etiquette and procedures of key signing parties are located here, here, and here.¬†Two site for generating paper fingerprint¬†slips are located here and here.\nManually encrypting You MUST specify a recipient when encrypting files, including yourself! If you want only yourself to decrypt a file, you must specify only¬†yourself as a recipient. If you want only¬†another user¬†to decrypt a file, you must specify only¬†another user as a recipient.¬†If you do not specify a recipient, no one will be able to decrypt your file (not even you)!\nEmail To manually encrypt a message, start by saving the message to a file. Then, encrypt the file for email, using the command below.\ngpg --encrypt --sign --armor --recipient your-key-id --recipient their-key-id filename You can copy/paste the ASCII output into the body of the email/forum/etc\u0026hellip;\nNote - When GPG encrypts/decrypts a file, it usually leaves the original file intact. Be sure to securely delete this file (sdelete on Windows, shred on Linux).\nFiles Encrypting files is similar to encrypting emails.\ngpg --encrypt --sign --recipient your-key-id filename The resulting file will be named filename.gpg.\nNote - When GPG encrypts/decrypts a file, it usually leaves the original file intact. Be sure to securely delete this file (sdelete on Windows, shred on Linux).\nManually decrypting Use the command below to decrypt a file/message.\ngpg --output filename --decrypt filename.gpg Note - When GPG encrypts/decrypts a file, it usually leaves the original file intact. Be sure to securely delete this file (sdelete on Windows, shred on Linux).\nBasic key management List all keys on your system.\ngpg --list-keys Updates all¬†keys downloaded from a keyserver.\ngpg --refresh-keys --keyserver pgp.mit.edu List all signatures on a particular key\ngpg --list-sigs your-key-id Automated tools As you have learned by now, GPG is difficult and cumbersome to use on the command line. However, there are a number of GUI¬†tools that make using GPG a little easier.\nDesktop email Evolution¬†- An email client that provides email, calendar, and contacts, with GPG integration Claws Mail - An email client that provides email with GPG integration. Enigmail - A plugin that brings GPG integration to Thunderbird. GpgOL - A plugin that brings GPG integration to 32bit versions of Outlook. Part of Gpg4win. The Free Software Foundation has a great guide to configuring Enigmail on Thunderbird. I won\u0026rsquo;t bother going over the same setup here.\nWebmail For webmail,¬†Mailvelope is the most popular (still actively developed) way to encrypt email. It offers plugins for Firefox and Chrome, and integrates with Gmail, Yahoo! Mail, Outlook.com, and more. It can also create/manage/delete/import/export GPG keys, without GPG needing to be installed (it relies on OpenPGP.js).\nAgain, Mailvelope offers¬†a great guide to installation and configuration, so I won\u0026rsquo;t bother repeating it here.\nFiles Encrypting files on your local machine is made easier with the tools below.\nGPG Desktop - Brings GUI for encrypting files to Windows. Gpg4win - Suite of components that bring a GUI for encrypting files to Windows. GPG Tools - Suite of components that bring a GUI for encrypting files/email to Mac OS X and Apple Mail. GPA - Official GPG GUI client for Linux. Seahorse - Suite of components and plugins that bring GUI to various GNOME applications. Let me know how you use GPG!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2015/12/a-brief-introduction-to-gpg/","summary":"Introduction Put on your tinfoil hats, boys and girls! Today, we\u0026rsquo;re talking about security, encryption, and GPG!\nPGP vs OpenPGP vs GPG PGP Pretty Good Privacy (PGP) was a program created to encrypt/decrypt data in 1991 by Phil Zimmermann. Zimmermann formed PGP Incorporated, which was acquired serveral times and is now owned by Symantec.\nFun fact - in 1993 the US government charged Zimmerman with¬†\u0026ldquo;munitions export without a license\u0026rdquo;. At the time, cryptography systems with keys over 40 bits were considered a weapon, and since PGP used 128 bit keys, Zimmerman was in violation of the law.","title":"A brief introduction to GPG"},{"content":"Hey! Listen! This post is part of a series on using OpenWrt. Check them all out!\nDate URL Part 2016-04-28 OpenWrt upgrade process OpenWrt upgrade 2015-08-26 OpenWrt with OpenVPN server on TP-Link Archer C7 Initial post 2015-02-15 OpenWrt with OpenVPN client on TP-Link TL-MR3020 Initial post Introduction I\u0026rsquo;m not going to spend any time talking about why you should be using a VPN, or how a VPN works. If you\u0026rsquo;re here, you know that already. If you need a refresher on the different types of VPNs, see below.\nSoftware Advantage Disadvantage PPTP Available in most operating systems by default Uses IP protocol 47 (GRE) and UDP port 1723, making it easily detectable and blockable by a firewall Encryption is not strong First on NSA's \"to-hack\" list L2TP/IPSec Available in most operating systems by default More secure than PPTP No known security flaws Uses UDP ports 50, 500, 1701, and 4500, making it easily detectable and blockable by a firewall Slightly more overhead than OpenVPN, since traffic is passing through the tunnel and encryption in two separate steps OpenVPN Very configurable Uses open source software More secure than PPTP No known security flaws Can use any port, setting to TCP 443 makes it almost indistinguishable from HTTPS traffic Not available in most operating systems by default, requires a third-party application Looking at my Piwik data, my most popular posts by far are the guides about setting up an OpenVPN client on a MR3020. After that, I receive the most questions about how to setup an OpenVPN server. Until now, I\u0026rsquo;ve been running a PPTP server on an e2000 running DD-WRT, because PPTP is easy to setup in DD-WRT (assuming you have the correct build). However, PPTP has its flaws (as shown above). I\u0026rsquo;ve also setup OpenVPN Access Server on Ubuntu Server, but that is for connecting to a VPS, not your home network (though, you could build the same setup in your home).\nThis tutorial is going to be about setting up your own OpenVPN server on OpenWrt. This setup is taken mainly from this guide.\nHardware Since I\u0026rsquo;ve had luck with TP-Link in the past, I chose to use a TP-Link Archer C7 for my main router/OpenVPN server. I was looking for something that had dual-band technology (since the 2.4GHz spectrum is pretty crowded around my house), as well as 802.11ac technology (since it\u0026rsquo;s several times faster than 802.11n).\nIf you\u0026rsquo;re purchasing a C7, make sure it is hardware version 2.0. From the C7\u0026rsquo;s wiki page:\nFor the Archer C7 v1.x and WDR7500 v2.x, the 5GHz 802.11a/n/ac functionality is not supported, and likely will never be, since support for the AR1A (v1) variant of QCA9880 chip is not included in the open source ath10k driver. The Archer C7 v2.x uses the BR4A (v2) variant which is supported in ath10k.\nSoftware Obviously, I\u0026rsquo;m using OpenWrt again. In this case, I\u0026rsquo;m going to be using Chaos Calmer, even though it\u0026rsquo;s still on release candidate 3 and not a \u0026ldquo;stable\u0026rdquo; release yet. I\u0026rsquo;m choosing CC because LuCI for BB does not supporting configuring 802.11ac via the web.\nWhen choosing a download for OpenWrt CC RC3 on the C7, be careful which one you choose. There is a download for v1 and v2, then a file for flashing from factory or from a previous release of OpenWrt.\nC7 v1 factory C7 v1 OpenWrt upgrade C7 v2 factory¬†\u0026lt;\u0026ndash;I\u0026rsquo;m using this file, since my C7 is v2 and on factory firmware C7 v2 OpenWrt upgrade Install OpenWrt I‚Äôm going to assume you‚Äôre running the factory firmware and want to install OpenWrt. If you haven\u0026rsquo;t already, make sure you check the MD5 hash of the file you downloaded.\nDisconnect your PC from all wired and wireless networks, then connect the LAN port of the C7 to your PC. You should pull an IP in the 192.168.0.X range, so your C7\u0026rsquo;s IP should be 192.168.0.1. Open your browser, navigate to 192.168.0.1, and enter the username/password combination of admin/admin.\nOnce you‚Äôre logged into the router, go to System Tools, then Firmware Upgrade. Browse to your file and click Upgrade.\nIf you receive a message reading Please choose a file to upgrade!, you\u0026rsquo;ll need to rename the file to something shorter, like openwrt.bin.\nConfigure OpenWrt Set a password After the router reboots, you\u0026rsquo;ll need to login via telnet (since SSH is disabled, and LuCI isn\u0026rsquo;t installed in non-final releases of CC). Check your IP address and login via telnet, as shown below.\n/home/logan logan@arch --\u0026gt; telnet 192.168.1.1 Trying 192.168.1.1... Connected to 192.168.1.1. Escape character is \u0026#39;^]\u0026#39;. === IMPORTANT ============================ Use \u0026#39;passwd\u0026#39; to set your login password this will disable telnet and enable SSH ------------------------------------------ BusyBox v1.23.2 (2015-06-18 21:35:30 CEST) built-in shell (ash) _______ ________ __ | |.-----.-----.-----.| | | |.----.| |_ | - || _ | -__| || | | || _|| _| |_______|| __|_____|__|__||________||__| |____| |__| W I R E L E S S F R E E D O M ----------------------------------------------------- CHAOS CALMER (15.05-rc3, r46163) ----------------------------------------------------- * 1 1/2 oz Gin Shake with a glassful * 1/4 oz Triple Sec of broken ice and pour * 3/4 oz Lime Juice unstrained into a goblet. * 1 1/2 oz Orange Juice * 1 tsp. Grenadine Syrup ----------------------------------------------------- root@OpenWrt:/# After you\u0026rsquo;re in through telnet, use passwd to change your password (which will enable SSH).\nroot@OpenWrt:/# passwd Changing password for root New password: Retype password: Password for root changed by root Logout of telnet, then SSH in using root and the password you just set.\n/home/logan logan@arch --\u0026gt; ssh root@192.168.1.1 root@192.168.1.1\u0026#39;s password: BusyBox v1.23.2 (2015-06-18 21:35:30 CEST) built-in shell (ash) _______ ________ __ | |.-----.-----.-----.| | | |.----.| |_ | - || _ | -__| || | | || _|| _| |_______|| __|_____|__|__||________||__| |____| |__| W I R E L E S S F R E E D O M ----------------------------------------------------- CHAOS CALMER (15.05-rc3, r46163) ----------------------------------------------------- * 1 1/2 oz Gin Shake with a glassful * 1/4 oz Triple Sec of broken ice and pour * 3/4 oz Lime Juice unstrained into a goblet. * 1 1/2 oz Orange Juice * 1 tsp. Grenadine Syrup ----------------------------------------------------- root@OpenWrt:~# After you\u0026rsquo;re in, we can start setting up OpenWrt. Most of these steps will be taken from my previous guides, as well as the OpenWrt basic config guide.\nSetup NTP The C7 doesn‚Äôt have a real-time clock or CMOS battery. Because of this, every time it loses power, the clock resets to a specific date. To circumvent this, we‚Äôre going to use NTP to get our time from the internet. You don‚Äôt have to setup NTP, but it makes troubleshooting easier when you‚Äôre looking at timestamped log files. Keep in mind, since the C7 is connected directly to your PC (not the internet), this won‚Äôt take effect until after we get it online.\nFirst, set a hostname, zone name, and time zone for your router. The list of zone names/time zones can be found here. Make note of the tick marks around the zonename.\nuci set system.@system[0].hostname=\u0026#34;c7main\u0026#34; uci set system.@system[0].zonename=\u0026#34;America/New York\u0026#34; uci set system.@system[0].timezone=\u0026#34;EST5EDT,M3.2.0,M11.1.0\u0026#34; uci commit system Next, we‚Äôre going to enable the NTP client.¬†I‚Äôm using US servers from the NTP Pool Project, but change your servers as needed. Again, don‚Äôt forget the tick marks.\nuci set system.ntp=\u0026#34;timeserver\u0026#34; uci set system.ntp.enabled=\u0026#34;1\u0026#34; uci delete system.ntp.server uci add_list system.ntp.server=\u0026#34;0.us.pool.ntp.org\u0026#34; uci add_list system.ntp.server=\u0026#34;1.us.pool.ntp.org\u0026#34; uci add_list system.ntp.server=\u0026#34;2.us.pool.ntp.org\u0026#34; uci add_list system.ntp.server=\u0026#34;3.us.pool.ntp.org\u0026#34; uci commit system Set default IP Next, we‚Äôre going to change the default IP of the router from 192.168.1.1 to 10.10.1.1 (or whatever scheme you want). Most devices ship with 192.168.1.1 as the default, but I like to change to a different subnet.\nuci set network.lan.ipaddr=\u0026#34;10.10.1.1\u0026#34; uci commit network You can also limit the number of addresses available in the DHCP pool (optional).\nuci set dhcp.lan.start=\u0026#34;10\u0026#34; uci set dhcp.lan.limit=\u0026#34;50\u0026#34; uci commit dhcp reboot Verify internet access At this point, plug your internet connection into the WAN port of the C7. Assuming it receives an IP from your modem via DHCP, you should be able to access the internet on a client PC, as well as ping websites through SSH. If you check the date with the date command, you should see the date/time are correct because of NTP.\nSetup wireless Next, I\u0026rsquo;m going to setup the wireless. However, I\u0026rsquo;m going to opt to configure the wireless from the web interface, also known as LuCI. I\u0026rsquo;m choosing to do this because the C7 has two radios and it\u0026rsquo;s easier to configure through LuCI than SSH. If I lose nerd-points in your eyes, I\u0026rsquo;m sorry.\nInstall LuCI LuCI isn‚Äôt installed in non-final releases of CC, so we need to install it.\nopkg update opkg install luci luci-ssl /etc/init.d/uhttpd start /etc/init.d/uhttpd enable After LuCI is installed, navigate to 10.10.1.1 in your browser, and enter the username/password combination you were using for SSH.\nCreate wireless network Go to the Network dropdown, then select Wifi. Enable your radios as necessary. I enabled a 802.11n radio at 2.4GHz and a 802.11ac radio at 5GHz to test with. Press Save \u0026amp; Apply to continue.\nSetup DDNS First, we\u0026rsquo;ll need to setup dynamic DNS (DDNS). We\u0026rsquo;ll be running a server out of our house, and since our ISP regularly changes our IP address, we\u0026rsquo;ll never know when the address changes. Instead, we can run a small program on OpenWrt that will reach out to a DDNS provider, tell them what our IP address currently is, and associate it to a DNS name. This way, when setting up our OpenVPN clients, we\u0026rsquo;ll use the DDNS name, not our IP.\nIf you don\u0026rsquo;t have one already, you\u0026rsquo;ll need a DDNS provider. I\u0026rsquo;ve been a Dyn customer since before all the drama about discontinuing their free accounts. Make sure you choose a provider that is supported by OpenWrt. Once you choose a provider, you\u0026rsquo;ll need to register a DNS name with them.\nYou\u0026rsquo;ll also need the following info about your account:\nDDNS service name (as listed here, or in /usr/lib/ddns/services) Host name/domain Username Password (some providers offer an updater key instead of exposing your password) Interface you\u0026rsquo;ll be using to get DNS info (e.g., wan, wan6, lan, etc\u0026hellip;) Start by installing the necessary DDNS packages. If you want to configure DDNS via LuCI, you\u0026rsquo;ll need the package for that as well. I\u0026rsquo;m also installing two extra packages to make DDNS requests over SSL, as described here.\nopkg update opkg install ddns-scripts luci-app-ddns ca-certificates wget I\u0026rsquo;m going to be configuring via command line, but you could perform the same steps in LuCI. Here, I\u0026rsquo;m using the IP of the eth0 interface to update my DDNS entry. Obviously, substitute your service/hostname/username/password as needed.\nuci delete ddns.myddns_ipv4 uci delete ddns.myddns_ipv6 uci set ddns.myddns=\u0026#34;service\u0026#34; uci set ddns.myddns.service_name=\u0026#34;ddnsprovider.com\u0026#34; uci set ddns.myddns.domain=\u0026#34;yournamehere.yourproviderhere.com\u0026#34; uci set ddns.myddns.username=\u0026#34;username\u0026#34; uci set ddns.myddns.password=\u0026#34;p@ssw0rd\u0026#34; uci set ddns.myddns.interface=\u0026#34;wan\u0026#34; uci set ddns.myddns.ip_source=\u0026#34;interface\u0026#34; uci set ddns.myddns.ip_interface=\u0026#34;eth0\u0026#34; uci set ddns.myddns.enabled=\u0026#34;1\u0026#34; uci set ddns.myddns.use_https=\u0026#34;1\u0026#34; uci set ddns.myddns.cacert=\u0026#34;/etc/ssl/certs\u0026#34; uci commit ddns When you\u0026rsquo;re finished, be sure to start and enable the DDNS client.\n/etc/init.d/ddns start /etc/init.d/ddns enable Check your DDNS provider\u0026rsquo;s website to make sure your address is updating. If you\u0026rsquo;re having issues, run the command below to manually update your DDNS. It should give you some insight as to where the error is.\n/usr/lib/ddns/dynamic_dns_updater.sh myddns Setup OpenVPN Install packages Start by installing the necessary OpenVPN packages. If you want to configure OpenVPN via LuCI, you\u0026rsquo;ll need the package for that as well.\nopkg update opkg install openvpn-openssl openvpn-easy-rsa luci-app-openvpn openssh-sftp-server It\u0026rsquo;s a good idea to move the /etc/easy-rsa directory to somewhere else, in case you do an upgrade and overwrite your files.\nmkdir /etc/config/openvpn-config mv /etc/easy-rsa/* /etc/config/openvpn-config/ rm -rf /etc/easy-rsa/ ln -s /etc/config/openvpn-config/ /etc/easy-rsa rm /etc/config/openvpn_recipes touch /etc/config/openvpn-config/client.ovpn Create certificates Next, we\u0026rsquo;re going to generate the certificates for the server and client(s). We need to start by editing a few lines in the /etc/easy-rsa/vars file.\nSet the key size to at least 2048 bits. A key size of 4096 is preferred, but your client has to support it, plus it adds additional encryption overhead.\nexport KEY_SIZE=2048 Fill out the certificate info as necessary.\nexport KEY_COUNTRY=\u0026#34;US\u0026#34; export KEY_PROVINCE=\u0026#34;CA\u0026#34; export KEY_CITY=\u0026#34;SanFrancisco\u0026#34; export KEY_ORG=\u0026#34;Fort-Funston\u0026#34; export KEY_EMAIL=\u0026#34;me@myhost.mydomain\u0026#34; export KEY_OU=\u0026#34;MyOrganizationalUnit\u0026#34; Next, create your certificate authority, Diffie-Hellman parameters (this will take 40+ minutes), and certificates. If you want more client certificates, run the last command again, specifying a different name.\ncd /etc/easy-rsa source vars clean-all build-ca build-dh build-key-server c7 build-key-pkcs12 user1 Note - I\u0026rsquo;m choosing to use the PKCS12 format for the client certificates, since it combines the key and CA certificate into one file. Your client may want the two certificates to be separate.\nConfigure network/firewall Next, we need to configure a new network interface and assign a firewall zone to it.\nuci set network.vpn0=\u0026#34;interface\u0026#34; uci set network.vpn0.ifname=\u0026#34;tun0\u0026#34; uci set network.vpn0.proto=\u0026#34;none\u0026#34; uci set network.vpn0.auto=\u0026#34;1\u0026#34; uci commit network uci add firewall rule uci set firewall.@rule[-1].name=\u0026#34;Allow-OpenVPN-Inbound\u0026#34; uci set firewall.@rule[-1].target=\u0026#34;ACCEPT\u0026#34; uci set firewall.@rule[-1].src=\u0026#34;wan\u0026#34; uci set firewall.@rule[-1].proto=\u0026#34;udp\u0026#34; uci set firewall.@rule[-1].dest_port=\u0026#34;1194\u0026#34; uci add firewall zone uci set firewall.@zone[-1].name=\u0026#34;vpn\u0026#34; uci set firewall.@zone[-1].input=\u0026#34;ACCEPT\u0026#34; uci set firewall.@zone[-1].forward=\u0026#34;ACCEPT\u0026#34; uci set firewall.@zone[-1].output=\u0026#34;ACCEPT\u0026#34; uci set firewall.@zone[-1].masq=\u0026#34;1\u0026#34; uci set firewall.@zone[-1].network=\u0026#34;vpn0\u0026#34; uci add firewall forwarding uci set firewall.@forwarding[-1].src=\u0026#34;vpn\u0026#34; uci set firewall.@forwarding[-1].dest=\u0026#34;wan\u0026#34; uci add firewall forwarding uci set firewall.@forwarding[-1].src=\u0026#34;vpn\u0026#34; uci set firewall.@forwarding[-1].dest=\u0026#34;lan\u0026#34; uci commit firewall /etc/init.d/network reload /etc/init.d/firewall reload Enable packet forwarding We also need to check if packet forwarding is enabled (it should be by default).\ncat /proc/sys/net/ipv4/ip_forward If it is not enabled, edit the file above and set the value to 1.\nOpenVPN server config Here, we\u0026rsquo;re going to be configuring the OpenVPN server. See the comments in the commands below for more information.\ntouch /etc/config/openvpn uci delete openvpn.sample_server uci delete openvpn.sample_client #set and enable vpn uci set openvpn.myvpn=\u0026#34;openvpn\u0026#34; uci set openvpn.myvpn.enabled=\u0026#34;1\u0026#34; #specify TUN vs. TAP (if you\u0026#39;re not sure, you want TUN) uci set openvpn.myvpn.dev=\u0026#34;tun\u0026#34; #specify port to use (default is 1194) uci set openvpn.myvpn.port=\u0026#34;1194\u0026#34; #specify protocol to use (default is UDP) uci set openvpn.myvpn.proto=\u0026#34;udp\u0026#34; #specify to use compression uci set openvpn.myvpn.comp_lzo=\u0026#34;yes\u0026#34; #logging uci set openvpn.myvpn.status=\u0026#34;/var/log/openvpn_status.log\u0026#34; uci set openvpn.myvpn.log=\u0026#34;/tmp/openvpn.log\u0026#34; uci set openvpn.myvpn.verb=\u0026#34;3\u0026#34; uci set openvpn.myvpn.mute=\u0026#34;5\u0026#34; #ping every 10 seconds, assume not responding after 120 seconds uci set openvpn.myvpn.keepalive=\u0026#34;10 120\u0026#34; #keep key and tunnel persistent across restarts uci set openvpn.myvpn.persist_key=\u0026#34;1\u0026#34; uci set openvpn.myvpn.persist_tun=\u0026#34;1\u0026#34; #set user and group to less-privileged account (UNIX/Linux only) uci set openvpn.myvpn.user=\u0026#34;nobody\u0026#34; uci set openvpn.myvpn.group=\u0026#34;nogroup\u0026#34; #certificate information uci set openvpn.myvpn.ca=\u0026#34;/etc/easy-rsa/keys/ca.crt\u0026#34; uci set openvpn.myvpn.cert=\u0026#34;/etc/easy-rsa/keys/c7.crt\u0026#34; uci set openvpn.myvpn.key=\u0026#34;/etc/easy-rsa/keys/c7.key\u0026#34; uci set openvpn.myvpn.dh=\u0026#34;/etc/easy-rsa/keys/dh2048.pem\u0026#34; #server settings uci set openvpn.myvpn.mode=\u0026#34;server\u0026#34; uci set openvpn.myvpn.tls_server=\u0026#34;1\u0026#34; uci set openvpn.myvpn.server=\u0026#34;10.8.0.0 255.255.255.0\u0026#34; #specify topology to use uci set openvpn.myvpn.topology=\u0026#34;subnet\u0026#34; #specify gateway to use uci set openvpn.myvpn.route_gateway=\u0026#34;dhcp\u0026#34; #allow clients to \u0026#34;see\u0026#34; one another uci set openvpn.myvpn.client_to_client=\u0026#34;1\u0026#34; #options to push to clients uci add_list openvpn.myvpn.push=\u0026#34;comp-lzo yes\u0026#34; #keep key and tunnel persistent across restarts uci add_list openvpn.myvpn.push=\u0026#34;persist-key\u0026#34; uci add_list openvpn.myvpn.push=\u0026#34;persist-tun\u0026#34; #set user and group to less-privileged account (UNIX/Linux only) uci add_list openvpn.myvpn.push=\u0026#34;user nobody\u0026#34; uci add_list openvpn.myvpn.push=\u0026#34;user nogroup\u0026#34; #specify topology to use uci add_list openvpn.myvpn.push=\u0026#34;topology subnet\u0026#34; #specify gateway to use uci add_list openvpn.myvpn.push=\u0026#34;route-gateway dhcp\u0026#34; #redirect ALL traffic through the VPN server (this is IMPORTANT if you don\u0026#39;t trust your local network) uci add_list openvpn.myvpn.push=\u0026#34;redirect-gateway def1\u0026#34; #push a local route to your clients (allow your clients to access the server\u0026#39;s network) uci add_list openvpn.myvpn.push=\u0026#34;route 10.10.1.0 255.255.255.0\u0026#34; #push DNS to your clients (this is IMPORTANT if you don\u0026#39;t trust your local network) uci add_list openvpn.myvpn.push=\u0026#34;dhcp-option DNS 107.170.95.180\u0026#34; uci add_list openvpn.myvpn.push=\u0026#34;dhcp-option DNS 50.116.40.226\u0026#34; uci commit openvpn Be sure to start and enable the OpenVPN server.\n/etc/init.d/openvpn start /etc/init.d/openvpn enable Next, look at the logfile at /tmp/openvpn.log. With any luck, you should see Initialization Sequence Completed, showing that your OpenVPN server is up!\nroot@c7main:/etc/config/openvpn-config/keys# cat /tmp/openvpn.log Thu Aug 20 20:49:02 2015 OpenVPN 2.3.6 mips-openwrt-linux-gnu [SSL (OpenSSL)] [LZO] [EPOLL] [MH] [IPv6] built on Jun 18 2015 Thu Aug 20 20:49:02 2015 library versions: OpenSSL 1.0.2d 9 Jul 2015, LZO 2.08 Thu Aug 20 20:49:03 2015 Diffie-Hellman initialized with 2048 bit key Thu Aug 20 20:49:03 2015 Socket Buffers: R=[163840-\u0026gt;131072] S=[163840-\u0026gt;131072] Thu Aug 20 20:49:03 2015 TUN/TAP device tun0 opened Thu Aug 20 20:49:03 2015 TUN/TAP TX queue length set to 100 Thu Aug 20 20:49:03 2015 do_ifconfig, tt-\u0026gt;ipv6=0, tt-\u0026gt;did_ifconfig_ipv6_setup=0 Thu Aug 20 20:49:03 2015 /sbin/ifconfig tun0 10.8.0.1 netmask 255.255.255.0 mtu 1500 broadcast 10.8.0.255 Thu Aug 20 20:49:03 2015 GID set to nogroup Thu Aug 20 20:49:03 2015 UID set to nobody Thu Aug 20 20:49:03 2015 UDPv4 link local (bound): [undef] Thu Aug 20 20:49:03 2015 UDPv4 link remote: [undef] Thu Aug 20 20:49:03 2015 MULTI: multi_init called, r=256 v=256 Thu Aug 20 20:49:03 2015 IFCONFIG POOL: base=10.8.0.2 size=252, ipv6=0 Thu Aug 20 20:49:03 2015 Initialization Sequence Completed OpenVPN client config Edit the OpenVPN client configuration file at /etc/config/openvpn-config/client.ovpn. I\u0026rsquo;m purposely keeping the client configuration file as thin as possible, so that most settings can be setup on the server and pushed to clients.\n#specify TUN vs. TAP (if you\u0026#39;re not sure, you want TUN) dev tun #specify protocol to use (default is UDP) proto udp #Certificate information ca ca.crt cert user1.crt key user1.key #client settings client remote-cert-tls server remote YOUR_DNS_ENTRY_OR_IP 1194 Distribute keys You‚Äôll need to move the following files from the router, to your client(s). All four files should be saved in the same folder/location on your client.\nCA certificate (ca.crt) client certificate (user1.crt) client keyfile (user1.key) client config file (client.ovpn) You can use SFTP, SSH, or copy them to a USB drive. You could email them, but I would advise against it (since the key isn\u0026rsquo;t encrypted).\nConfigure OpenVPN client In this case, I\u0026rsquo;m going to be using the official OpenVPN Android app, but there are also clients for iOS, Windows, Mac, and Linux.\nOnce installed, tap on the Option button, then tap on Import, then tap on Import Profile from SD Card.\nBrowse to the client.ovpn file and import it into the OpenVPN Connect app.\nThe profile should be imported successfully, and you should be able to see your server\u0026rsquo;s name or IP. Click Connect to establish a connection.\nVerify your connection on the next screen.\nVerify connection Try to browse a public site (e.g., www.google.com), then try to browse to your router\u0026rsquo;s IP (e.g., 10.10.1.1). If everything is setup correctly, both should load. You can also check your IP with an external tool, such as WhatIsMyIP, and you should see your OpenWrt router\u0026rsquo;s public IP. I\u0026rsquo;d also advise to check for DNS leaks (your DNS should be set to the DNS servers we pushed to the clients).\nLet me know how your setup went!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2015/08/openwrt-with-openvpn-server-on-tp-link-archer-c7/","summary":"Hey! Listen! This post is part of a series on using OpenWrt. Check them all out!\nDate URL Part 2016-04-28 OpenWrt upgrade process OpenWrt upgrade 2015-08-26 OpenWrt with OpenVPN server on TP-Link Archer C7 Initial post 2015-02-15 OpenWrt with OpenVPN client on TP-Link TL-MR3020 Initial post Introduction I\u0026rsquo;m not going to spend any time talking about why you should be using a VPN, or how a VPN works. If you\u0026rsquo;re here, you know that already.","title":"OpenWrt with OpenVPN server on TP-Link Archer C7"},{"content":"Hey! Listen! This post is part of a series on using your own router with Verizon FiOS. Check them all out!\nDate URL Part 2016-08-22 Verizon FiOS Router Maintenance Charge Maintenance Charges 2015-07-11 Use your own router with Verizon FiOS Initial Post Introduction At the new house, we have Verizon FiOS. If you\u0026rsquo;re not familiar, FiOS is a FTTP (Fiber-to-the-Premises) multimedia service that offers phone service, internet, and TV. If fiber is strung in your area, Verizon taps into the fiber line on the telephone pole and runs it to your house. Verizon will then install a box on your property called the Optical Network Terminal (ONT), that converts the fiber signal into a copper signal.\nEach ONT has multiple outputs and is capable of delivering multiple phone lines, internet data, and TV data. For the internet signal, typically the Verizon technician configures the ONT to have coaxial output, because most homes are already wired for coaxial from the demarc to various rooms in the house.\nVerizon also provides an internet router that connects to the ONT. The FiOS router (typically an ActionTec MI424WR 100Mbps or 1Gbps) has a coaxial/ethernet inputs and acts as an all-in-one MoCA bridge, router, switch, and wireless access-point.\nIn the typical setup (shown below) the coaxial cable coming from the ONT is split in two: one run for the FiOS router, and one run for the TV set-top boxes. The FiOS router takes input from coaxial and converts it to internet signal via the MoCA (Multimedia over Coax Alliance) bridge. If you have FiOS TV, you must have the FiOS router on your network (for functions like video-on-demand, the guide, etc\u0026hellip;).\nI\u0026rsquo;m not using FiOS for TV or phone service (I\u0026rsquo;m internet-only). My current setup (with the FiOS router) is shown below.\nHowever, if you\u0026rsquo;re an internet-only FiOS customer (like me), you don\u0026rsquo;t need to use the FiOS router, since the set-top boxes aren\u0026rsquo;t being used. I\u0026rsquo;d rather replace it with my own OpenWrt router that is more nerd-oriented and packs more features. Ideally, what I\u0026rsquo;d like to have is below.\nThis setup has the following benefits:\nI don\u0026rsquo;t have to use Verizon\u0026rsquo;s router. I wouldn\u0026rsquo;t have to put my router behind the FiOS router, resulting in a double-NAT (as I used to have). In some older FiOS routers, there is a hardware limit of 100Mbps. You can supposedly still receive TV service by turning the FiOS router into a MoCA bridge, as described here, and by a commenter, Danny. Router recommendations Almost any standard router will work here, as long as it acts as a router (i.e., it routes packets between networks) and a firewall (i.e., it inspects packets based on rules). If you\u0026rsquo;re an average user, most devices off the shelf from BestBuy or Amazon will get the job done just fine.\nPersonally, I recommend any router manufacturer that provides consistent updates. Asus is the real star here. All of their routers run the same basic OS, so when they create an update, it typically gets built for each model, since they\u0026rsquo;re based on the same platform. Because of this, Asus provides updates to their routers once every couple weeks. In addition, the excellent Merlin firmware is based on the standard Asus firmware. TP-Link and Netgear aren\u0026rsquo;t bad either, but only expect the newest devices to receive consistent updates.\nRouters to avoid I\u0026rsquo;d recommend avoiding a router by a manufacturer that has a poor history of providing updates. Unfortunately, this list is probably too exhaustive to list every manufacturer.\nAlso, you do not want a router that is advertised as a \u0026ldquo;DOCSIS modem\u0026rdquo; or a router that comes with a coaxial port instead of an ethernet WAN port. An example of what you don\u0026rsquo;t want is the Netgear C7000, because it is a modem, and lacks a WAN port.\nHow-to Do this at your own risk, I\u0026rsquo;m not responsible for anything you break. üôÉ\nRun ethernet cable In my case, this was a relatively short run. The ONT is in the unfinished basement and the router sits directly above it on the TV stand. There was already a hole drilled in the floor from a previous coaxial run, so I chose to cut the connectors off a Cat6 patch cable, run the cable through the floor, and re-crimp new connectors.¬†If you\u0026rsquo;re curious, below are the parts/tools I used.\nCable stripper Cable crimper Wire snips Cat6 connectors Cat6 patch cable Cable tester Cable clips I used the T568B standard (shown below) to terminate the cable.\nIf you don\u0026rsquo;t know how to make Cat6 cables, this video below is incredibly helpful.\nI tested my cable with a cable tester (to verify all four pairs were punched down correctly) and then tested it between my laptop and the FiOS router.\nConnect ethernet to ONT The ONT has two sides: one panel accessible by the customer and another accessible by Verizon.\nDisclaimer - Do not open the Verizon side of the ONT, as it\u0026rsquo;s their property. While you\u0026rsquo;re at it, don\u0026rsquo;t relocate or alter the ONT in any way, shape, or form. IANAL, but you will most definitely void any warranty or service agreement you had.\nOn the side accessible by the customer,¬†you should see a standard RJ-45 jack (hard to see, but it\u0026rsquo;s on the right).\nPlug your newly-made ethernet cable into the ONT.\nSetup new router In this step, you want to go through and setup your new router before you plug it into the network. Setup your username/password, WiFi settings, DHCP ranges, etc\u0026hellip; so that you can cutover to the new router quickly.\nIn my case, I\u0026rsquo;m going to be using OpenWrt on a TP-Link Archer C7. I\u0026rsquo;ve used OpenWrt in the past on a TP-Link MR-3020 and wanted to try it on a proper router. The Archer C7 has 802.11a/b/g/n/ac and is dual-band capable at 2.4GHz and 5GHz. It has OpenWrt support, as well as DD-WRT support. I plan on using the router to host an OpenVPN server, as well as a dynamic DNS updater. If you\u0026rsquo;d like, you can read more on that setup, here.\nBreak DHCP lease We need to start by breaking the DHCP lease on the FiOS router. To do this, login to the FiOS router via the web interface (most likely, the address will be 192.168.1.1 and the username/password will be on a sticker on the router). Click on¬†the My Network option at the top of the screen, on the left side click on¬†Network Connections, click on Broadband Connection (Ethernet/Coax), then click on Settings at the bottom of the page. Look for the¬†DHCP Lease¬†option in the list, click the Release button next to it, then scroll down to the bottom and click Apply.¬†As soon as the settings are applied, immediately unplug the power from the FiOS router so it doesn\u0026rsquo;t request a new DHCP lease.\nCall Verizon Call FiOS support at 1-888-553-1555. Remember what your mother taught you: use your manners! The Verizon technician doesn\u0026rsquo;t have to do this for you and will be doing you a favor. Ask customer support to switch the ONT from coaxial output to ethernet output.¬†If they give you a hard time about doing it remotely, tell them that you want to use your own router, an ethernet cable is already run, and you don\u0026rsquo;t need a technician to come out. You may even need to ask for a supervisor or level-two support technician. Expect to spend about 30-45 minutes on the phone.\nConnect new router After Verizon sets up the ethernet output,¬†connect the ethernet cable from the ONT to the WAN port on the new router. Connect a client (e.g., laptop, phone, etc\u0026hellip;) to a LAN port (or wireless) on the new router. Log into the router\u0026rsquo;s admin page and verify you\u0026rsquo;re receiving an IP address from the ONT. Once you are, verify your client can get online.\nThank the technician profusely The support technician just did you a huge favor. Take their survey after the call and give them 5-stars.\nWrap-up Disconnect the coaxial cable from the FiOS router and move any remaining ethernet connections over to the new router. With the FiOS router down and your new router up, verify internet connectivity once more. This is to double-check that the FiOS router isn\u0026rsquo;t routing any traffic at all.\nExtras Alternate ONT models There are various models of ONTs out there.\nA commenter was nice enough to send me a picture of his ONT (below) to show you the differences (thanks, Larry!).\nAnother commenter submitted a picture of his ONT (thanks, Brian!).\nClone MAC address I used to recommend cloning the MAC address of your FiOS router onto your new router. However, one commenter, Jeremy, had a pretty terrible time with this, and actually had his service cancelled. Instead, I recommend using your router with it\u0026rsquo;s true MAC address. This will most likey involve a call to Verizon, but it\u0026rsquo;s worth a few minutes on the phone.\nWhen I spoke with Verizon, they were able to switch the ONT over to ethernet without issue. The technician was able to see the MAC address of my C7, and I was able to verify a few packets were being sent/received, but I still wasn\u0026rsquo;t pulling an IP from the ONT. When I switched my connection back to the FiOS router (this time, on ethernet), I was able to get online without issue. I assumed it was something specific to my C7, and decided to clone the MAC address of the FiOS router to the WAN interface of the C7. After I rebooted, I was able to get an IP and get online.\nStrangely enough, after a few weeks, I removed the cloned MAC, rebooted, and still had service.\nDid you switch the FiOS router out for your own? If so, let me know how it went!\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2015/07/use-your-own-router-with-verizon-fios/","summary":"Hey! Listen! This post is part of a series on using your own router with Verizon FiOS. Check them all out!\nDate URL Part 2016-08-22 Verizon FiOS Router Maintenance Charge Maintenance Charges 2015-07-11 Use your own router with Verizon FiOS Initial Post Introduction At the new house, we have Verizon FiOS. If you\u0026rsquo;re not familiar, FiOS is a FTTP (Fiber-to-the-Premises) multimedia service that offers phone service, internet, and TV. If fiber is strung in your area, Verizon taps into the fiber line on the telephone pole and runs it to your house.","title":"Use your own router with Verizon FiOS"},{"content":"Update: LUKS2 is out, use it instead! LUKS2 was released in 2018, you should double-check the documentation for it before you blindly follow this guide. üôÉ\nIntroduction Since TrueCrypt is no longer under active development, I\u0026rsquo;ve decided to wipe my external drives and re-encrypt them with LUKS and dm-crypt. These are standard Linux tools that are available by default in most distributions. I\u0026rsquo;ve used LUKS and dm-crypt in the past, when I installed Arch Linux on my laptop. Here, I\u0026rsquo;ll be performing a similar procedure, but without LVM.\nCreating the encrypted drive Step 1 - Identify your disk Make sure you know which disk you\u0026rsquo;re working with by using lsblk.\nsudo lsblk Here, you can see the physical disk called /dev/sdb, which is my 1TB external drive. Do not assume that your drive will be /dev/sdb.\nNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 298.1G 0 disk ‚îú‚îÄsda1 8:1 0 1007K 0 part ‚îú‚îÄsda2 8:2 0 128M 0 part /boot ‚îî‚îÄsda3 8:3 0 298G 0 part ‚îî‚îÄVolGroup00 254:0 0 298G 0 crypt ‚îú‚îÄVolGroup00-lvolswap 254:1 0 8G 0 lvm [SWAP] ‚îú‚îÄVolGroup00-lvolroot 254:2 0 25G 0 lvm / ‚îî‚îÄVolGroup00-lvolhome 254:3 0 265G 0 lvm /home sdb 8:16 0 931.5G 0 disk Step 2 - Securely wipe your disk You should always wipe your disk before doing anything. Unfortunately, depending on the size of the disk, this could take a long time. If your drive is already encrypted, you could simply wipe the header and your data would be safe. Since I\u0026rsquo;m paranoid, I always choose to nuke the entire drive. You could use badblocks to do a destructive write test (as I did here), or use dd, as shown below. If you\u0026rsquo;re using a SSD, your techniques will have to be a little different.\nsudo dd if=/dev/zero of=/dev/sdb iflag=nocache oflag=direct bs=4096 Please don\u0026rsquo;t copy/paste this command directly, as you could risk destroying your current system. I\u0026rsquo;m not responsible for anything you break. ü§∑‚Äç‚ôÇÔ∏è\nStep 3 - Create partition Start by creating a partition using fdisk.\nsudo fdisk /dev/sdb Use the n option to create a new partition, then press p for a primary partition. Press 1 to¬†edit the first partition, then use the defaults for first and last sectors (this will fill up the entire drive). Finally, press w to write your changes.\nCommand (m for help): n Partition type p primary (0 primary, 0 extended, 4 free) e extended (container for logical partitions) Select (default p): p Partition number (1-4, default 1): 1 First sector (2048-1953458175, default 2048): Last sector, +sectors or +size{K,M,G,T,P} (2048-1953458175, default 1953458175): Created a new partition 1 of type \u0026#39;Linux\u0026#39; and of size 931.5 GiB. Command (m for help): w The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. Running lsblk again, we can see our new partition, /dev/sdb1.\nNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 298.1G 0 disk ‚îú‚îÄsda1 8:1 0 1007K 0 part ‚îú‚îÄsda2 8:2 0 128M 0 part /boot ‚îî‚îÄsda3 8:3 0 298G 0 part ‚îî‚îÄVolGroup00 254:0 0 298G 0 crypt ‚îú‚îÄVolGroup00-lvolswap 254:1 0 8G 0 lvm [SWAP] ‚îú‚îÄVolGroup00-lvolroot 254:2 0 25G 0 lvm / ‚îî‚îÄVolGroup00-lvolhome 254:3 0 265G 0 lvm /home sdb 8:16 0 931.5G 0 disk ‚îî‚îÄsdb1 8:17 0 931.5G 0 part Step 4 - Encrypt partition Here, we\u0026rsquo;ll setup encryption on our new partition.\nsudo cryptsetup -v -y -c aes-xts-plain64 -s 512 -h sha512 -i 5000 --use-random luksFormat /dev/sdb1 Option Description -v verbose -y verify passphrase, ask twice, and complain if they don\u0026rsquo;t match -c specify the cipher used -s specify the key size used -h specify the hash used -i number of milliseconds to spend passphrase processing (if using anything more than sha1, must be great than 1000) --use-random which random number generator to use luksFormat to initialize the partition and set a passphrase /dev/sdb1 the partition to encrypt Seriously, read the man page and the FAQ on cryptsetup before you do anything here.\nTo see the configuration of the header, use the command below.\nsudo cryptsetup luksDump /dev/sdb1 Step 4.5 - Backup the LUKS header The LUKS header stores metadata about the LUKS device, as well as the master key, key files, etc\u0026hellip; Specifically, from the cryptsetup FAQ and specification:\nA LUKS partition starts with the LUKS partition header (phdr) and is followed by key material. After the key material, the bulk data is located, which is encrypted by the master key. The phdr contains information about the used cipher, cipher mode, the key length, a uuid and a master key checksum. Also, the phdr contains information about the key slots. Every key slot is associated with a key material section after the phdr.¬†When a key slot is active, the key slot stores an encrypted copy of the master key in its key material section. This encrypted copy is locked by a user password. Supplying this user password unlocks the decryption for the key material, which stores the master key. The master key in turn unlocks the bulk data. For a key slot, all parameters how to decrypt its key material with a given user password are stored in the phdr (f.e. salt, iteration depth).\nThat paragraph is probably easier explained with an image.\nIf you don\u0026rsquo;t understand already, it\u0026rsquo;s important to not damage the LUKS header. It\u0026rsquo;s best practice to backup the header as soon as you create the LUKS device, because you\u0026rsquo;re probably lazy and won\u0026rsquo;t do it later. If you damage the header at all (accidental formatting, wrong device when using dd, bad block, etc\u0026hellip;), you\u0026rsquo;ll need this backup header to recover the data. The header file itself needs encrypted and should be stored in safe place (not on the same drive, obviously).\nsudo cryptsetup luksHeaderBackup --header-backup-file /path/to/file.img /dev/sdb1 Note - TrueCrypt (brilliant piece of software) uses a backup header at the end of the drive as well, to mitigate the risk of a single header.\nStep 5 - Unlock the LUKS device Open the LUKS container using the passphrase you just set. This will mount the device at /dev/mapper/volume01.\nsudo cryptsetup luksOpen /dev/sdb1 volume01 Step 6 - Create filesystem I\u0026rsquo;m going to be using ext4. Again, specify the name of device you set in the step above.\nsudo mkfs.ext4 /dev/mapper/volume01 Step 7 - Mount device Here, create a mount point, then mount the device to that location.\nsudo mkdir -p /mnt/drive01 sudo mount /dev/mapper/volume01 /mnt/drive01 Step 8 - Unmount and close container Now, unmount the drive and close the LUKS container.\nsudo umount /mnt/drive01 sudo cryptsetup luksClose /dev/mapper/volume01 Mounting the encrypted drive Every time you want to use this drive, you\u0026rsquo;ll need to open the LUKS container, mount the drive, do your work, unmount the drive, then close the LUKS container. You can do this manually, or a file manager to auto-mount it.\nManual Below are the steps to manually unlock and use the drive.\nsudo cryptsetup luksOpen /dev/sdb1 volume01 sudo mount /dev/mapper/volume01 /mnt/drive01 ##DO YOUR WORK HERE## sudo umount /mnt/drive01 sudo cryptsetup luksClose /dev/mapper/volume01 Automatic Modern file managers like Thunar and Nautilus have support for unlocking and mounting LUKS devices automatically. The only downside to this setup is that you can\u0026rsquo;t use keyfiles in addition to passphrases.\nInstall and configure Thunar If you don\u0026rsquo;t have Thunar, you\u0026rsquo;ll need it, along with a couple other packages.\nsudo pacman -S thunar thunar-volman gvfs gvfs-afc Open Thunar and navigate to Edit\u0026ndash;\u0026gt;Preferences\u0026ndash;\u0026gt;Advanced and ensure that Enable Volume Management is checked.\nClick on Configure, and ensure that Mount removable drives when hot-plugged and Mount removable media when inserted are both checked. Click on Close to save your changes.\nMount drive Plug in your external drive and open Thunar. In the top-left, you should see your drive under DEVICES.\nWhen you click on the drive, you\u0026rsquo;ll be prompted for the passphrase you set earlier.\nTo unmount the drive, right-click on it and select Unmount.\n-Logan\nComments Old comments from WordPress\n","permalink":"https://loganmarchione.github.io/2015/05/encrypted-external-drive-with-luks/","summary":"Update: LUKS2 is out, use it instead! LUKS2 was released in 2018, you should double-check the documentation for it before you blindly follow this guide. üôÉ\nIntroduction Since TrueCrypt is no longer under active development, I\u0026rsquo;ve decided to wipe my external drives and re-encrypt them with LUKS and dm-crypt. These are standard Linux tools that are available by default in most distributions. I\u0026rsquo;ve used LUKS and dm-crypt in the past, when I installed Arch Linux on my laptop.","title":"Encrypted external drive with LUKS"},{"content":"Hey! Listen! This post is part of a series on using OpenWrt. Check them all out!\nDate URL Part 2016-04-28 OpenWrt upgrade process OpenWrt upgrade 2015-08-26 OpenWrt with OpenVPN server on TP-Link Archer C7 Initial post 2015-02-15 OpenWrt with OpenVPN client on TP-Link TL-MR3020 Initial post Update: Multiple posts Originally, this series consisted of three posts with basically the same content, but small improvements each time. The original links are below:\nRevision 1 Revision 2 Revision 3 (this post) I have since re-directed all the links to this page, since revision 1 and revision 2 were obsoleted by revision 3. I just wanted to keep the links alive on the internet.\nIntroduction¬†A few months ago, the team at OpenWrt released version 14.07 of OpenWrt, called Barrier Breaker. I\u0026rsquo;m going to be installing Barrier Breaker on my MR3020 and setting up an OpenVPN client. If you don\u0026rsquo;t know the difference between PPTP/IPSec/OpenVPN, IVPN has a great comparison chart.\nThe \u0026ldquo;why\u0026rdquo; Before we get started, I need to get up on my soapbox and say a few things. If you\u0026rsquo;re not using a VPN, you should be. VPNs aren\u0026rsquo;t just for hackers, thieves, or people doing illegal things (you wouldn\u0026rsquo;t download a car, would you?). VPNs are great¬†for:\nAdding a layer of security to your browsing (VPNs encrypt everything!) Securely connecting two routers to create one large network over the internet (businesses do this all the time) Students/employees connecting back to their university/office to work remotely (again, a common practice) Circumventing geoblocking (i.e., content blocked based on your physical location) Watch Netflix from outside the US Watch BBC iPlayer from outside the UK FREEDOM OF SPEECH! Use a VPN to circumvent government restrictions put on the internet (e.g., China, Iran, North Korea, etc\u0026hellip;) But, I digress. VPNs are great. If you don\u0026rsquo;t have one, get one. Personally, I like using Private Internet Access¬†(I\u0026rsquo;m not compensated, just a happy customer).¬†If you don\u0026rsquo;t know where to start, TorrentFreak has a great article on which VPN services take your anonymity seriously (newsflash, PIA is at the top of their list).\nThe \u0026ldquo;how\u0026rdquo; My plan for this router is to use it when I travel. I plan on plugging it into the Ethernet port in a hotel (or my house/friend\u0026rsquo;s house/Airbnb host) and having it broadcast a wireless network. Since the router is an OpenVPN client, any devices that join that wireless network will be VPNed into PIA\u0026rsquo;s servers. Eventually, when I install OpenVPN on my home router, I can route my connection back home. It\u0026rsquo;s probably easier illustrated than explained, as below.\nThere are a few advantages to this setup, as opposed to installing the OpenVPN client on each device:\nDevices that don\u0026rsquo;t support OpenVPN can be protected (XBox, Roku, etc\u0026hellip;) Multiple machines (phone, laptop, Roku, etc\u0026hellip;) can¬†share one VPN connection You can switch between an insecure wireless network (home/friend\u0026rsquo;s house/hotel) and a¬†secure wireless network (OpenWrt) whenever needed Ready? Let\u0026rsquo;s get started!\nInstall OpenWrt I\u0026rsquo;m going to assume you\u0026rsquo;re already running Attitude Adjustment (AA) and want to upgrade to Barrier Breaker (BB).\nDisconnect your PC from all wired and wireless networks, then connect your MR3020 to your PC. Because of the way I have this router setup from my previous post (eth0 is a DHCP client, not server), I\u0026rsquo;m going to connect to the WiFi network it\u0026rsquo;s broadcasting.¬†I checked my IP, opened my browser, and navigated to 10.80.1.1 (your address will be 192.168.1.1 as stock). I then logged in with the username and password I had set before.\nOnce you\u0026rsquo;re logged into OpenWrt, go to the System tab, then the Backup/Flash Firmware tab.¬†At this point, it\u0026rsquo;s a good idea to¬†make a backup of your config by¬†pressing¬†Generate Archive.\nAs-of this writing, the OpenWrt wiki page for the MR3020 doesn\u0026rsquo;t list BB as the newest firmware. There are two options for the BB download: a file for the factory¬†firmware, and a file for upgrading. We\u0026rsquo;ll choose the upgrade.\nBack at your router, under Flash new firmware image, make sure Keep settings is checked to keep your current settings. I\u0026rsquo;m going to uncheck this, since I want to start from scratch. Browse to your downloaded firmware, and press Flash image to upgrade it.\nVerify the checksum, and press Proceed to continue.\nWait a few minutes and the router will reboot. Check your IP again after it\u0026rsquo;s back up, as mine had changed since I erased my settings.\nAt this point, my MR3020¬†is running stock BB and I\u0026rsquo;m going to reconfigure it from scratch. Since the wireless network was wiped out, I\u0026rsquo;m going to reconnect with Ethernet.\nConfigure OpenWrt From here, the OpenWrt wiki page recommends going through the basic configuration for any OpenWrt installation. I\u0026rsquo;m going to be combining some of the basic configuration with my configuration for the VPN client.\nNavigate to 192.168.1.1 in your browser and you\u0026rsquo;ll be greeted by LuCI, the web interface for OpenWrt. OpenWrt recently switched to the Unified Configuration Interface, also known as UCI. The UCI is basically a collection of easy-to-read configuration files that are all centrally located, making OpenWrt much easier¬†to configure. What\u0026rsquo;s nice about LuCI is that it reads/writes from/to the UCI files. Any changes you make in LuCI are reflected in the UCI files, and vice versa, meaning you can configure¬†the MR3020 from the web interface, or from the command line.\nAnyway, moving on. Leave the username as¬†\u0026ldquo;root\u0026rdquo; and the password field empty. Press Login to continue.\nSet a password From the main status screen, we\u0026rsquo;re going to set a root password by using the link in the yellow¬†box at the top of the page. If you haven\u0026rsquo;t noticed, LuCI is a lot easier on the eyes in BB than AA.\nHere, you can (and should) set a root password, as well as setup SSH access (which we\u0026rsquo;ll need later). Press Save \u0026amp;¬†Apply to continue.\nLook for Password successfully changed! at the top of the screen.\nVerify SSH access by using PuTTY or another SSH client.\n[logan@Arch ~]$ ssh root@192.168.1.1 root@192.168.1.1\u0026#39;s password: BusyBox v1.22.1 (2014-09-20 22:01:35 CEST) built-in shell (ash) Enter \u0026#39;help\u0026#39; for a list of built-in commands. _______ ________ __ | |.-----.-----.-----.| | | |.----.| |_ | - || _ | -__| || | | || _|| _| |_______|| __|_____|__|__||________||__| |____| |__| W I R E L E S S F R E E D O M ----------------------------------------------------- BARRIER BREAKER (14.07, r42625) ----------------------------------------------------- * 1/2 oz Galliano Pour all ingredients into * 4 oz cold Coffee an irish coffee mug filled * 1 1/2 oz Dark Rum with crushed ice. Stir. * 2 tsp. Creme de Cacao ----------------------------------------------------- root@OpenWrt:~# Setup NTP The MR3020 doesn\u0026rsquo;t have a real-time clock or CMOS battery. Because of this, every time it loses power, the clock resets to October 1st. To circumvent this, we\u0026rsquo;re going to use NTP to get our time from the internet. You don\u0026rsquo;t have to setup NTP, but it makes troubleshooting easier when you\u0026rsquo;re looking at timestamped log files. Keep in mind, since the MR3020 is connected directly to your PC (not the internet), this won\u0026rsquo;t take effect until after we get it online. Don\u0026rsquo;t freak out if it\u0026rsquo;s not working right away.\nFirst, set a hostname, zone name, and time zone for your router. The list of zone names/time zones can be found here. Make note of the tick marks around the zonename.\nuci set system.@system[0].hostname=mr3020_home uci set system.@system[0].zonename=\u0026#39;America/New York\u0026#39; uci set system.@system[0].timezone=EST5EDT,M3.2.0,M11.1.0 uci commit system Next, we\u0026rsquo;re going to enable the NTP client.¬†I\u0026rsquo;m using US servers from the NTP Pool Project, but change your servers as needed. Again, don\u0026rsquo;t forget the tick marks.\nuci set system.ntp=timeserver uci set system.ntp.enabled=1 uci delete system.ntp.server uci add_list system.ntp.server=\u0026#39;0.us.pool.ntp.org\u0026#39; uci add_list system.ntp.server=\u0026#39;1.us.pool.ntp.org\u0026#39; uci add_list system.ntp.server=\u0026#39;2.us.pool.ntp.org\u0026#39; uci add_list system.ntp.server=\u0026#39;3.us.pool.ntp.org\u0026#39; uci commit system Set default IP Next, we\u0026rsquo;re going to change the default IP of the router from 192.168.1.1 to 10.80.1.1 (or whatever scheme you want). Most devices ship with 192.168.1.1 as the default, and since we\u0026rsquo;re going to be double-NATed, we can\u0026rsquo;t have two identical IPs on the same network.\nuci set network.lan.ipaddr=10.80.1.1 uci commit network You can also limit the number of addresses available in the DHCP pool (optional).\nuci set dhcp.lan.start=10 uci set dhcp.lan.limit=20 uci commit dhcp /etc/init.d/network restart Log back into the web interface at the new address using your new¬†root password.\nCreate wireless network We need to create a wireless network for the MR3020 to broadcast. Eventually, we\u0026rsquo;re going to turn off LAN access on the Ethernet port, and we\u0026rsquo;ll need a way to connect to the router locally.\nStart by enabling wireless. At this point, you should be able to see the default OpenWrt network from a device.\nuci delete wireless.radio0.disabled uci commit wireless /etc/init.d/network restart Once enabled, setup your network as needed (name, channel, etc\u0026hellip;).\nuci set wireless.radio0.channel=11 uci set wireless.radio0.txpower=18 uci set wireless.radio0.country=US uci set wireless.@wifi-iface[0].ssid=\u0026#39;Aw yiss\u0026#39; uci commit wireless You should secure your network and choose a strong password (preferably WPA2-PSK with AES). Remember, this device may be a direct link back to your home network. Even if you have a strong VPN password, a weak WiFi password with weak encryption (e.g., WEP) could compromise your network.\nuci set wireless.@wifi-iface[0].encryption=\u0026#39;psk2+ccmp\u0026#39; uci set wireless.@wifi-iface[0].key=\u0026#39;wirelesspasswordgoeshere\u0026#39; uci commit wireless /etc/init.d/network restart At this point, you should disconnect the Ethernet cable from the MR3020 and connect to the WiFi network we just setup. Normally, it\u0026rsquo;s not recommended to configure routers over wireless, but since we\u0026rsquo;re not going to be transferring files or upgrading firmware, we should be ok.\nSetup WAN interface We need the MR3020 to request an IP address from another router when it is plugged in. For this, we\u0026rsquo;ll need to make a new interface that will act as a DHCP client. Name the interface something like WAN, with the protocol being set to DHCP client, covering the eth0 interface.\nuci set network.WAN=interface uci set network.WAN.proto=dhcp uci set network.WAN.ifname=eth0 uci commit network On the next screen, under Common Configuration, go to the Firewall Settings tab and select WAN. Press Save \u0026amp; Apply to continue.\nuci set firewall.@zone[1].network=\u0026#39;wan wan6 WAN\u0026#39; uci commit firewall /etc/init.d/network restart /etc/init.d/firewall restart Unbridge LAN interfaces By default, the wired and wireless interfaces are bridged. I want them to be separate, so that I can plug the wired interface into another router and use the wireless interface to broadcast a network. Essentially, I making it so that only another router can use the Ethernet port, and only clients can use the wireless network.\nuci delete network.lan.ifname uci delete network.lan.type uci commit network /etc/init.d/network restart If you don\u0026rsquo;t unbridge the interfaces, you\u0026rsquo;ve basically just created a wireless AP for the other router.\nVerify internet access At this point, plug your MR3020 into a LAN port on your other router, and connect your PC to the MR3020\u0026rsquo;s wireless network. It doesn\u0026rsquo;t matter what IP your MR3020 gets from the other router, as your PC should see the MR3020 as 10.80.1.1 (or whatever your made it).\nYou should be able to access the internet, as well as ping websites through SSH.¬†In addition, go to the Status¬†dropdown, then select Overview¬†to make sure your Local Time field is updated with the correct time, now that we\u0026rsquo;re on the internet.\nCongratulations, you are now double-NATed.\nConfigure extroot Before we get started, we need to make some space¬†for OpenVPN. The MR3020 only has 4MB of flash. After OpenWrt is installed, we\u0026rsquo;re only left with about 400KB, which won\u0026rsquo;t be enough for the 600KB+ of OpenSSL libraries we\u0026rsquo;ll need, in addition to other packages that will make life easier.\nroot@OpenWrt:~# df -h Filesystem Size Used Available Use% Mounted on rootfs 640.0K 228.0K 412.0K 36% / /dev/root 2.3M 2.3M 0 100% /rom tmpfs 14.1M 448.0K 13.7M 3% /tmp /dev/mtdblock3 640.0K 228.0K 412.0K 36% /overlay overlayfs:/overlay 640.0K 228.0K 412.0K 36% / tmpfs 512.0K 0 512.0K 0% /dev There are two ways around this:\nExtRoot, which can either extend or move the root filesystem to a USB flash drive Build a custom image of OpenWrt from scratch, leaving out unnecessary packages My first instinct was to build a custom image, leaving out PPP. However, after a few hours of trying and multiple images, it still didn\u0026rsquo;t give me the space I needed. The only way to get OpenVPN on the MR3020 would be to leave LuCI out of the image, and I\u0026rsquo;m not¬†willing to give that up.\nThat leaves me with using a USB flash drive to extend or move the filesystem.¬†Thankfully, setting up ExtRoot is pretty easy, and we won\u0026rsquo;t¬†need a huge flash drive since we\u0026rsquo;re only after a few extra MB. I picked up this¬†flash drive¬†since it\u0026rsquo;s small.\nStart by reading the theory on ExtRoot, then go over the how-to guide. You need to decide whether you\u0026rsquo;ll be using external overlay (also called pivot-overlay) or external root (also called pivot-root). Essentially, external overlay extends the root filesystem to include the flash drive, while external root copies the root filesystem to the flash drive, then boots from the flash drive. External root has a couple advantages (that I can see):\nYou can boot from multiple flash drives, each with a different config (one flash drive with a config for home, another with a config for traveling, etc\u0026hellip;) If the flash drive dies, OpenWrt still boots from the internal root filesystem (without all your configs) In this guide, I\u0026rsquo;m going to be using external¬†root.\nSince my flash drive is 8GB, I\u0026rsquo;m going to give 1GB to OpenWrt and use the rest for a SAMBA share. Any device connected to my router will have access to the other ~6.5GB share. Get stared by formatting your flash drive with two ext4 partitions. I did this on my machine using GParted, but if you\u0026rsquo;re running Windows you can use this¬†to format the drive. In this case, /dev/sda1 is 1GB and /dev/sda2 is the remaining ~6.5GB.\nNext, SSH into your router, and install a few packages. You\u0026rsquo;ll need to install the kmod-fs package for the type of filesystem that you\u0026rsquo;re using (e.g., kmod-fs-ext4, kmod-fs-ext3, kmod-fs-btrfs, etc\u0026hellip;)\nopkg update opkg install block-mount kmod-usb-storage kmod-fs-ext4 There\u0026rsquo;s a good chance your kernel modules didn\u0026rsquo;t load. If that\u0026rsquo;s the case, reboot your router¬†and then plug in your flash drive.\nkmod: failed to insert /lib/modules/3.10.49/sd_mod.ko Configuring kmod-usb-storage. Configuring kmod-crypto-hash. Configuring kmod-lib-crc16. Configuring block-mount. Configuring kmod-fs-ext4. kmod: failed to insert /lib/modules/3.10.49/ext4.ko Find the name of your flash drive with the block info command. Mine was /dev/sda. Notice there are two partitions on the drive.\nroot@mr3020_home:~# block info /dev/mtdblock2: UUID=\u0026#34;20ad40ea-d33a421e-785b7d2d-ada99230\u0026#34; VERSION=\u0026#34;4.0\u0026#34; TYPE=\u0026#34;squashfs\u0026#34; /dev/mtdblock3: TYPE=\u0026#34;jffs2\u0026#34; /dev/sda1: UUID=\u0026#34;bf19ec66-8d6a-40d7-b366-f99f48cced33\u0026#34; NAME=\u0026#34;EXT_JOURNAL\u0026#34; VERSION=\u0026#34;1.0\u0026#34; TYPE=\u0026#34;ext4\u0026#34; /dev/sda2: UUID=\u0026#34;5ca298db-53d6-406c-9db3-344c2e5ebae8\u0026#34; NAME=\u0026#34;EXT_JOURNAL\u0026#34; VERSION=\u0026#34;1.0\u0026#34; TYPE=\u0026#34;ext4\u0026#34; Create two directories and mount /dev/sda1 and /dev/sda2 on them.\nmkdir /mnt/batman mount /dev/sda1 /mnt/batman mkdir /mnt/network chmod -R 777 /mnt/network mount /dev/sda2 /mnt/network Now, copy the router\u0026rsquo;s internal flash to the flash drive. Obviously, replace /mnt/batman¬†with whatever mount point you\u0026rsquo;re using.\nmkdir -p /tmp/cproot mount --bind / /tmp/cproot tar -C /tmp/cproot -cvf - . | tar -C /mnt/batman -xf - umount /tmp/cproot Your flash drive now has a copy of the router\u0026rsquo;s root filesystem on it (so don\u0026rsquo;t lose it). However, the router will still boot from its internal memory, so we need to change that by editing the /etc/config/fstab file. In addition to that, we\u0026rsquo;re also creating an extra entry for our SAMBA fileshare.\ncat \u0026gt;\u0026gt; /etc/config/fstab \u0026lt;\u0026lt; EOF config \u0026#39;mount\u0026#39; option target / option device /dev/sda1 option fstype ext4 option options rw,sync option enabled 1 option enabled_fsck 0 config \u0026#39;mount\u0026#39; option target /mnt/network option device /dev/sda2 option fstype ext4 option options rw,sync option enabled 1 option enabled_fsck 1 EOF Reboot your router. When it starts up, check your mount points and you should see that /dev/sda1 has been mounted on /, while /dev/sda2 has been mounted on /mnt/network.\nroot@mr3020_home:~# mount rootfs on / type rootfs (rw) /dev/root on /rom type squashfs (ro,noatime) proc on /proc type proc (rw,noatime) sysfs on /sys type sysfs (rw,noatime) tmpfs on /tmp type tmpfs (rw,nosuid,nodev,noatime) /dev/sda1 on / type ext4 (rw,relatime,data=ordered) tmpfs on /dev type tmpfs (rw,relatime,size=512k,mode=755) devpts on /dev/pts type devpts (rw,relatime,mode=600) /dev/sda2 on /mnt/network type ext4 (rw,sync,relatime,data=ordered) debugfs on /sys/kernel/debug type debugfs (rw,noatime) If you check your space again, you\u0026rsquo;ll see that your root filesystem is now larger, and you have a second partition for SAMBA.\nroot@mr3020_home:~# df -h Filesystem Size Used Available Use% Mounted on rootfs 975.9M 10.5M 898.2M 1% / /dev/root 2.3M 2.3M 0 100% /rom tmpfs 14.1M 360.0K 13.7M 2% /tmp /dev/sda1 975.9M 10.5M 898.2M 1% / tmpfs 512.0K 0 512.0K 0% /dev /dev/sda2 6.2G 14.5M 5.9G 0% /mnt/network Setup VPN Now we need to install the OpenVPN client and configure it. The¬†VPN termination point is going to be one of PIA\u0026rsquo;s¬†servers, but it could be any OpenVPN server.¬†You should read OpenWrt\u0026rsquo;s VPN overview, as well the OpenVPN beginner\u0026rsquo;s guide¬†and the¬†client guide.\nFirst, we\u0026rsquo;ll need to install a couple packages: openvpn-openssl¬†for obvious reasons, the real version of wget to downlad the configuration files from PIA, and unzip to unzip the downloaded files. This is easiest done by connecting through SSH and running the commands below.\nopkg update opkg install openvpn-openssl wget unzip mv /etc/config/openvpn /etc/config/openvpn_old Unfortunately, there is no LuCI package for OpenVPN in BB, like there is in AA. As-of this writing, the package luci-app-openvpn is marked as broken. There appears to be a package for Chaos Calmer, located here, but I don\u0026rsquo;t think that will work in BB. That means we\u0026rsquo;re doing everything from the command line, which isn\u0026rsquo;t as intimidating as it may sound. Plus, since LuCI runs from the UCI files, we\u0026rsquo;ll be able to see some of our changes in LuCI when we log back in.\nWe\u0026rsquo;ll need to create a new interface for the VPN by using the commands below. Name the network interface whatever you\u0026rsquo;d like, and name the physical (even though it\u0026rsquo;s virtual) interface tun0.\ncat \u0026gt;\u0026gt; /etc/config/network \u0026lt;\u0026lt; EOF config interface \u0026#39;PIA_VPN\u0026#39; option proto \u0026#39;none\u0026#39; option ifname \u0026#39;tun0\u0026#39; EOF /etc/init.d/network restart Download the OpenVPN configuration files from PIA.\ncd /etc/openvpn wget --no-check-certificate https://www.privateinternetaccess.com/openvpn/openvpn.zip unzip openvpn.zip rm openvpn.zip Now, we need to edit each .ovpn file in /etc/openvpn¬†to include your username and password. However, it‚Äôs a pain editing every file manually. Instead, we\u0026rsquo;ll create a single file that stores your login credentials.¬†The file I created is called authuser. Substitute your username and password, obviously.\ncat \u0026gt;\u0026gt; /etc/openvpn/authuser \u0026lt;\u0026lt; EOF PIA_USERNAME PIA_PASSWORD EOF However, now we\u0026rsquo;ll have to go back and edit each .ovpn file to look for the authuser file, which is still too much work for me. If you look at each .ovpn file, you\u0026rsquo;ll see the only difference between them is the server address. What if we created a generic .ovpn¬†connection file which omitted the server address (and port), but specified to use the authuser file? We could pass the server address and port as an option in¬†our command to start the VPN connection.\nCreate the file with the command below. See how we removed the line for the server/port, and added a line for the authuser file and auth-nocache options?\ncat \u0026gt;\u0026gt; /etc/openvpn/piageneric.ovpn \u0026lt;\u0026lt; EOF client dev tun proto udp resolv-retry infinite nobind persist-key persist-tun ca ca.crt tls-client remote-cert-tls server auth-user-pass authuser auth-nocache comp-lzo verb 1 reneg-sec 0 crl-verify crl.pem keepalive 10 120 EOF To compare, this is the US East.ovpn file\u0026hellip;\nclient dev tun proto udp remote us-east.privateinternetaccess.com 1194 resolv-retry infinite nobind persist-key persist-tun ca ca.crt tls-client remote-cert-tls server auth-user-pass comp-lzo verb 1 reneg-sec 0 crl-verify crl.pem Now, we need to create a new firewall zone for this VPN connection. This is actually the same config as the WAN zone, but it\u0026rsquo;s easier to make a new zone in case we need to change anything in the future. Name the firewall zone, and substitute the network interface name you created above. We\u0026rsquo;ll also be forwarding LAN traffic to the VPN.\ncat \u0026gt;\u0026gt; /etc/config/firewall \u0026lt;\u0026lt; EOF config zone option name \u0026#39;VPN_FW\u0026#39; option input \u0026#39;REJECT\u0026#39; option output \u0026#39;ACCEPT\u0026#39; option forward \u0026#39;REJECT\u0026#39; option masq \u0026#39;1\u0026#39; option mtu_fix \u0026#39;1\u0026#39; option network \u0026#39;PIA_VPN\u0026#39; config forwarding option dest \u0026#39;VPN_FW\u0026#39; option src \u0026#39;lan\u0026#39; EOF /etc/init.d/network restart /etc/init.d/firewall restart If you\u0026rsquo;d like, you can login to LuCI and see the new network interface, physical interface tun0, and firewall zone. Back on the command line, use the following command to start the VPN. Specify your generic configuration file and choose a¬†server¬†from PIA, as well as a port number.\nopenvpn --cd /etc/openvpn --config /etc/openvpn/piageneric.ovpn --remote us-east.privateinternetaccess.com 1194 If everything went well, you should see something like below, ending in Initialization Sequence Completed. If not, you did something wrong. Check your logs and start looking¬†here.\nroot@mr3020_home:~# openvpn --cd /etc/openvpn --config /etc/openvpn/piag eneric.ovpn --remote us-east.privateinternetaccess.com 1194 Sat Jan 24 13:16:20 2015 OpenVPN 2.3.6 mips-openwrt-linux-gnu [SSL (OpenSSL)] [LZO] [EPOLL] [MH] [IPv6] built on Jan 6 2015 Sat Jan 24 13:16:20 2015 library versions: OpenSSL 1.0.1k 8 Jan 2015, LZO 2.08 Sat Jan 24 13:16:20 2015 WARNING: file \u0026#39;authuser\u0026#39; is group or others accessible Sat Jan 24 13:16:20 2015 UDPv4 link local: [undef] Sat Jan 24 13:16:20 2015 UDPv4 link remote: [AF_INET]64.237.51.174:1194 Sat Jan 24 13:16:21 2015 [Private Internet Access] Peer Connection Initiated with [AF_INET]64.237.51.174:1194 Sat Jan 24 13:16:24 2015 TUN/TAP device tun0 opened Sat Jan 24 13:16:24 2015 do_ifconfig, tt-\u0026gt;ipv6=0, tt-\u0026gt;did_ifconfig_ipv6_setup=0 Sat Jan 24 13:16:24 2015 /sbin/ifconfig tun0 10.121.1.6 pointopoint 10.121.1.5 mtu 1500 Sat Jan 24 13:16:24 2015 Initialization Sequence Completed Check ifconfig to see if you have a tunnel interface. If you do, that\u0026rsquo;s good!\ntun0 Link encap:UNSPEC HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 inet addr:10.121.1.6 P-t-P:10.121.1.5 Mask:255.255.255.255 UP POINTOPOINT RUNNING NOARP MULTICAST MTU:1500 Metric:1 RX packets:78 errors:0 dropped:0 overruns:0 frame:0 TX packets:102 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:100 RX bytes:10371 (10.1 KiB) TX bytes:83342 (81.3 KiB) Next, try to get on the internet. If you can\u0026rsquo;t, there\u0026rsquo;s a good chance it\u0026rsquo;s a DNS issue. To resolve this, we\u0026rsquo;ll set our DNS servers on this connection to use PIA\u0026rsquo;s DNS servers. It looks like we can set the DNS servers for a specific interface, so we\u0026rsquo;ll add them for the¬†LAN¬†interface.\nuci add_list dhcp.lan.dhcp_option=\u0026#34;6,209.222.18.222,209.222.18.218\u0026#34; uci commit dhcp /etc/init.d/network restart Now we should have DNS working, and since we\u0026rsquo;re using PIA VPN and PIA DNS servers, we shouldn\u0026rsquo;t have any DNS leaks either. After all, what\u0026rsquo;s the point of a VPN if your DNS leaks?\nRestart your VPN connection and try it again!¬†Check your IP with an external tool, like WhatIsMyIP, both on your local wireless network, as well as the OpenWrt network. You should see the difference, meaning you are successfully connected!\nBefore (on my local network)\u0026hellip;\nAfter (VPNed in)\u0026hellip;\nNow is a good time to¬†check for DNS leaks while on the VPN. Basically, we\u0026rsquo;re looking to make sure the server giving us our IP address is also providing DNS. If it\u0026rsquo;s not, then your ISP probably providing DNS, and they\u0026rsquo;re able to see every DNS request you make.\nNote - Commenter Ben found that his DNS was still leaking when set on the LAN interface. He suggested setting it on the WAN interface, as seen in the comments.\nRun at startup If you\u0026rsquo;d like your VPN connection to run at startup, edit the¬†/etc/rc.local file. Paste your connection string before exit 0. The ampersand tells OpenWrt not to output anything to the screen.\nBefore\u0026hellip;\n# Put your custom commands here that should be executed once # the system init finished. By default this file does nothing. exit 0 After\u0026hellip;\n# Put your custom commands here that should be executed once # the system init finished. By default this file does nothing. openvpn --cd /etc/openvpn --config /etc/openvpn/piageneric.ovpn --remote us-east.privateinternetaccess.com 1194 \u0026amp; exit 0 Setup SAMBA Next, we need to setup the SAMBA share by installing the SAMBA packages. You\u0026rsquo;ll need to search opkg for the correct version of SAMBA server.\nopkg update opkg list | grep -i samba opkg install luci-app-samba samba36-server /etc/init.d/samba enable /etc/init.d/samba start rm /tmp/luci-indexcache Following the last step of this guide (thanks to commenter Ben for sending this in!), go to the Services¬†dropdown, then select¬†Network Shares.¬†Under Samba, select a hostname.\nThen, under Shared Directories, select Add. Here, specify a share name and path (in our case, /mnt/network), and select Allow guests. If you don\u0026rsquo;t want guest access, you\u0026rsquo;ll need to setup users as described here. Press Save \u0026amp; Apply to continue.\nConnect to your router\u0026rsquo;s wireless network, then, in your file manager (assuming you\u0026rsquo;re using Linux, since this is a ext4 SAMBA share), navigate to your share name (e.g., smb://openwrt/box/).\nNote - Your distro may not have a SAMBA client installed. On Arch Linux, I needed the smbclient and¬†gvfs-smb packages.\nSetup alerting scripts The whole point of this build was to create a connection that is always on and safe for you to use. But, what if the VPN tunnel goes down? You\u0026rsquo;d still be able to pass traffic, but it would be over the regular internet, not the encrypted VPN connection. There are a couple ways around this, including putting a route in that denies traffic when not on the VPN, as well as setting up alerting scripts to let you know when the tunnel goes down. Here, I\u0026rsquo;ll be doing the latter.\nOn the¬†The OpenVPN 2.3 man page, there are options called --up and --down, which as they sound, run scripts when the VPN tunnel comes up or goes down. Basically, we\u0026rsquo;re going to create a script to email us when the tunnel comes up, and another script that will run when the tunnel goes down, but we still have internet access. Obviously, if the tunnel goes down as a result of the router being powered off or the WAN connection dying, the email isn\u0026rsquo;t going to work. We\u0026rsquo;re also going to implement a third script that will run out of root\u0026rsquo;s crontab to check for VPN connection status every 10 minutes.\nSetup email First, we need to install msmtp.\nopkg update opkg install msmtp If it\u0026rsquo;s not set already, you need to set the msmtp config file to be R/W for your account only. It won\u0026rsquo;t function otherwise.\nchmod 600 /etc/msmtprc cp -p /etc/msmtprc /etc/msmtprc_old We need an external STMP server that we can use to route messages through. Luckily, Google provides one for free if you have a Gmail account.¬†Obviously, I would advise against using your primary Gmail account for this. Setting up a dedicated Gmail account just for this application only takes a few minutes and is worth it, in my opinion. Google\u0026rsquo;s SMTP settings are here, we\u0026rsquo;ll¬†need them later.\nNext, we\u0026rsquo;re going to edit the config file at /etc/msmtprc to include our information. There is some pretty good documentation for msmtp over at SourceForge, so I won\u0026rsquo;t bother going over all the options below. Substitute your new Gmail username and password below.\nBefore\u0026hellip;\n# Example for a system wide configuration file # A system wide configuration file is optional. # If it exists, it usually defines a default account. # This allows msmtp to be used like /usr/sbin/sendmail. account default # The SMTP smarthost. host mailhub.oursite.example # Construct envelope-from addresses of the form \u0026#34;user@oursite.example\u0026#34;. #auto_from on #maildomain oursite.example # Use TLS. #tls on #tls_trust_file /etc/ssl/certs/ca-certificates.crt # Syslog logging with facility LOG_MAIL instead of the default LOG_USER. syslog LOG_MAIL After\u0026hellip;\naccount default tls on tls_certcheck off logfile /etc/openvpn/msmtp.log auto_from on auth on host smtp.gmail.com protocol smtp port 587 user your_gmail_address@gmail.com password your_gmail_password syslog LOG_MAIL Next, create three¬†scripts in your /etc/openvpn folder and set permissions on them.\ntouch /etc/openvpn/vpndown.sh touch /etc/openvpn/vpnup.sh touch /etc/openvpn/vpncheck.sh chmod 700 /etc/openvpn/vpndown.sh chmod 700 /etc/openvpn/vpnup.sh chmod 700 /etc/openvpn/vpncheck.sh vpndown.sh The only difference between the vpnup.sh script and¬†vpndown.sh script are the words UP and DOWN in the STATUS variable in each script. Replace your recipients as needed.\n#!/bin/ash #2015-01-24 #Logan Marchione STATUS=DOWN HOSTNAME=`uci get system.@system[0].hostname` RECIPIENT=\u0026#34;recipient@address.com\u0026#34; DAY=`date \u0026#34;+%A\u0026#34;` DATE=`date \u0026#34;+%Y-%m-%d\u0026#34;` TIME=`date \u0026#34;+%H:%M:%S\u0026#34;` EMAIL=\u0026#39;Subject: VPN \u0026#39;$STATUS\u0026#39; on \u0026#39;$HOSTNAME\u0026#39; From: OpenWrt Monitor As of \u0026#39;$DAY\u0026#39;, \u0026#39;$DATE\u0026#39; at \u0026#39;$TIME\u0026#39; the VPN tunnel on \u0026#39;$HOSTNAME\u0026#39; is \u0026#39;$STATUS\u0026#39;.\u0026#39; echo \u0026#34;$EMAIL\u0026#34; | msmtp -t $RECIPIENT vpnup.sh The only difference between the vpnup.sh script and¬†vpndown.sh script are the words UP and DOWN in the STATUS variable in each script. Replace your recipients as needed.\n#!/bin/ash #2015-01-24 #Logan Marchione STATUS=UP HOSTNAME=`uci get system.@system[0].hostname` RECIPIENT=\u0026#34;recipient@address.com\u0026#34; DAY=`date \u0026#34;+%A\u0026#34;` DATE=`date \u0026#34;+%Y-%m-%d\u0026#34;` TIME=`date \u0026#34;+%H:%M:%S\u0026#34;` EMAIL=\u0026#39;Subject: VPN \u0026#39;$STATUS\u0026#39; on \u0026#39;$HOSTNAME\u0026#39; From: OpenWrt Monitor As of \u0026#39;$DAY\u0026#39;, \u0026#39;$DATE\u0026#39; at \u0026#39;$TIME\u0026#39; the VPN tunnel on \u0026#39;$HOSTNAME\u0026#39; is \u0026#39;$STATUS\u0026#39;.\u0026#39; echo \u0026#34;$EMAIL\u0026#34; | msmtp -t $RECIPIENT Now, edit the /etc/openvpn/piageneric.ovpn file. Here, we\u0026rsquo;ve added the up and down options and specified the appropriate scripts. We\u0026rsquo;ve also added the up-restart option, which allows¬†scripts to be called for restarts as well as initial program start. Finally, I\u0026rsquo;ve set script-security level to 2, which allows¬†calling of built-in executables and user-defined scripts.\nclient dev tun proto udp resolv-retry infinite nobind persist-key persist-tun ca ca.crt tls-client remote-cert-tls server auth-user-pass authuser auth-nocache comp-lzo verb 1 up vpnup.sh down vpndown.sh script-security 2 up-restart reneg-sec 0 crl-verify crl.pem keepalive 10 120 vpncheck.sh This script calls ifconfig and looks for an adapter called tun0. If your adapter name is different, replace it as needed. Replace the line that¬†starts the VPN manually (the same command we used earlier) with your connection string.\n#!/bin/ash #2015-01-24 #Logan Marchione RESULT=`ifconfig | awk \u0026#39;/^tun0/ {print $1;}\u0026#39;` DATETIME=`date \u0026#34;+%Y-%m-%d %H:%M:%S\u0026#34;` if [ \u0026#34;$RESULT\u0026#34; == tun0 ] then echo \u0026#34;$DATETIME - No restart needed\u0026#34; \u0026gt;\u0026gt; vpncheck.log\u0026amp; else echo \u0026#34;$DATETIME - Restart needed, see below\u0026#34; \u0026gt;\u0026gt; vpncheck.log\u0026amp; openvpn --cd /etc/openvpn --config piageneric.ovpn --remote us-east.privateinternetaccess.com 1194 \u0026gt;\u0026gt; vpncheck.log\u0026amp; fi The vpncheck.sh script will need to run on a schedule, and for that, we\u0026rsquo;ll be using cron. First, we need to make a file for root\u0026rsquo;s crontab and then start crontab.\ntouch /etc/crontabs/root /etc/init.d/cron start /etc/init.d/cron enable If you check logs\u0026hellip;\nlogread \u0026hellip;you should see that cron was started.\nSat Jan 24 14:17:04 2015 cron.info crond[1526]: crond: crond (busybox 1.22.1) started, log level 5 Then, add your entry to crontab. Use the schedule below to setup your job.\n#Crontab Schedule # +---------------- minute (0 - 59) *=all # | +------------- hour (0 - 23) *=all # | | +---------- day of month (1 - 31) *=all # | | | +------- month (1 - 12) *=all # | | | | +---- day of week (0 - 6) (Sunday=0) *=all # | | | | | # * * * * * command to be executed # -- -- -- -- - --------------------------------- # 00 12 * * * some_command # will run some_command at 12:00 (noon) daily #Run VPN check to check for tunnel up/down 10 * * * * /etc/openvpn/vpncheck.sh \u0026gt; /etc/openvpn/vpncheck.log Finally, restart cron for the changes to take effect.\n/etc/init.d/cron restart Once everything is updated, reboot your MR3020 one final time.\nTest alerting scripts vpndown.sh Assuming your VPN is already up, use ps | grep openvpn to find¬†and kill¬†the OpenVPN¬†process ID.\nroot@mr3020_home:~# ps | grep openvpn 911 root 3436 S openvpn --cd /etc/openvpn --config /etc/openvpn/piageneric.ovpn --remote us-east.privateinternetaccess.com 1194 root@mr3020_home:~# kill 911 root@mr3020_home:~# ps | grep openvpn 1380 root 1356 S grep openvpn After you kill it, grep again and you should see that OpenVPN isn\u0026rsquo;t running. In a minute or so, you should you get an email alerting you that the VPN tunnel is down.\nvpnup.sh Now, start the VPN manually (using the same command we used earlier¬†to test).\nopenvpn --cd /etc/openvpn --config /etc/openvpn/piageneric.ovpn --remote us-east.privateinternetaccess.com 1194 \u0026amp; Here, you\u0026rsquo;ll see the output from OpenVPN starting, and you should see the script vpnup.sh running.\nroot@mr3020_home:~# openvpn --cd /etc/openvpn --config /etc/openvpn/piag eneric.ovpn --remote us-east.privateinternetaccess.com 1194 \u0026amp; root@mr3020_home:~# Sat Jan 24 13:56:03 2015 OpenVPN 2.3.6 mips-openwrt-linux-gnu [SSL (OpenSSL)] [LZO] [EPOLL] [MH] [IPv6] built on Jan 6 2015 Sat Jan 24 13:56:03 2015 library versions: OpenSSL 1.0.1k 8 Jan 2015, LZO 2.08 Sat Jan 24 13:56:03 2015 WARNING: file \u0026#39;authuser\u0026#39; is group or others accessible Sat Jan 24 13:56:03 2015 NOTE: the current --script-security setting may allow this configuration to call user-defined scripts Sat Jan 24 13:56:03 2015 UDPv4 link local: [undef] Sat Jan 24 13:56:03 2015 UDPv4 link remote: [AF_INET]64.237.52.133:1194 Sat Jan 24 13:56:05 2015 [Private Internet Access] Peer Connection Initiated with [AF_INET]64.237.52.133:1194 Sat Jan 24 13:56:08 2015 TUN/TAP device tun0 opened Sat Jan 24 13:56:08 2015 do_ifconfig, tt-\u0026gt;ipv6=0, tt-\u0026gt;did_ifconfig_ipv6_setup=0 Sat Jan 24 13:56:08 2015 /sbin/ifconfig tun0 10.150.1.10 pointopoint 10.150.1.9 mtu 1500 Sat Jan 24 13:56:08 2015 vpnup.sh tun0 1500 1542 10.150.1.10 10.150.1.9 init Sat Jan 24 13:56:12 2015 Initialization Sequence Completed Again, in a minute or so, you should you get an email alerting you that the VPN tunnel is up.\nvpncheck.sh This is easy to test. Kill your OpenVPN process and wait until the vpncheck.sh script runs out of crontab. Then, you should see your tunnel come back up and get an email about it.\nExtras Backup your config You did all this work, don\u0026rsquo;t lose it. Go to the System¬†dropdown, then select¬†Backup/Flash Firmware¬†and press Generate Archive to download a backup of all your configuration files. I don\u0026rsquo;t believe this backs up custom scripts/files, so keep that in mind.\nFailsafe mode At some point during this build, you\u0026rsquo;ll probably break something and lock yourself out of your router. Thankfully, you\u0026rsquo;re not left with a paper-weight. OpenWrt includes a failsafe mode that will let you telnet to your router. Steps for the MR3020 are below.\nPower off your MR3020 and connect it to your PC via Ethernet Set your PC\u0026rsquo;s IP to 192.168.1.2 with a subnet of 255.255.255.0 and a gatway of 192.168.1.1 Plug in the power to the MR3020 When the WPS button starts to flash, slide the switch labeled 3G/4G/WISP/AP back and forth really fast. At this point, the WPS button will start¬†blinking faster than it was before. You are in failsafe mode. Connect to the router via telnet and you should see that you are in failsafe mode. logan@fedora20 ~$ telnet 192.168.1.1 Trying 192.168.1.1... Connected to 192.168.1.1. Escape character is \u0026#39;^]\u0026#39;. === IMPORTANT ============================ Use \u0026#39;passwd\u0026#39; to set your login password this will disable telnet and enable SSH ------------------------------------------ BusyBox v1.22.1 (2014-09-20 22:01:35 CEST) built-in shell (ash) Enter \u0026#39;help\u0026#39; for a list of built-in commands. _______ ________ __ | |.-----.-----.-----.| | | |.----.| |_ | - || _ | -__| || | | || _|| _| |_______|| __|_____|__|__||________||__| |____| |__| W I R E L E S S F R E E D O M ----------------------------------------------------- BARRIER BREAKER (14.07, r42625) ----------------------------------------------------- * 1/2 oz Galliano Pour all ingredients into * 4 oz cold Coffee an irish coffee mug filled * 1 1/2 oz Dark Rum with crushed ice. Stir. * 2 tsp. Creme de Cacao ----------------------------------------------------- Now, you should be able to change your password by entering passwd, but you may get an error about the filesystem being read-only, like below. passwd: /etc/passwd: Read-only file system passwd: can\u0026#39;t update password file /etc/passwd If that happens, enter mount_root, then try the passwd command again. At this point, you should be able to SSH into the MR3020.\nIf you installed too many packages and filled up the filesystem, you can wipe it and do a factory reset with the command below.\nfirstboot Reboot the router, as below. reboot -f Try to SSH in. If it doesn\u0026rsquo;t work (mine didn\u0026rsquo;t), telnet in again, set your password again, and then try SSH again.\nIf you want to transfer a new firmware file to the router, you can do that with the SCP utility on your PC.\nscp /path/to/file.bin root@192.168.1.1:/path/to/file.bin Then, flash the new firmware file with the command below. sysupgrade -v /path/to/file.bin HTTPS Support Out of the box, LuCI does not support HTTPS. For that, you\u0026rsquo;ll need a couple packages.\nopkg update opkg install luci-ssl uhttpd-mod-tls First, backup the original /etc/config/uhttpd file.¬†Then, edit the file to change your certificate settings¬†as needed.\ncp -p /etc/config/uhttpd /etc/config/uhttpd_old vi /etc/config/uhttpd Before\u0026hellip;\nconfig cert \u0026#39;px5g\u0026#39; option days \u0026#39;730\u0026#39; option bits \u0026#39;1024\u0026#39; option country \u0026#39;DE\u0026#39; option state \u0026#39;Berlin\u0026#39; option location \u0026#39;Berlin\u0026#39; option commonname \u0026#39;OpenWrt\u0026#39; After\u0026hellip;\nconfig cert \u0026#39;px5g\u0026#39; option days \u0026#39;730\u0026#39; option bits \u0026#39;2048\u0026#39; option country \u0026#39;US\u0026#39; option state \u0026#39;Pennsylvania\u0026#39; option location \u0026#39;Pennsylvania\u0026#39; option commonname \u0026#39;10.80.1.1\u0026#39; Once you have your certificate setup, restart the webserver.\n/etc/init.d/uhttpd restart You should see a message similar to¬†the one below.\nGenerating RSA private key, 2048 bit long modulus Generating selfsigned certificate with subject \u0026#39;C=US;ST=Pennsylvania;L=Pennsylvania;CN=10.80.1.1;\u0026#39; and validity 20141021000526-20161020000526 If you navigate to /etc, you should see a certificate and a key file.\n-rw-r--r-- 1 root root 828 Oct 20 20:50 /etc/uhttpd.crt -rw-r--r-- 1 root root 1192 Oct 20 20:50 /etc/uhttpd.key Open your browser, and instead of going to http://10.80.1.1, go to https://10.80.1.1.¬†If you get a scary looking error message, that\u0026rsquo;s ok. Click Advanced.\nThen, proceed to your site.\nIn the URL bar, you\u0026rsquo;ll still probably see some intimidating red error message.\nUpon further inspection, we can see this error is because the certificate wasn\u0026rsquo;t generated by a trusted CA (Thawte, Symatec, etc\u0026hellip;).\nIf you inspect the actual certificate, you can see it\u0026rsquo;s the certificate we created, so you know it can be trusted.\nThat\u0026rsquo;s it! I\u0026rsquo;ll be tweaking this guide as I go, but let me know if anything is incorrect or missing. Also, a¬†couple useful posts and sources I used when stuck are located¬†here, here, and here.\n-Logan\nComments Old comments from WordPress (rev1)\nOld comments from WordPress (rev2)\nOld comments from WordPress (rev3)\n","permalink":"https://loganmarchione.github.io/2015/02/openwrt-with-openvpn-client-on-tp-link-tl-mr3020/","summary":"Hey! Listen! This post is part of a series on using OpenWrt. Check them all out!\nDate URL Part 2016-04-28 OpenWrt upgrade process OpenWrt upgrade 2015-08-26 OpenWrt with OpenVPN server on TP-Link Archer C7 Initial post 2015-02-15 OpenWrt with OpenVPN client on TP-Link TL-MR3020 Initial post Update: Multiple posts Originally, this series consisted of three posts with basically the same content, but small improvements each time. The original links are below:","title":"OpenWrt with OpenVPN client on TP-Link TL-MR3020"},{"content":"Ever since TrueCrypt disappeared a few days ago, there has been a lot of speculation as to what happened. There are plenty of theories on r/netsec, r/linx, and r/crypto. Even Bruce Schneier doesn\u0026rsquo;t know what\u0026rsquo;s going on.\nThere is a theory that the developer threw in the towel, however, the most popular theory going around is that the NSA/FBI/other-three-letter-organization was involved and this is TrueCrypt\u0026rsquo;s warrant canary. Because they would not legally be allowed to divulge the fact that they were being forced to backdoor their software, they decided to suggest alternatives known to be backdoored, knowing that users would understand the secret message.\nPersonally, I think a tinfoil-style comment on Ars Technica sums it up best:\nConsider the logic of it. The version with the warning is signed with the true private signing key. So it is authentic. The explanation about this being related to Windows XP support is ridiculous. The suggestion to use BitLocker is quite telling. Now suppose that the author received a secret order from a secret court that required the author keep secret the secrecy of the secret order from the secret court. Furthermore, the author was secretly required to turn over his secret signing key to a secret third party.\nIf you were the author, what would you do? Consider your options.\nOne is that you could issue an update with a warning that the program is no longer secure. Even though the program really is, at this moment, secure. The only source code changes are to insert the warnings. But what the warnings are warning you about, but cannot just come out and say, is that the program will not be secure in the future because a third party now has the keys to sign authentic new insecure versions.\nThis wouldn\u0026rsquo;t be unlike Lavabit shutting down. The author is choosing to fall on his sword for the good of everyone.\nUp until v7.2, TrueCrypt was the best at what it did. In theory, as long as there was no flaw in the code, you could still use older versions of TrueCrypt without issue. Good news for you, as plenty of sites are now hosting archives of those older versions:\nTrueCrypt.ch - Hosted in Switzerland GitHub - Team behind TrueCrypt audit GitHub Gibson Research Corporation GitHub Get downloading.\n-Logan\n","permalink":"https://loganmarchione.github.io/2014/06/update-truecrypt-may-not-be-secure/","summary":"Ever since TrueCrypt disappeared a few days ago, there has been a lot of speculation as to what happened. There are plenty of theories on r/netsec, r/linx, and r/crypto. Even Bruce Schneier doesn\u0026rsquo;t know what\u0026rsquo;s going on.\nThere is a theory that the developer threw in the towel, however, the most popular theory going around is that the NSA/FBI/other-three-letter-organization was involved and this is TrueCrypt\u0026rsquo;s warrant canary. Because they would not legally be allowed to divulge the fact that they were being forced to backdoor their software, they decided to suggest alternatives known to be backdoored, knowing that users would understand the secret message.","title":"UPDATE: TrueCrypt may not be secure"},{"content":"Recently, I posted three articles of a four-part series showing how to encrypt an external drive with TrueCrypt on Fedora 20. As-of today, May 28th, TrueCrypt may not be secure after-all.\nThe truecrypt.org website now redirects to truecrypt.sourceforge.net. A warning is displayed that reads, \u0026ldquo;WARNING: Using TrueCrypt is not secure as it may contain unfixed security issues\u0026rdquo; and it directs users to alternative encryption packages for Windows, Mac, and Linux.\nArs Technica, Hacker News, and The Register have a good articles, so I won\u0026rsquo;t repeat everything they\u0026rsquo;re saying. Initially, it appeared that the TrueCrypt website was hacked. However, in addition to the website updates, new binaries were released that display warnings like INSECURE_APP when users try to encrypt data. The binaries, however, are signed with the developer\u0026rsquo;s key. In addition, a Wikipedia user named Truecrypt-end attempted to update the Wikipedia page with the same messages, but it was rejected by moderators. TrueCrypt was recently going through an independent security audit, and it passed Phase 1 in April. However, this doesn\u0026rsquo;t seem to be related.\nA thread on r/crypto offers up a couple explanations:\nThe website was hacked, and the keys are presumed to be compromised. The last working version is 7.1a and version 7.2 is a hoax/malware/spam Something bad happened to the developers (Lava-bit style extortion or major bug/flaw found in code) and this version is legitimate We\u0026rsquo;ll have to see how this one plays out.\n-Logan\n","permalink":"https://loganmarchione.github.io/2014/05/truecrypt-may-not-be-secure/","summary":"Recently, I posted three articles of a four-part series showing how to encrypt an external drive with TrueCrypt on Fedora 20. As-of today, May 28th, TrueCrypt may not be secure after-all.\nThe truecrypt.org website now redirects to truecrypt.sourceforge.net. A warning is displayed that reads, \u0026ldquo;WARNING: Using TrueCrypt is not secure as it may contain unfixed security issues\u0026rdquo; and it directs users to alternative encryption packages for Windows, Mac, and Linux.","title":"TrueCrypt may not be secure"},{"content":"In March, I cancelled my subscription to Dropbox over privacy concerns. Seems like that was a good idea.\nDropbox just announced that they\u0026rsquo;re adding Dr. Condoleezza Rice to their Board of Directors. I don\u0026rsquo;t have to tell you why this is a terrible idea.\nSee the official petition here, and my letter to Dropbox customer service below.\nTo whom it may concern,\nI have been a paid subscriber to Dropbox since 2010, and have loved every minute of your service since day 1. However, with recent revelations about the NSA, I\u0026rsquo;ve been growing increasingly worried about storing my data in the cloud. Before my subscription renewed in March, I removed all of my files and downgraded to a free account. Originally, I had planned to re-subscribe once I decided how to encrypt my data locally before uploading.\nHowever, after learning that Dr. Condoleezza Rice will be joining your Board of Directors, I will NOT be coming back. Dr. Rice has a proven track record of supporting warrantless wiretapping of US citizens in the name of stopping \u0026ldquo;terrorism\u0026rdquo;. As a company that is trusted with personal user data, you should be ashamed of yourselves for this action.\nI\u0026rsquo;m sure that one individual\u0026rsquo;s opinion won\u0026rsquo;t matter to your CEO, but I sincerely hope that you lose more customers over this decision. My trust in your service has been lost, and you will not be getting it back.\nSincerely,\nLogan Marchione\n-Logan\n","permalink":"https://loganmarchione.github.io/2014/04/update-dropping-dropbox/","summary":"In March, I cancelled my subscription to Dropbox over privacy concerns. Seems like that was a good idea.\nDropbox just announced that they\u0026rsquo;re adding Dr. Condoleezza Rice to their Board of Directors. I don\u0026rsquo;t have to tell you why this is a terrible idea.\nSee the official petition here, and my letter to Dropbox customer service below.\nTo whom it may concern,\nI have been a paid subscriber to Dropbox since 2010, and have loved every minute of your service since day 1.","title":"UPDATE: Dropping Dropbox"},{"content":"I dropped Dropbox!¬†Well, not entirely.\nI\u0026rsquo;ve been a Dropbox user since Day 1. I remember when their service was first introduced. Cloud storage was just coming out and it was so convenient to be able to access your data anywhere.\nI quickly outgrew the 2GB free limit, earned a few extra GB through DropQuest, and then decided to start paying for their storage. For the past few years, I\u0026rsquo;ve been paying $99/yr for 100GB of space. Honestly, I have never had a single problem with Dropbox since I first started using it and I would recommend it to anyone in a second.\nHowever, in light of recent events, I\u0026rsquo;ve been worried about my data in the cloud. Dropbox encrypts data in transit and stores it in Amazon\u0026rsquo;s S3 storage. While your data is stored encrypted, Dropbox holds the keys. According to a Dropbox Help Center article:\nDropbox users can\u0026rsquo;t view your files (unless you share them) Dropbox employees are prohibited from viewing your files To me, the devil is in the details. While a regular Dropbox user can\u0026rsquo;t view my files, any Dropbox employee can, they\u0026rsquo;re just not allowed to. Because I\u0026rsquo;m not encrypting my files before transit (I\u0026rsquo;m letting the Dropbox app do it), they can be decrypted by Dropbox employees. Dropbox says they do this to comply with any legal requests, which is completely understandable. However, with the NSA looking to add Dropbox to the list of PRISM providers, I\u0026rsquo;m not too excited about my data being decrypted whenever the government demands it.\nBefore my year-long contract renewed, I made the decision to downgrade to a free account until I can figure out how I want to use cloud storage. I considered using TrueCrypt containers inside Dropbox, but I was concerned about whether or not the entire container would need synced every time I changed a single file within. I also considered a service like SpiderOak that claims to have a zero-knowledge policy. Wuala also offers zero-knowledge, but with data centers in Switzerland.\nUntil then, I\u0026rsquo;m not worried about storing my non-sensitive data in the cloud. So far, I\u0026rsquo;ve managed to accumulate 41GB worth of free storage:\n2GB with Dropbox 2GB with SpiderOak 5GB with Wuala 7GB with OneDrive 10GB with Tresorit 15GB with Google Drive -Logan\n","permalink":"https://loganmarchione.github.io/2014/03/dropping-dropbox/","summary":"I dropped Dropbox!¬†Well, not entirely.\nI\u0026rsquo;ve been a Dropbox user since Day 1. I remember when their service was first introduced. Cloud storage was just coming out and it was so convenient to be able to access your data anywhere.\nI quickly outgrew the 2GB free limit, earned a few extra GB through DropQuest, and then decided to start paying for their storage. For the past few years, I\u0026rsquo;ve been paying $99/yr for 100GB of space.","title":"Dropping Dropbox"},{"content":"Hello, World! üëã My name is Logan Marchione and I\u0026rsquo;m a Sr. Software Engineer on the Platform team at Rapid7. This is my space on the web to learn about the internet, crypto{graphy,currency}, Linux, hosting, code, etc\u0026hellip;\nI\u0026rsquo;m passionate about open-source software, dates being in the RFC 3339 format (YYYY-MM-DD), and Oxford commas. Shameless plug: I‚Äôm a fan of the EFF and the work they do to help protect freedom online. Consider joining! I\u0026rsquo;ve been a member since 2014!\nIf you\u0026rsquo;re interested in hiring me, check out my resume. If you enjoy what I create, you can subscribe to my blog\u0026rsquo;s feed.\nI hope you find something of value here! Enjoy!\nPresence on the web Twitter Twitter\nDocker Docker Hub\nY Combinator HackerNews\nGitHub GitHub\nGitLab GitLab (username squatting)\nsourcehut (username squatting)\nSteam Steam\nMastodon Mastodon\nContact info ‚úâÔ∏è logan[at]loganmarchione[dot]com\nHugo stats This site is generated with Hugo. These stats are heavily inspired by Luke Harris.\nNumber of pages 63 Number of posts 58 Number of non-posts 5 Nubmer of tags 0 Nubmer of categories 12 Total words written (in posts) 70,056 Average words per post 1,207 Oldest post Dropping Dropbox - 2014-03-26 Newest post Linux on the Lenovo ThinkPad T14 Gen2 (AMD) - 2022-11-09 -Logan\n","permalink":"https://loganmarchione.github.io/about/","summary":"Hello, World! üëã My name is Logan Marchione and I\u0026rsquo;m a Sr. Software Engineer on the Platform team at Rapid7. This is my space on the web to learn about the internet, crypto{graphy,currency}, Linux, hosting, code, etc\u0026hellip;\nI\u0026rsquo;m passionate about open-source software, dates being in the RFC 3339 format (YYYY-MM-DD), and Oxford commas. Shameless plug: I‚Äôm a fan of the EFF and the work they do to help protect freedom online.","title":"About"},{"content":"Education and Certifications Education and certifications, some of which may not be reflected on my resume.\nOrganization Course/Certificate Badge Obtained Expiration Certificate Organization Course/Certificate Badge Obtained Expiration Certificate The Pennsylvania State University Bachelor of Science in Information Sciences and Technology\nMinor in Security and Risk Analysis 2011-12-XX N/A N/A CompTIA Security+ (SY0-501) 2019-09-21 2022-09-21 PDF edX Linux Foundation - Introduction to Site Reliability Engineering and DevOps 2020-01-10 N/A PDF edX Microsoft - Enterprise Security Fundamentals 2020-01-16 N/A PDF (ISC)\u0026sup2; Systems Security Certified Practitioner (SSCP) 2020-03-17 2023-03-31 PDF edX MongoDB University - MongoDB Basics 2020-03-04 N/A PDF edX RedHat - Fundamentals of Red Hat Enterprise Linux 2020-03-17 N/A PDF FEMA IS-100.C: Introduction to the Incident Command System 2020-04-16 N/A PDF FEMA IS-700.B: An Introduction to the National Incident Management System 2020-04-23 N/A PDF edX Microsoft - Introduction to Python: Absolute Beginner 2020-06-02 N/A PDF AWS AWS Cloud Practitioner Essentials 2021-08-26 N/A PNG AWS AWS Security Fundamentals (Second Edition) 2021-08-26 N/A PNG A Cloud Guru Learn AWS by Doing 2021-09-01 N/A PNG AWS Certified Cloud Practitioner (CCP) 2021-10-09 2024-10-09 PDF -Logan\n","permalink":"https://loganmarchione.github.io/education/","summary":"Education and Certifications Education and certifications, some of which may not be reflected on my resume.\nOrganization Course/Certificate Badge Obtained Expiration Certificate Organization Course/Certificate Badge Obtained Expiration Certificate The Pennsylvania State University Bachelor of Science in Information Sciences and Technology\nMinor in Security and Risk Analysis 2011-12-XX N/A N/A CompTIA Security+ (SY0-501) 2019-09-21 2022-09-21 PDF edX Linux Foundation - Introduction to Site Reliability Engineering and DevOps 2020-01-10 N/A PDF edX Microsoft - Enterprise Security Fundamentals 2020-01-16 N/A PDF (ISC)\u0026sup2; Systems Security Certified Practitioner (SSCP) 2020-03-17 2023-03-31 PDF edX MongoDB University - MongoDB Basics 2020-03-04 N/A PDF edX RedHat - Fundamentals of Red Hat Enterprise Linux 2020-03-17 N/A PDF FEMA IS-100.","title":"Education"},{"content":"Interview stuff I end up referencing this materal often, so I thought I\u0026rsquo;d publish it here.\nQuestions for interviewer Purpose When asked \u0026ldquo;Do you have any questions for us?\u0026rdquo;, you don\u0026rsquo;t need to mumble like you\u0026rsquo;re not prepared. These questions are more geared towards tech/IT white-collar (i.e., cubicle) type jobs in the USA. Instructions Print this out and bring it with you to an interview. Make sure you actually write down the answers you\u0026rsquo;re given, don\u0026rsquo;t just nod your head and say \u0026ldquo;Mmhmmm\u0026rdquo;. Comments and notes are in italics. Questions About the (potential) company (may be best to direct this to HR) How are you funded? Capital, stocks, private investment, etc\u0026hellip; Are you profitable? If not, what is your plan to become profitable? This mainly applies to startups. What is the company\u0026rsquo;s growth plan for the next 1 year? Next 5 years? Do you outsource work? If so, what percentage? Not specifically overseas, but even to contractors. Can you tell me about the company culture? Is there a busy time of the day/week/month/year? If so, why? Am I expected to take my work home with me? Try to find out the work/life balance. Am I expected to obtain a security clearance? Do you provide open offices, personal offices, or cubicles? Is there a dress code? About the (potential) position Why is this position open? Try to determine if the position has high turnover or if it\u0026rsquo;s unnecessarily stressful. Can you describe a typical day in this position? What about a typical week? What would you expect me to accomplish in the first 60 to 90 days? What about the first year? How is the success of the person in this position to be measured? Do you work on a quota (e.g., number of closed tickets per week), or are your goals less quantifiable? What are the common attributes your top performers in this position? What are the biggest challenges or obstacles a person in this position will face? What are the core work hours? What timezones does this position span? Is there an on-call rotation or shift-work? If so, please describe. About your (potential) manager How long have you been with the company? How would you describe your management style? If they use the words \u0026ldquo;hands-on\u0026rdquo; or \u0026ldquo;micro\u0026rdquo;, run the other way. What is your team\u0026rsquo;s biggest challenge right now? They\u0026rsquo;ll probably say \u0026ldquo;Not enough staff\u0026rdquo;, since they\u0026rsquo;re hiring. Ask for their second biggest challenge. Is there anything in particular that frustrates you? Anything from the culture, to a particular project. Try to learn what frustrates them, because you need to show them how you can solve their problems. What is the number one goal/project you\u0026rsquo;d like to achieve/complete in the next year or two? What do your employees do in their free time? This not only shows that the employees have lives outside of work, but it shows that their manager knows them on a personal level. What excites you personally about coming into work? About your (potential) team/coworkers How is your team structured? What is the junior/senior balance of the team? Will you end up being the least or most experienced person on the team? How long has the longest team member been here? How do you assign work/projects to members of the team? How frequently does your team work with other teams? How does inter/intra team communication work (e.g., Skype, Teams, Slack, etc\u0026hellip;)? Do you use any tools for project organization? What kind of recurring meetings does the team have? Salary/compensation/performance reviews I highly recommend reading this before discussing salary (specifically the five tips) Postpone salary negotiations until after you\u0026rsquo;ve been offered a job Let the other side make the first offer When you hear the offer, repeat the top value, then be silent Counter the offer with a researched response Cinch the deal, then some more Do you give formal performance reviews? If so, how often? How do you reward tenure? Do you give annual salary increases? If so, what was last year\u0026rsquo;s median raise on your team (in percent)? Do you give bonuses? If so, how often? Do you rank employees against one another when determining raises and bonuses? Benefits/perks What kind of benefits do you offer? Healthcare/dental/vision? Make sure to ask who the provider is for each. Life insurance? Prescription insurance? Retirement plan(i.e., 401k/403b)? Make sure to ask the percentage match and vesting period. Stock options or profit sharing? Employee stock purchase program? What kind of perks do you offer? Tuition assistance and other education (e.g., certificates, classes, conferences, etc\u0026hellip;)? Child/dependent care? Flexible hours? Employee discounts? Company car/credit card? Commuter perks (e.g., bus pass)? Wellness programs (e.g., gym membership)? In-office snacks/food? In-office causal dress code? Charity donation matching? Paid sabbaticals? Time off/PTO How much PTO is offered? Is it give at once or accrued over time? If accrued, what is the accrual rate? Are sick and vacation time separate or part of the same pool? What paid holidays are offered? Is there a roll-over policy for PTO? Is there a sell-back policy for PTO? Do you offer maternity/paternity leave? Work from home What is the ratio of remote to office workers? How flexible are the work from home hours? How frequently can I work from home? How frequently will I be expected to come into the office? Will the company pay for electronics/office equipment? If so, who owns that equipment? How do you feel about BYOD? ","permalink":"https://loganmarchione.github.io/interviews/","summary":"Interview stuff I end up referencing this materal often, so I thought I\u0026rsquo;d publish it here.\nQuestions for interviewer Purpose When asked \u0026ldquo;Do you have any questions for us?\u0026rdquo;, you don\u0026rsquo;t need to mumble like you\u0026rsquo;re not prepared. These questions are more geared towards tech/IT white-collar (i.e., cubicle) type jobs in the USA. Instructions Print this out and bring it with you to an interview. Make sure you actually write down the answers you\u0026rsquo;re given, don\u0026rsquo;t just nod your head and say \u0026ldquo;Mmhmmm\u0026rdquo;.","title":"Interviews"},{"content":"Introduction This policy is subject to change without notice and was last updated on 2022-02-07.\nWho I am This is my personal site, the address is https://loganmarchione.com.\nMy opinions are my own, and do not reflect those of any current or previous employers, groups, or organizations.\nWhat personal data I collect and why I collect it I use your information only for providing and improving this site.\nAnalytics As-of 2021-03-01, I use Plausible for analytics. Information about Plausible\u0026rsquo;s privacy features are located here. Visitors to my site should be aware of a few things:\nI only use your information to determine what posts are more popular, what day/time is best to post, how long you stay on my site, etc‚Ä¶ Plausible collects minimal data by design. They only collect: Page URL HTTP Referer Browser (derived from the User-Agent HTTP header) Operating system (derived from the User-Agent HTTP header) Device type Visitor Country (after the geolocation lookup is completed, your IP is discarded and is never stored in their database or logs) Plausible uses JavaScript for the tracking tag. Because of this, you can use uBlock Origin, NoScript, or Ghostery to block JavaScript on my site (this might make some pages display/behave in unintended ways). Plausible is open source with their code available on GitHub. Ads/sponsorship As-of 2022-02-07, I am a verified Brave Creator. If you use the Brave browser, you can send me a tip in BAT. Being part of the Brave Creator program doesn\u0026rsquo;t inject anything into the traffic between my site and your browser, it simply gives you the option to send me BAT (and if you\u0026rsquo;re not using Brave, none of this applies to you).\nI don\u0026rsquo;t accept sponsors or free items in exchange for review.\nContact If there‚Äôs anything else you‚Äôd like to know about how I use your information or the security of this site, please contact me.\n-Logan\n","permalink":"https://loganmarchione.github.io/privacy/","summary":"Introduction This policy is subject to change without notice and was last updated on 2022-02-07.\nWho I am This is my personal site, the address is https://loganmarchione.com.\nMy opinions are my own, and do not reflect those of any current or previous employers, groups, or organizations.\nWhat personal data I collect and why I collect it I use your information only for providing and improving this site.\nAnalytics As-of 2021-03-01, I use Plausible for analytics.","title":"Privacy"}]